{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(mokken-1-notebook)=\n",
    "# Analisi della Scala di Mokken\n",
    "\n",
    "L'Analisi delle Scale Mokken (MSA), così denominata in onore del matematico e scienziato politico olandese Robert J. Mokken, è un insieme di metodi utilizzati nell'ambito della Teoria Non Parametrica della Risposta agli Item (NIRT). Secondo i principi dei modelli della Teoria della Risposta agli Item (IRT), i costrutti psicologici sono considerati latenti, ovvero non direttamente osservabili, e si manifestano attraverso le risposte ai test. Le reazioni dei partecipanti ai test (cioè, le risposte agli item) indicano la loro posizione su un continuum latente e riflettono il grado in cui i partecipanti possiedono il costrutto in esame.\n",
    "\n",
    "I modelli della IRT forniscono strumenti analitici per esaminare la congruenza degli item di un test con la variabile latente sottostante. In particolare, i modelli MSA hanno una natura non parametrica e sono caratterizzati da presupposti meno restrittivi rispetto ai modelli IRT parametrici. I modelli MSA sono applicabili sia a item dicotomici che politomici, e rivestono un ruolo cruciale nella validazione di strumenti di misura psicometrici e nell'ordinare rispondenti e item lungo una scala ordinale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling di Guttman \n",
    "\n",
    "La MSA trova le sue radici nello scaling di Guttman, sviluppato nel 1950 da Louis Guttman. Questo metodo, originariamente concepito per item dicotomici, mira a estrarre una singola dimensione dai dati, posizionando sia le persone che gli item su questa dimensione tramite valori numerici. Ad esempio, consideriamo cinque item di un test psicologico e cinque rispondenti ipotetici, A, B, C, D ed E, che rispondono a questi item. Le risposte vengono rappresentate in una tabella dove 1 indica una risposta corretta e 0 una errata.\n",
    "\n",
    "| Items | Esaminati | 1 | 2 | 3 | 4 | 5 |\n",
    "|-------|-----------|---|---|---|---|---|\n",
    "|       | A         | 1 | 1 | 1 | 1 | 1 |\n",
    "|       | B         | 1 | 1 | 1 | 1 | 0 |\n",
    "|       | C         | 1 | 1 | 1 | 0 | 0 |\n",
    "|       | D         | 1 | 1 | 0 | 0 | 0 |\n",
    "|       | E         | 1 | 0 | 0 | 0 | 0 |\n",
    "\n",
    "In questa tabella, che rappresenta una scala di Guttman, gli item sono ordinati dal più facile al più difficile, e i rispondenti dall'abilità maggiore a quella minore. Si presume che un rispondente che ha risposto correttamente ad un item di difficoltà superiore abbia risposto correttamente anche a tutti gli item di difficoltà inferiore. Le deviazioni da questo modello sono considerate \"errori di Guttman\".\n",
    "\n",
    "La scala di Guttman, basandosi su un principio deterministico, non riesce sempre a catturare pienamente la complessità dei dati reali. Tuttavia, offre una rappresentazione chiara della relazione cumulativa o gerarchica tra gli item di un test e le abilità dei rispondenti. Questo modello suggerisce che, se una persona dimostra una competenza specifica, si presume che possieda anche tutte le competenze di base correlate.\n",
    "\n",
    "Tuttavia, quando emergono eccezioni a questa regola, ossia risposte corrette a item difficili ma errate a quelli più semplici, si potrebbe dedurre che il test richieda competenze multiple e non unicamente riconducibili a una dimensione unica. Questo fenomeno mette in luce la complessità e la multidimensionalità delle competenze umane.\n",
    "\n",
    "In conclusione, la MSA si adatta particolarmente a contesti dove i processi di risposta non sono completamente chiari (come quando la prestazione dipende da una struttura multidimensionale di abilità), consentendo di verificare se le risposte dei partecipanti rispettino i requisiti del modello e di ordinare persone e item su una scala ordinale, basandosi sui punteggi totali grezzi.\n",
    "\n",
    "## Analisi della Scala di Mokken\n",
    "\n",
    "La MSA si colloca all'interno del paradigma dello scaling di Guttman, ma transita dal modello deterministico classico di Guttman a un approccio probabilistico. Il modello di Guttman si basa sul principio di perfetta transitività, secondo cui, in presenza di una sequenza di item ordinati per difficoltà, un rispondente che riesce a rispondere correttamente a un item difficoltoso dovrebbe anche rispondere correttamente agli item più semplici. Tuttavia, questo modello deterministico cumulativo spesso non riflette la realtà dei dati empirici, influenzati dalla complessità delle abilità umane e da altre variabili. Di conseguenza, sono stati adottati modelli probabilistici, come la MSA e il modello di Rasch, che permettono una certa varianza nelle risposte.\n",
    "\n",
    "La MSA, evoluzione probabilistica dello scaling di Guttman, consente un certo grado di violazioni di questo modello, risultando meno restrittiva e più aderente ai dati empirici. Questo modello facilita l'analisi dell'unidimensionalità e la misurazione di variabili latenti su una scala unidimensionale, specialmente utile con un numero limitato di item.\n",
    "\n",
    "A differenza di metodi come l'analisi fattoriale e l'analisi di affidabilità, la scala di Guttman e, per estensione, la MSA, sono ottimizzate per l'analisi di item con significative differenze di difficoltà. La MSA si articola in due modelli IRT non parametrici principali: il Modello di Omogeneità Monotona (MHM) e il Modello di Monotonicità Doppia (DMM). \n",
    "\n",
    "**Modello di Omogeneità Monotona (MHM)** Il MHM, il primo modello della MSA, si fonda su tre presupposti fondamentali: unidimensionalità, monotonicità e indipendenza locale. Queste assunzioni sono vitali per il suo funzionamento. Se valide, consentono di posizionare gli individui su una scala unidimensionale ordinale, con un ordinamento costante attraverso tutti gli item. In presenza di un insieme omogeneo di item, l'ordinamento degli individui rimane invariato per ogni sottoinsieme di item. Il MHM fornisce una base robusta per l'analisi delle risposte agli item, soprattutto in contesti dove la monotonicità è cruciale.\n",
    "\n",
    "**Modello di Monotonicità Doppia (DMM)** Il DMM estende il MHM includendo un ulteriore vincolo: le Funzioni di Risposta agli Item (IRF) non devono intersecarsi. Questo modello esamina la relazione tra la difficoltà degli item e il livello di abilità dei rispondenti. La validità dell'Invariance of Item Ordering (IIO) indica che l'ordinamento degli item per difficoltà è uniforme a tutti i livelli di abilità. La violazione dell'IIO può suggerire un fenomeno di Differential Item Functioning (DIF), mettendo in dubbio l'invarianza della misurazione e suggerendo che l'ordine degli item potrebbe variare tra sottogruppi di rispondenti con abilità simili.\n",
    "\n",
    "In conclusione, la MSA rappresenta un'evoluzione metodologica significativa rispetto allo scaling di Guttman, offrendo un approccio meno restrittivo e più adatto all'analisi dei dati empirici. Fornisce un quadro analitico efficace per l'indagine dettagliata delle risposte agli item e delle abilità dei rispondenti in contesti psicologici e educativi.\n",
    "\n",
    "## Confronto tra il Modello di Rasch e l'Analisi della Scala di Mokken\n",
    "\n",
    "Il Modello di Rasch (RM) assume che la probabilità di risposta corretta a un item sia determinata dall'abilità della persona (θ) e dalla difficoltà dell'item (δ). La relazione tra la probabilità di una risposta corretta e θ è descritta da una funzione logistica, con IRFs parallele e dalla stessa pendenza. Questo modello è definito parametrico poiché utilizza una funzione parametrica specifica, la funzione logistica, per stabilire tale relazione.\n",
    "\n",
    "Il Modello di Rasch prevede che i punteggi grezzi totali siano sufficienti per stimare i parametri delle persone e degli item. È considerato il modello più restrittivo rispetto al Modello di Monotonicità Omogenea (MHM) e al Modello di Monotonicità Doppia (DMM) per le sue assunzioni aggiuntive.\n",
    "\n",
    "D'altra parte, l'Analisi della Scala di Mokken (MSA) appartiene alla categoria dei modelli non parametrici della IRT (NIRT), che non prevedono una funzione specifica per le IRFs. In questi modelli, il punteggio grezzo totale fornisce un ordine basato sulla variabile latente θ, poiché θ non è direttamente stimato. Questo approccio è meno restrittivo rispetto ai modelli parametrici e consente una maggiore flessibilità nell'analisi dei dati.\n",
    "\n",
    "Il MHM, il modello meno restrittivo tra i tre, si basa su tre assunzioni fondamentali: unidimensionalità, monotonicità e indipendenza locale. Questo modello permette di ordinare gli individui su una scala unidimensionale ordinale, mantenendo costante questo ordinamento attraverso tutti gli item. Il DMM, invece, aggiunge l'assunzione di IRF non intersecanti al MHM, producendo scale ordinali separate per persone e item.\n",
    "\n",
    "Un punto critico è che, mentre il Modello di Rasch crea una scala metrica comune per persone e item, consentendo misurazioni indipendenti da persone e item, il DMM genera scale ordinali distinte. Inoltre, i modelli NIRT, come la MSA, non richiedono la conformità degli item a una funzione logistica specifica, evitando così la necessità di scartare gli item che non seguono tale funzione, una limitazione dei modelli PIRT (Parametric Item Response Theory).\n",
    "\n",
    "In sintesi, mentre il Modello di Rasch offre un approccio più restrittivo ma preciso, basato su assunzioni specifiche e una scala metrica comune, la MSA offre una maggiore flessibilità e applicabilità a un'ampia gamma di dati, pur producendo scale ordinali distinte per persone e item. Questa differenza chiave tra i due approcci sottolinea l'importanza di scegliere il modello più adatto in base agli obiettivi specifici e alla natura dei dati in esame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confronto tra la Teoria Classica dei Test e l'Analisi della Scala di Mokken \n",
    "\n",
    "Consideriamo le somiglianze e le differenze tra la Teoria Classica dei Test (CTT) e l'Analisi della Scala di Mokken (MSA).\n",
    "\n",
    "La CTT si basa su diverse assunzioni fondamentali:\n",
    "1. I punteggi osservati sono la somma dei punteggi veri e dei punteggi di errore, con l'aspettativa che i punteggi di errore abbiano una media di zero su prove ripetute.\n",
    "2. Non c'è correlazione tra i punteggi di errore e i punteggi veri.\n",
    "3. I punteggi veri in un test non sono correlati ai punteggi di errore in un altro test.\n",
    "4. I punteggi di errore in due test somministrati agli stessi soggetti sono non correlati.\n",
    "\n",
    "Nella CTT, i punteggi grezzi totali sono considerati indicatori delle posizioni delle persone sul continuum del tratto latente. La proporzione di risposte corrette ad un item, nota come valore p, riflette la facilità di quell'item. Inoltre, la correlazione tra le risposte corrette a singoli item e il punteggio totale su un test valuta la capacità di discriminazione degli item, ossia quanto bene essi distinguono tra i partecipanti con diverse livelli di abilità. La CTT enfatizza anche l'importanza dell'affidabilità, definita come la correlazione tra i punteggi osservati su due forme parallele del test.\n",
    "\n",
    "Confrontando la Teoria Classica dei Test (CTT) con l'Analisi di Scala di Mokken (MSA), possiamo notare alcune somiglianze nei metodi utilizzati per calcolare gli indici di difficoltà degli item e le abilità dei partecipanti. Nella MSA, il coefficiente di scalabilità di un singolo item, Hi, si può paragonare alla correlazione tra le risposte corrette ai singoli item e il punteggio totale, come avviene nella CTT. Analogamente, il coefficiente di scalabilità tra coppie di item, Hij nella MSA, è simile alla correlazione tra coppie di item nella CTT. Inoltre, il coefficiente di scalabilità complessivo, H, nella MSA è comparabile agli indici di discriminazione media degli item nella CTT.\n",
    "\n",
    "Tuttavia, una differenza fondamentale tra la Mokken Scale Analysis (MSA) e la Teoria Classica dei Test (CTT) risiede nella capacità di valutare il modello statistico ipotizzato. La MSA consente di verificare empiricamente in maniera più diretta le sue assunzioni, come l'indipendenza locale, l'unidimensionalità e la monotonicità. Ad esempio, un coefficiente di scalabilità negativo nella MSA potrebbe mettere in dubbio gli assunti del Modello di Omogeneità Monotona (MHM). Questa capacità di testare empiricamente le sue assunzioni rende la MSA un modello particolarmente robusto e trasparente.\n",
    "\n",
    "In conclusione, mentre la CTT fornisce un quadro teorico solido per la comprensione e l'interpretazione dei punteggi dei test, la MSA offre un approccio più flessibile e testabile, particolarmente utile nell'analizzare la struttura dei dati dei test e nella valutazione della validità delle scale di misurazione. Queste caratteristiche rendono la MSA un complemento prezioso alla CTT nella pratica della misurazione psicologica.\n",
    "\n",
    "\n",
    "## Modelli\n",
    "\n",
    "L'MSA utilizza due diversi modelli IRT non parametrici per costruire scale. I modelli non parametrici impiegano assunzioni meno restrittive sui dati rispetto alla maggior parte degli altri modelli IRT, spesso parametrici, e si concentrano tipicamente sull'indagine dettagliata dell'adattamento del modello e sull'esplorazione dei dati per comprendere meglio il test, i suoi item e la popolazione di interesse in modo più approfondito (Junker & Sijtsma, 2001). I modelli non parametrici implicano scale ordinali per persone e item basate su punteggi di test osservabili, definiti rispettivamente da medie di punteggi. \n",
    "\n",
    "### Il Modello di Omogeneità Monotona di Mokken\n",
    "\n",
    "Il modello di omogeneità monotona, proposto da Mokken nel 1971, rappresenta una delle due configurazioni fondamentali nell'ambito dei modelli non parametrici per la teoria della risposta agli item (IRT), l'altra essendo il modello di doppia monotonicità.\n",
    "\n",
    "#### Caratteristiche del Modello di Omogeneità Monotona\n",
    "\n",
    "Questo modello si basa sul concetto di omogeneità monotona, che implica che se un soggetto ha una probabilità maggiore o uguale di rispondere correttamente a un item (o di scegliere una risposta più alta in un item graduato) rispetto a un altro soggetto, allora ciò dovrebbe valere per tutti gli item all'interno del set considerato. In termini più semplici, se un individuo A ha una maggiore probabilità di risposta corretta rispetto a un individuo B su un item, allora A dovrebbe avere una probabilità maggiore o uguale su tutti gli altri item della scala. Questo principio supporta l'idea che gli item si possano ordinare in una scala unidimensionale, dove un singolo tratto latente o abilità del soggetto determina una risposta consistente su tutti gli item.\n",
    "\n",
    "#### I presupposti fondamentali del modello sono:\n",
    "\n",
    "1. **Unidimensionalità**: Tutti gli item di una scala misurano un unico attributo, rappresentato da una variabile latente, denotata con $ h $.\n",
    "2. **Monotonicità**: Con l'aumentare di $ h $, aumenta anche la probabilità di ottenere un punteggio almeno pari a $ x_j $ per l'item $ j $. Questo suggerisce che più un individuo possiede l'attributo misurato, maggiore è la probabilità che ottenga punteggi alti, tipici di un livello superiore dell'attributo. La funzione che descrive questa relazione è nota come la funzione di risposta gradino dell'item (ISRF).\n",
    "3. **Indipendenza locale**: Gli item che misurano lo stesso attributo mostrano una correlazione positiva nei punteggi quando si varia $ h $. Tuttavia, se si rimuove questa fonte di variazione, ad esempio isolando un sottogruppo di persone con lo stesso valore di $ h $, la correlazione tra gli item scompare, dimostrando che la scala è unidimensionale e che condizionando rispetto a $ h $ gli item risultano indipendenti. Statisticamente, questo si traduce in una covarianza condizionale pari a zero tra gli item, un concetto noto come indipendenza locale debole.\n",
    "\n",
    "#### Vantaggi del modello\n",
    "\n",
    "Uno dei principali vantaggi del modello di omogeneità monotona è la sua flessibilità: non richiede la specificazione di una forma funzionale precisa per la relazione tra la probabilità di una risposta e il tratto latente. Questo lo rende particolarmente adatto per applicazioni dove la forma della distribuzione del tratto latente non è nota o è difficile da specificare.\n",
    "\n",
    "#### Verifica dell'omogeneità monotona\n",
    "\n",
    "Per verificare l'omogeneità monotona in un set di item, i ricercatori spesso ricorrono a coefficienti di scalabilità, come il coefficiente $ H $ di Mokken, che misura la forza della relazione monotona tra gli item e il tratto latente. Valori più alti di $ H $ indicano una maggiore omogeneità e, quindi, una migliore qualità della scala in termini di rappresentazione del tratto latente. Questo coefficiente aiuta a valutare la coerenza con cui gli item riflettono il tratto o l'abilità di interesse, essenziale per garantire la validità delle misurazioni effettuate con la scala.\n",
    "\n",
    "### Il Modello di Doppia Monotonicità di Mokken\n",
    "\n",
    "Il modello di doppia monotonicità, noto anche come modello di monotonicità forte, è una delle due configurazioni fondamentali sviluppate da Mokken per l'analisi delle risposte agli item in contesti non parametrici. Questo modello estende il concetto di omogeneità monotona, aggiungendo requisiti più stringenti sulla monotonicità delle funzioni di risposta degli item (Item Response Functions - IRF).\n",
    "\n",
    "#### Caratteristiche Principali del Modello\n",
    "\n",
    "Nel modello di doppia monotonicità, si richiede non solo che la probabilità di rispondere correttamente a un item (o di selezionare una risposta più elevata in un item graduato) aumenti monotonamente con il tratto latente del rispondente, come nel modello di omogeneità monotona, ma anche che questo incremento sia coerente e non decrescente per ogni item lungo il continuum del tratto. In altre parole, per ogni aumento nel tratto latente, la probabilità di una risposta positiva deve sempre crescere, garantendo una coerenza sia nell'ordinamento dei soggetti che nella relazione tra il tratto latente e la probabilità di risposta per ciascun item.\n",
    "\n",
    "#### Implementazione e Verifica\n",
    "\n",
    "Il modello di doppia monotonicità implica anche l'ordinamento degli item basato sulla media dei punteggi degli item, tipicamente utilizzato in vari test di intelligenza dove gli item sono presentati in ordine decrescente di punteggio medio. Questo approccio permette ai rispondenti di iniziare con gli item più facili, aiutandoli a superare l'ansia iniziale, e evita di scoraggiarli con item troppo difficili all'inizio.\n",
    "\n",
    "Per stabilire che l'ordinamento degli item sia equo per rispondenti di diverse abilità, è essenziale dimostrare che l'ordinamento degli item sia invariante, ovvero che rimanga costante indipendentemente dal livello di abilità dei rispondenti. Questa invarianza è garantita dal modello attraverso la non intersecazione delle IRF dei diversi item.\n",
    "\n",
    "#### Quarta Ipotesi: IRF non Intersecanti\n",
    "\n",
    "Nel modello di doppia monotonicità, si assume che le IRF di ciascun item non si intersechino. Ciò significa che l'ordinamento degli item, ad eccezione di possibili pareggi, rimane costante per ogni valore del tratto latente $ h $. Algebricamente, questo ordinamento invariante è definito come segue:\n",
    "\n",
    "- L'aspettativa del punteggio medio di un item, $ e(X_j) $, è calcolata integrando la funzione di risposta dell'item $ e(X_j | h) $ sulla distribuzione cumulativa della variabile latente $ G(h) $.\n",
    "- Gli item vengono ordinati inizialmente per i loro punteggi medi campionari, e numerati in modo che $ e(X_1) \\leq e(X_2) \\leq ... \\leq e(X_J) $.\n",
    "- Si presume che, se per qualsiasi coppia di item consecutivi $ j $ e $ j+1 $, esista almeno un valore di $ h $ per cui $ e(X_j | h) \\leq e(X_{j+1} | h) $, allora, assumendo che le IRF non si intersechino, per tutti gli item si verifica che $ e(X_1 | h) \\leq e(X_2 | h) \\leq ... \\leq e(X_J | h) $, per tutti i valori di $ h $.\n",
    "\n",
    "La consistenza di questo ordinamento rende più chiara l'interpretazione della scala: per ogni valore di $ h $, l'item con il punteggio medio più basso è considerato il meno popolare o il più difficile, seguito dagli altri fino all'item con il punteggio più alto, il più facile o popolare. Questo facilita la comprensione della relazione tra il punteggio totale e gli item individuali, conferendo maggiore significato al punteggio totale ottenuto.\n",
    "\n",
    "## Estensione dell'Analisi delle Scale di Mokken agli Item Politomici\n",
    "\n",
    "L'Analisi delle Scale di Mokken (MSA) è stata originariamente concepita per essere applicata a item dicotomici, ma successivamente è stata estesa da Molenaar nel 1982 e nel 1997 per includere anche gli item politomici. Questa estensione mantiene i principi fondamentali della MSA applicati agli item dicotomici, ma introduce considerazioni specifiche legate alla natura degli item politomici.\n",
    "\n",
    "Negli item politomici, come quelli utilizzati nelle scale Likert, le verifiche delle ipotesi del modello MSA vengono condotte non solo per l'item nel suo insieme, ma anche per ogni categoria di risposta individualmente, che viene definita \"passaggio\". Ad esempio, in un item Likert a cinque punti, che varia da \"fortemente d'accordo\" a \"fortemente in disaccordo\", si identificano quattro passaggi distinti, ognuno rappresentante una transizione tra due categorie adiacenti.\n",
    "\n",
    "Per ciascun passaggio di un item politomico, viene definita una Funzione di Risposta del Passaggio dell'Item (ISRF). Questa funzione modella la probabilità che un rispondente selezioni una particolare categoria di risposta basandosi sul suo tratto latente, denotato con $ \\theta $. Le ISRF sono cruciali per comprendere in che modo le diverse categorie di risposta sono associate al tratto latente misurato dall'item.\n",
    "\n",
    "Affinché il modello di omogeneità monotona sia applicabile agli item politomici, è essenziale che la probabilità di selezionare una categoria di risposta $ k $ o superiore aumenti in modo monotono al crescere di $ \\theta $. Questo implica che le categorie di risposta devono essere significative in termini ordinali, rappresentando livelli progressivamente crescenti del tratto latente. Un elemento chiave dell'analisi di item politomici nell'MSA è quindi la monotonicità: le ISRF devono essere funzioni crescenti rispetto a $ \\theta $, indicando che con l'aumento del tratto latente, cresce anche la probabilità che un individuo opti per categorie di risposta più elevate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'Affidabilità nei Test Psicometrici\n",
    "\n",
    "L'affidabilità di un test psicometrico indica il grado in cui i risultati del test sono consistenti e privi di errori di misurazione. Tradizionalmente, si valuta l'affidabilità esaminando la stabilità dei punteggi tra diverse somministrazioni del test, che possono avvenire in momenti differenti o attraverso versioni parallele del test. In teoria, se i punteggi veri degli esaminandi non cambiano, ci si aspetterebbe una correlazione perfetta tra i punteggi ottenuti nelle diverse somministrazioni. Qualsiasi variazione rispetto a questa correlazione ideale viene attribuita all'errore di misurazione.\n",
    "\n",
    "Tuttavia, misurare l'affidabilità attraverso somministrazioni ripetute o forme parallele del test presenta delle sfide, inclusa la difficoltà di creare test paralleli veramente comparabili e l'influenza di fattori esterni come la memoria o l'effetto pratica. Di conseguenza, l'affidabilità è frequentemente stimata mediante tecniche che necessitano una sola somministrazione del test.\n",
    "\n",
    "L'alfa di Cronbach è uno dei metodi più diffusi per stimare l'affidabilità, nonostante le sue note limitazioni. Per esempio, presume che tutti gli item del test siano equamente correlati, una condizione che non sempre si verifica nella pratica. Rispondendo a queste limitazioni, Mokken ha introdotto nel 1971 un coefficiente di affidabilità alternativo, noto come ρ (rho) o statistica MS, che si basa sulla presunzione della validità della doppia monotonicità, una condizione piuttosto esigente.\n",
    "\n",
    "Per superare alcune delle difficoltà legate alla statistica ρ, Van der Ark, Van der Palm e Sijtsma nel 2011 hanno proposto il Coefficiente di Affidabilità delle Classi Latenti (LCRC). Questo indicatore, che necessita solo della condizione di indipendenza locale tra gli item, è un estimatore non distorto dell'affidabilità dei punteggi dei test. La condizione meno restrittiva rende il LCRC un'opzione più flessibile e praticabile in vari contesti di test, rispetto al coefficiente ρ.\n",
    "\n",
    "La selezione del metodo più adeguato per stimare l'affidabilità di un test dipende dalle caratteristiche specifiche del test stesso e dalle esigenze di misurazione. Sebbene l'alfa di Cronbach sia ancora ampiamente utilizzato e riconosciuto come uno standard, alternative come la statistica ρ di Mokken e il LCRC offrono strumenti supplementari che possono risultare più appropriati in situazioni dove le assunzioni dell'alfa di Cronbach non sono rispettate o nei contesti in cui si impiegano modelli non parametrici, come quelli dell'Analisi delle Scale di Mokken.\n",
    "\n",
    "Queste alternative permettono agli sviluppatori di test di adattare meglio le metodologie di valutazione dell'affidabilità alle specifiche caratteristiche del test e alle necessità di misurazione, contribuendo così a una più accurata interpretazione dei risultati del test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficienti di Scalabilità nelle Scale Mokken\n",
    "\n",
    "I coefficienti di scalabilità nelle Scale di Mokken, designati come $ H $, $ H_i $ e $ H_{ij} $, sono elementi chiave nell'Analisi delle Scale di Mokken (MSA). Questi coefficienti sono utilizzati per valutare la qualità della misurazione, quantificando quanto coerentemente e ordinatamente gli item e i punteggi totali si distribuiscono lungo un continuum latente. Essi riflettono quanto bene gli item si organizzano in una gerarchia e quanto i punteggi degli item siano ordinati consistentemente.\n",
    "\n",
    "- **Coefficienti di Scalabilità Singoli ($ H_i $)**: Questi valutano la qualità di ciascun item individualmente. Un valore elevato di $ H_i $ indica che l'item è particolarmente efficace nel discriminare tra rispondenti con diversi livelli del tratto latente e contribuisce significativamente all'ordinamento dei rispondenti lungo il continuum. Valori superiori a 0.30 sono generalmente considerati accettabili, indicando una buona capacità di discriminazione.\n",
    "\n",
    "- **Coefficienti di Scalabilità per Coppie di Item ($ H_{ij} $)**: Questi coefficienti esaminano la coerenza tra coppie di item nella scala. Valori positivi indicano che la coppia di item è coerente con il modello di omogeneità monotona. Al contrario, valori negativi possono suggerire la presenza di multidimensionalità o di non monotonicità, mettendo in luce potenziali problemi nell'omogeneità o unidimensionalità della scala.\n",
    "\n",
    "- **Coefficienti di Scalabilità per l'Intero Test ($ H $)**: Questo indice misura la qualità complessiva del test, rivelando in che misura la struttura dei dati si avvicina a un modello di Guttman perfetto. Valori di $ H $ tra 0.30 e 0.40 indicano una scala debole, valori tra 0.40 e 0.50 indicano una scala moderata, mentre valori superiori a 0.50 denotano una scala forte.\n",
    "\n",
    "Questi coefficienti derivano dall'analisi del rapporto tra gli errori di Guttman osservati e quelli teoricamente previsti. Un coefficiente $ H $ vicino all'unità suggerisce una perfetta aderenza al modello di Guttman, indicando un errore minimo, mentre valori vicini a zero indicano una significativa presenza di errori di Guttman.\n",
    "\n",
    "L'Analisi delle Scale di Mokken permette una verifica empirica dell'adattamento dei dati al modello di omogeneità monotona, fornendo una base robusta per analizzare la struttura interna dei test e la qualità degli item. I coefficienti di scalabilità sono utilizzati per valutare l'integrità e la coerenza degli item all'interno di una scala unidimensionale e sono particolarmente preziosi per identificare item che potrebbero essere ridondanti o non congruenti con il tratto latente misurato.\n",
    "\n",
    "Oltre a valutare la precisione dell'ordinamento dei rispondenti e la qualità degli item, i coefficienti di scalabilità offrono indicazioni cruciali sulla validità di costrutto di una scala. Anche se una scala mostra una forte capacità discriminante (indicata da valori elevati di $ H_i $ e $ H $), potrebbe carentare in termini di validità di costrutto se gli item non coprono adeguatamente l'intero spettro del costrutto target. Analogamente, valori elevati di $ H_{ij} $ tra specifiche coppie di item possono suggerire una potenziale ridondanza.\n",
    "\n",
    "In conclusione, i coefficienti di scalabilità nelle Scale di Mokken non solo misurano la precisione e la qualità del test, ma contribuiscono anche a una comprensione più profonda della struttura e della validità di una scala. Essi svolgono un ruolo essenziale nella selezione e nell'analisi degli item in contesti psicometrici, educativi e di ricerca, facilitando scelte informate sulla costruzione e l'ottimizzazione delle scale di misurazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi degli Errori Standard nei Coefficienti di Scalabilità delle Scale Mokken\n",
    "\n",
    "Gli errori standard (SE) rivestono un ruolo cruciale nell'interpretazione dei coefficienti di scalabilità nelle scale di Mokken, poiché quantificano l'incertezza associata a queste stime. Un errore standard elevato rispetto al valore del coefficiente stesso, come un SE di 0.08 per un coefficiente $ H_i $ di 0.30, può indicare che il valore reale del coefficiente nella popolazione potrebbe essere significativamente diverso da 0.30, sollevando dubbi sulla scalabilità degli item.\n",
    "\n",
    "La grandezza dell'errore standard è influenzata principalmente da due fattori:\n",
    "1. **Dimensione del campione**: Maggiore è il campione, generalmente minore è l'errore standard. Questo è dovuto al fatto che stime basate su campioni più grandi tendono ad essere più vicine ai veri valori della popolazione.\n",
    "2. **Asimmetria delle distribuzioni dei punteggi degli item**: Distribuzioni più asimmetriche possono aumentare l'errore standard, poiché complicano la stima precisa dei coefficienti di scalabilità.\n",
    "\n",
    "Gli intervalli di confidenza (CI) al 95% per i coefficienti di scalabilità possono essere calcolati utilizzando la formula:\n",
    "\n",
    "$$\n",
    "\\text{95\\% CI} = H_i \\pm (1.96 \\times \\text{SE})\n",
    "$$\n",
    "\n",
    "Ad esempio, per un $ H_i $ di 0.30 con un SE di 0.10, l'intervallo di confidenza sarà tra 0.10 e 0.50. Questo intervallo ampio suggerisce che, con il 95% di confidenza, il valore reale di $ H_i $ potrebbe variare significativamente, indicando una potenziale bassa affidabilità del coefficiente. Se $ H_i $ è 0.15 con un SE di 0.10, l'intervallo di confidenza sarà tra -0.05 e 0.35, il che potrebbe implicare che il vero valore del coefficiente sia zero o addirittura negativo nella popolazione, suggerendo che l'item potrebbe non essere adeguato.\n",
    "\n",
    "Nonostante gli item con bassi coefficienti di scalabilità siano spesso considerati candidati per l'eliminazione, come suggerito da Mokken (1971), Crișan e colleghi (2020) avvertono contro la rimozione acritica di tali item. Essi sostengono che la decisione di escludere item dalle scale dovrebbe essere presa con cautela, valutando non solo la psicometria ma anche la rilevanza teorica e il contenuto degli item. Eliminare item può infatti ridurre la copertura del costrutto misurato e la validità dei criteri, anche se può sembrare migliorare l'affidabilità o la validità predittiva della scala.\n",
    "\n",
    "L'analisi degli errori standard e degli intervalli di confidenza offre informazioni preziose sulla stabilità e l'affidabilità dei coefficienti di scalabilità nelle scale Mokken. Questi dati sono fondamentali per giudicare la qualità degli item e l'integrità complessiva della scala. Tuttavia, le decisioni relative alla gestione degli item devono essere informate da una comprensione approfondita del costrutto teorico, oltre che dalle considerazioni empiriche. Questo approccio bilanciato assicura che le scale non solo siano psicometricamente robuste, ma anche teoricamente valide e pertinenti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedura di Selezione Automatica degli Item nelle Scale di Mokken\n",
    "\n",
    "La Procedura di Selezione Automatica degli Item (AISP) è un metodo impiegato nell'Analisi delle Scale di Mokken (MSA) per selezionare item da un pool più ampio in base alle assunzioni del Modello di Mokken (MHM). L'AISP è utilizzata per verificare l'unidimensionalità e identificare item che non rispettano i criteri di scalabilità.\n",
    "\n",
    "Una scala di Mokken si basa sulla selezione di item che soddisfano due criteri principali:\n",
    "1. **Covarianza individuale ($H_i$)**: Ogni item deve avere una covarianza che supera un valore soglia $c$, generalmente raccomandato come $c = 0.30$.\n",
    "2. **Covarianza reciproca ($H_{ij}$)**: La covarianza tra ogni coppia di item deve essere maggiore di zero, indicando che gli item sono coerenti tra loro rispetto al tratto latente misurato.\n",
    "\n",
    "Il processo di costruzione di una scala inizia con la selezione di due item che presentano la $H_{ij}$ più alta e prosegue aggiungendo item che rispettano i criteri sopra descritti. Se alcuni item non rispettano questi criteri, vengono esclusi o utilizzati per tentare la costruzione di una seconda scala.\n",
    "\n",
    "Le scale costruite mediante l'AISP sono destinate a misurare un tratto latente comune, ordinando in modo affidabile le persone e distinguendo efficacemente tra diversi livelli del tratto. Tuttavia, se un item viene selezionato nonostante un $H_i$ inferiore al valore soglia $c$, questo item è considerato inadatto e dovrebbe essere rimosso nelle analisi successive.\n",
    "\n",
    "La scelta del valore soglia $c$ è critica: valori soglia più elevati possono portare all'esclusione di numerosi item, risultando in scale ridotte e potenzialmente meno informative. Al contrario, valori soglia più bassi possono includere troppi item, mascherando la potenziale multidimensionalità dei dati. La selezione di $c$ dovrebbe quindi riflettere gli obiettivi specifici della ricerca.\n",
    "\n",
    "L'AISP può essere vista come un'alternativa all'analisi fattoriale esplorativa. A differenza dell'analisi fattoriale, che tende sempre a trovare una soluzione indipendentemente dalla significatività, l'AISP può concludere senza identificare una scala valida se tutti i valori di $H_{ij}$ risultano inferiori a 0.30. Questa caratteristica enfatizza l'importanza di non affidarsi ciecamente ai risultati software e di considerare anche il contesto teorico e il contenuto degli item.\n",
    "\n",
    "Sebbene l'AISP sia uno strumento utile per la costruzione di scale di Mokken, studi di simulazione hanno mostrato che può essere meno efficace di altri metodi non parametrici nel rilevare la vera dimensionalità dei dati, specialmente in presenza di dimensioni correlate o item che saturano su più dimensioni. Pertanto, è fondamentale che i ricercatori utilizzino l'AISP con attenzione, valutando attentamente una gamma di valori di $c$ per assicurare una corretta interpretazione della struttura dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monotonicità nelle Scale di Mokken\n",
    "\n",
    "La monotonicità è un principio fondamentale nelle scale di Mokken che descrive la relazione tra la posizione di un individuo su una variabile latente (una caratteristica o tratto non direttamente osservabile) e la probabilità di rispondere correttamente a un item. Questo concetto implica che, man mano che un individuo si colloca a livelli superiori della variabile latente, la sua probabilità di risposta corretta dovrebbe aumentare o almeno rimanere invariata, ma non diminuire. Questo principio si applica sia agli item dicotomici (con due possibili risposte) sia agli item politomici (con multiple risposte).\n",
    "\n",
    "Per valutare la monotonicità, uno dei metodi più utilizzati è l'analisi dei gruppi di restscore. Il \"restscore\" rappresenta il punteggio complessivo ottenuto da una persona in un test, escluso il punteggio dell'item specifico in esame. Ad esempio, in un test di 10 item, se si analizza l'item numero 10, il restscore di un individuo sarà il totale dei punteggi ottenuti negli altri 9 item.\n",
    "\n",
    "I gruppi di restscore sono organizzati in categorie che vanno dal punteggio minimo al massimo possibile, escluso l'item in esame. Nei grafici, questi gruppi sono confrontati con la percentuale di risposte corrette per l'item analizzato in ciascun gruppo. Idealmente, con l'aumentare del restscore, si dovrebbe osservare un incremento o una costanza nella percentuale di risposte corrette. Se le dimensioni dei gruppi di restscore sono piccole, ciò può compromettere l'affidabilità delle stime; in tali casi, è possibile combinare gruppi adiacenti per ottenere campioni più grandi e stime più precise.\n",
    "\n",
    "Il restscore serve come indicatore approssimativo della posizione di un individuo sulla variabile latente $ \\theta $. Se la monotonicità è verificata, ci si aspetta che la percentuale di risposte corrette aumenti o rimanga stabile all'aumentare del restscore, indicando che individui con un restscore più alto hanno maggiori probabilità di rispondere correttamente rispetto a quelli con un restscore più basso.\n",
    "\n",
    "L'analisi IRF è cruciale per esaminare come varia la performance degli item lungo il continuum del tratto latente. A differenza della teoria della risposta all'item (IRT) parametrica, che si concentra sulla stima dei parametri, il NIRT (IRT non parametrico) utilizza metodi grafici per analizzare come gli item funzionano a vari livelli del tratto latente.\n",
    "\n",
    "Per gli item politomici, la monotonicità viene valutata non solo globalmente ma anche all'interno di ogni categoria di risposta. I coefficienti di scalabilità, come $ H_i $ e $ H_{ij} $, sono utilizzati per misurare la monotonicità. Se il Modello di Omogeneità Monotona (MHM) è valido, le covarianze tra tutte le coppie di item ($ H_{ij} $) devono essere non negative. Tuttavia, $ H_{ij} $ non negativi da soli non garantiscono funzioni di risposta non decrescenti e non assicurano un completo adattamento al MHM. Generalmente, item con valori di $ H_i $ superiori a 0.30 sono considerati accettabili.\n",
    "\n",
    "In sintesi, la monotonicità è essenziale per assicurare che le scale di Mokken siano valide e affidabili, e l'analisi dei restscore e delle IRF fornisce gli strumenti necessari per verificare questa proprietà chiave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Il Concetto di Ordinamento Invariante degli Item nei Contesti di Valutazione\n",
    "\n",
    "Nell'ambito della psicometria e della valutazione educativa, definire correttamente la difficoltà degli item di un test è fondamentale. Questa difficoltà viene generalmente stabilita attraverso le medie di risposta degli item osservate nella popolazione target. Tuttavia, è essenziale riconoscere che l'ordine di difficoltà basato su tali medie potrebbe non rimanere costante per ogni individuo.\n",
    "\n",
    "L'Ordinamento Invariante degli Item (IIO) si focalizza sulla consistenza dell'ordine di difficoltà degli item attraverso vari sottogruppi di persone. Questo principio garantisce che i confronti basati sui punteggi totali tra i gruppi siano legittimi e che le differenze osservate nei punteggi riflettano distinzioni reali nelle capacità o nelle caratteristiche misurate. Ad esempio, in test psicologici come quelli che valutano la depressione o l'ansia, l'IIO suggerisce che una persona con un punteggio totale più elevato dovrebbe esibire tutti i sintomi di una con punteggio inferiore, più ulteriori sintomi che riflettono una maggiore severità.\n",
    "\n",
    "L'IIO è cruciale per mantenere una progressione logica e valida degli item in un test, da quelli più facili a quelli più difficili, assicurando che tale scala sia applicabile universalmente ai partecipanti. Se un item è percepito come facile per tutti i partecipanti, e uno difficile rappresenta una sfida per tutti, l'ordinamento degli item è detto invariante.\n",
    "\n",
    "Una violazione dell'IIO può indicare discrepanze nella percezione della difficoltà degli item tra diversi gruppi, il che può evidenziare una funzione differenziale degli item (DIF) o un bias di misurazione. Questo rende problematico ordinare gli item basandosi unicamente sulla loro difficoltà apparente.\n",
    "\n",
    "### Metodi di Valutazione dell'IIO\n",
    "\n",
    "Per verificare l'IIO, si impiegano diverse tecniche analitiche:\n",
    "- **Metodo dei gruppi di restscore**: Analizza se l'ordine di difficoltà degli item rimane costante tra i gruppi formati in base ai punteggi totali escludendo l'item in questione.\n",
    "- **Metodo di divisione degli item**: Esamina la coerenza dell'ordine degli item dividendo il campione in sottogruppi basati su criteri specifici.\n",
    "- **Matrici delle proporzioni P(++)/P(--)**: Queste matrici confrontano le probabilità cumulative di risposta positiva o negativa per valutare se la struttura dell'item è stabile tra i gruppi.\n",
    "- **Metodo di divisione dei restscore**: Simile al metodo dei gruppi di restscore, questo approccio utilizza segmentazioni più dettagliate del punteggio totale per analisi più granulari.\n",
    "\n",
    "L'IIO è vitale sia per la correttezza teorica della misurazione che per l'interpretazione accurata dei risultati dei test. Nonostante la sua importanza, l'IIO è spesso trascurato in pratica. È particolarmente cruciale nei test che intendono riflettere una struttura gerarchica o cumulativa dei tratti. Per ottenere conclusioni affidabili riguardo ai processi cognitivi o evolutivi basati sull'ordine di difficoltà degli item, è indispensabile dimostrare l'invarianza dell'ordinamento degli item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensione del Campione \n",
    "\n",
    "Nel campo della psicometria, determinare la dimensione minima di un campione per i test statistici è un'area ben stabilita. Tuttavia, per quanto riguarda l'Analisi delle Scale Mokken (MSA), questo è un ambito ancora poco esplorato e ci sono pochi studi a riguardo. La ricerca in questo settore è necessaria per evitare sia la capitalizzazione sul caso sia l'utilizzo di campioni eccessivamente grandi, specialmente quando le risorse e il tempo a disposizione dei ricercatori sono limitati.\n",
    "\n",
    "La \"capitalizzazione sul caso\" si riferisce a una condizione in cui una scala di Mokken viene identificata casualmente quando, in realtà, tale scala non esiste e ciò è dovuto alla ridotta dimensione del campione. Al contrario, può anche accadere che una scala esistente non venga identificata.\n",
    "\n",
    "Uno studio condotto da Straat et al. (2014) ha esaminato le dimensioni minime del campione necessarie per l'Automated Item Selection Procedure (AISP) e per l'algoritmo genetico (GA). Lo studio ha valutato l'impatto di diversi fattori, inclusa la lunghezza del test, i valori approssimativi dei coefficienti di scalabilità (Hi) degli item e la correlazione tra le dimensioni nella scala. I risultati hanno evidenziato che la dimensione del campione necessaria dipende da tutti questi fattori. Tuttavia, il fattore più influente è risultato essere il valore di Hi. Con l'aumento di Hi, erano necessarie dimensioni di campione più piccole per assegnare correttamente gli item alle scale appropriate. La lunghezza del test non ha avuto un grande impatto sulla precisione della classificazione degli item nelle scale corrette. Tuttavia, le correlazioni tra le dimensioni hanno avuto qualche effetto in combinazione con vari livelli di Hi. Per valori di Hi intorno a .22, sono necessarie dimensioni di campione di 750-1000 persone per ottenere una precisione mediocre o adeguata, e di 1250-2500 persone per una precisione buona o eccellente. Con valori di Hi di .42, per una precisione mediocre o adeguata sono necessarie dimensioni di campione di 50 persone, mentre per una precisione buona o eccellente, la dimensione del campione dovrebbe essere di almeno 250. Quando le correlazioni tra le due dimensioni erano alte (ad esempio, .60) e i valori di Hi erano .42, erano necessarie dimensioni di campione maggiori per assegnare correttamente gli item alle scale rispetto alla condizione in cui le correlazioni erano .30 o 1.\n",
    "\n",
    "Un altro studio condotto da Watson et al. (2018) ha indagato l'impatto della dimensione del campione sui coefficienti di scalabilità utilizzando dati reali. Hanno estratto campioni di 50, 250, 500, 600, 750 e 1000 persone da un campione più ampio di 7510 persone che hanno risposto a un questionario di 14 item con item a 5 punti Likert. Utilizzando il bootstrapping, hanno estratto 1000 campioni per ogni dimensione del campione. I risultati hanno mostrato che i valori medi di H e Hi non cambiavano notevolmente tra le diverse dimensioni del campione. Tuttavia, considerando gli intervalli di confidenza al 95%, dimensioni di campione più piccole hanno portato a un maggior numero di occasioni in cui il limite inferiore degli intervalli di confidenza al 95% per Hi era inferiore a .30. Ad esempio, per N=50, il numero di volte in cui il limite inferiore degli intervalli di confidenza per Hi era inferiore a .30 era 592, mentre per N=1000, questo numero era zero. Ciò significa che, basandosi sugli errori standard di Hi, quando N=50, in 592 casi su 1000 si dovrebbe rifiutare l'item, concludendo che il suo Hi potrebbe essere inferiore a .30. Tuttavia, i valori medi di Hi per N=50 e N=1000 erano esattamente gli stessi. Questo suggerisce che la dimensione del campione non influisce sulle stime puntuali dei coefficienti di scalabilità, ma gioca un ruolo cruciale quando si considerano gli errori standard dei coefficienti di scalabilità e gli intervalli di confidenza per decidere sulla qualità degli item.\n",
    "\n",
    "In conclusione, questi studi evidenziano l'importanza di considerare la dimensione del campione nell'analisi delle Scale Mokken. Mentre i valori medi di scalabilità possono non variare significativamente con la dimensione del campione, la precisione e l'affidabilità delle stime, così come la capacità di trarre conclusioni affidabili sulla qualità degli item, sono influenzate dalla grandezza del campione. Pertanto, è fondamentale scegliere una dimensione di campione adeguata per garantire risultati validi e affidabili nelle scale di Mokken. Questo è particolarmente critico in situazioni dove risorse e tempo sono limitati, e una scelta accurata della dimensione del campione può contribuire a un utilizzo più efficiente di tali risorse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Il Contributo della MSA alla Validazione dei Test\n",
    "\n",
    "Nell'ambito dell'Analisi delle Scale Mokken (MSA), la validità del modello di omogeneità monotona è cruciale. Questo modello è confermato quando le assunzioni fondamentali di unidimensionalità, monotonicità e indipendenza locale sono rispettate. In particolare, se i coefficienti di scalabilità H, Hi e Hij risultano positivi e significativamente superiori a zero (o meglio ancora, superiori a .30), ciò indica che i dati si conformano efficacemente a una struttura di Guttman. Tale conformità fornisce una forte indicazione dell'esistenza di un costrutto unidimensionale.\n",
    "\n",
    "L'adeguamento al modello di omogeneità monotona implica inoltre la presenza di monotonicità. Ciò significa che deve esistere una relazione non decrescente tra la variabile latente θ e la probabilità di ottenere una risposta corretta. Questo concetto è perfettamente in linea con il secondo criterio di validità nell'approccio basato sugli strumenti, secondo il quale variazioni nel tratto latente dovrebbero produrre variazioni corrispondenti nelle risposte agli item.\n",
    "\n",
    "Un'ulteriore dimensione della MSA è il modello di doppia monotonicità, che introduce l'assunzione dell'Ordinamento Invariante degli Item (IIO). Secondo questa assunzione, le Funzioni di Risposta all'Item (IRF) degli item di un test non dovrebbero intersecarsi. Anche se una sua violazione non rende di per sé un test invalido secondo l'approccio basato sugli strumenti, la conformità all'IIO migliora notevolmente l'interpretabilità dei punteggi del test. Inoltre, la violazione dell'IIO è analoga alla presenza di funzione differenziale dell'item (DIF) nei modelli IRT parametrici.\n",
    "\n",
    "In conclusione, la MSA si rivela uno strumento estremamente utile e potente per la validazione di test in ambiti psicologici ed educativi. La capacità della MSA di confermare il modello di omogeneità monotona attraverso i coefficienti di scalabilità offre una valida evidenza che i test misurano effettivamente il costrutto unidimensionale che intendono valutare. Questo aspetto è fondamentale per garantire che i punteggi dei test riflettano veramente le capacità o le caratteristiche misurate.\n",
    "\n",
    "L'incorporazione dell'Ordinamento Invariante degli Item (IIO) nel modello di doppia monotonicità aggiunge un ulteriore livello di rigorosità. Assicurandosi che le IRF degli item non si intersechino, si aumenta la precisione con cui il test misura il costrutto e si migliora l'interpretazione dei punteggi. Questo approccio riduce il rischio di bias e garantisce che il test sia equamente rappresentativo per tutti i partecipanti, indipendentemente dalle loro caratteristiche individuali.\n",
    "\n",
    "Inoltre, la MSA fornisce una base solida per affermare che le variazioni nei punteggi dei test sono effettivamente causate da variazioni nel costrutto misurato. Questa caratteristica rende la MSA particolarmente preziosa in contesti dove è essenziale dimostrare una relazione causale tra il costrutto e i punteggi del test.\n",
    "\n",
    "In sintesi, l'impiego della MSA nella validazione dei test non solo rafforza la fiducia nella precisione e nell'affidabilità dei test stessi, ma contribuisce anche a una maggiore chiarezza e trasparenza nell'interpretazione dei risultati. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critiche alla MSA\n",
    "\n",
    "Negli anni '80, l'Analisi delle Scale Mokken (MSA) è stata criticata per la limitata applicabilità del coefficiente di scalabilità H, ritenuto dipendente dalle caratteristiche del campione e degli item, e non adeguato come misura di adattamento del modello. Ulteriori critiche hanno riguardato il coefficiente di scalabilità degli item Hi, accusato di selezionare solo item con IRF ripide e distanti, escludendo item validi e riducendo la varianza e l'affidabilità del test. I critici hanno anche messo in dubbio l'adeguatezza della MSA per l'ordinamento libero degli item secondo il rango latente, suggerendo una possibile necessità del modello di Rasch.\n",
    "\n",
    "In risposta, i difensori della MSA hanno sottolineato che le critiche si basano su una lettura selettiva e una mancata comprensione dei modelli non parametrici. Hanno ribadito che H e Hi sono intesi come misure dell'omogeneità monotona, e non come indici di doppia monotonia, e che la dipendenza di H dalla varianza della popolazione è in linea con le assunzioni del modello. Questo dibattito evidenzia l'importanza di valutare attentamente i metodi statistici come la MSA nel loro contesto di applicazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerazioni Conclusive\n",
    "\n",
    "In questo capitolo, abbiamo esplorato una questione fondamentale nella misurazione psicologica: l'efficacia dei punteggi totali grezzi nell'ordinare gli esaminandi. Tradizionalmente, tali punteggi vengono utilizzati per classificare i soggetti, da quelli più competenti a quelli meno competenti, da quelli più ansiosi a quelli meno ansiosi, o da quelli più depressi a quelli meno depressi. Sebbene sia comunemente accettato che i punteggi grezzi siano dati su scala ordinale, molti ricercatori li trattano come se fossero su scala intervallo. Ciò significa che, utilizzando i punteggi grezzi, si può solamente stabilire l'ordine dei rispondenti, ma non discernere le differenze tra di loro.\n",
    "\n",
    "Il tema principale affrontato in questo capitolo è che i punteggi grezzi potrebbero non essere nemmeno dati ordinali. In altre parole, i punteggi totali grezzi potrebbero non essere sufficientemente affidabili per ordinare gli esaminandi. Affinché i punteggi grezzi siano considerati ordinali, i pattern di risposta devono adattarsi al Modello di Omogeneità Monotona (MHM). Nella teoria classica dei test, si assume che i punteggi totali siano ordinali senza verificarlo. Il MHM, come modello IRT non parametrico, ci permette di testare se i punteggi totali rispettano l'assioma di una scala ordinale. Lo stesso vale per gli item: l'adattamento al Modello di Doppia Monotonicità (DMM) ci permette di ordinare gli item in base alle loro proporzioni di risposte corrette (valore p).\n",
    "\n",
    "In questo capitolo, abbiamo discusso le procedure conosciute collettivamente come Analisi delle Scale Mokken, per testare l'adattamento dei dati al MHM e al DMM. Queste analisi offrono strumenti preziosi per verificare l'affidabilità e la validità dei punteggi totali grezzi utilizzati in una vasta gamma di contesti psicologici."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
