

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>2. L’analisi di regressione &#8212; cfa_book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '010_regression';</script>
    <link rel="shortcut icon" href="_static/increasing.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3. Fondamenti teorici" href="035_ctt.html" />
    <link rel="prev" title="1. Linguaggio di programmazione R" href="05_intro_r.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Modello lineare</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="05_intro_r.html">1. Linguaggio di programmazione R</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">2. L’analisi di regressione</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Teoria classica dei test</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="035_ctt.html">3. Fondamenti teorici</a></li>
<li class="toctree-l1"><a class="reference internal" href="037_err_std_mis.html">4. L’errore standard della misurazione</a></li>
<li class="toctree-l1"><a class="reference internal" href="038_err_std_stima.html">5. La stima del punteggio vero</a></li>
<li class="toctree-l1"><a class="reference internal" href="040_exercises_ctt.html">6. Applicazioni della CTT</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Analisi fattoriale</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="050_sviluppo_strumento.html">7. Utilizzo e costruzione di test psicometrici</a></li>
<li class="toctree-l1"><a class="reference internal" href="055_analisi_fattoriale_1.html">8. Il modello unifattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="056_analisi_fattoriale_2.html">9. Il modello statistico dell’analisi fattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="057_analisi_fattoriale_3.html">10. Il modello multifattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="058_factor_scores.html">11. I punteggi fattoriali</a></li>
<li class="toctree-l1"><a class="reference internal" href="060_path_analysis.html">12. Visualizzare i modelli di equazioni strutturali</a></li>
<li class="toctree-l1"><a class="reference internal" href="062_constraints_on_parms.html">13. Attendibilità e modello fattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="070_cfa_mod_comp.html">14. CFA: confronto tra modelli</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Costruzione di strumenti psicometrici</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="200_problema_strumento.html">15. Tipologie dei test psicometrici</a></li>
<li class="toctree-l1"><a class="reference internal" href="201_valutare_le_matrici.html">16. Valutazione della matrice di correlazione</a></li>
<li class="toctree-l1"><a class="reference internal" href="202_estrazione.html">17. L’estrazione dei fattori</a></li>
<li class="toctree-l1"><a class="reference internal" href="203_numero_fattori.html">18. Il numero dei fattori</a></li>
<li class="toctree-l1"><a class="reference internal" href="205_rotazione.html">19. La rotazione fattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="206_valutare_sol_fattoriale.html">20. Valutare e rifinire la soluzione fattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="250_group_invariance.html">21. Invarianza di misura</a></li>
<li class="toctree-l1"><a class="reference internal" href="300_gof.html">22. Indici di bontà dell’adattamento</a></li>
<li class="toctree-l1"><a class="reference internal" href="310_refine_solution.html">23. La revisione del modello</a></li>
<li class="toctree-l1"><a class="reference internal" href="315_mmm.html">24. CFA per matrici multi-tratto multi-metodo</a></li>
<li class="toctree-l1"><a class="reference internal" href="500_cat_data.html">25. Dati non gaussiani e categoriali</a></li>
<li class="toctree-l1"><a class="reference internal" href="501_missing_data.html">26. Dati mancanti</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Modelli di equazioni strutturali</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="316_sem_intro.html">27. Introduzione ai modelli di equazioni struttural</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Curve di crescita latente</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="320_lgm_intro.html">28. Curve di crescita latente</a></li>
<li class="toctree-l1"><a class="reference internal" href="321_lgm_prelims.html">29. Dati longitudinali</a></li>
<li class="toctree-l1"><a class="reference internal" href="324_lgm_mixed.html">30. LGM e modelli misti</a></li>
<li class="toctree-l1"><a class="reference internal" href="326_growth_1.html">31. Curve di crescita latente</a></li>
<li class="toctree-l1"><a class="reference internal" href="327_growth_cont.html">32. Il tempo su una metrica continua</a></li>
<li class="toctree-l1"><a class="reference internal" href="328_time_inv_cov.html">33. Covariate indipendenti dal tempo</a></li>
<li class="toctree-l1"><a class="reference internal" href="329_growth_groups.html">34. Modelli di crescita latenti a gruppi multipli</a></li>
<li class="toctree-l1"><a class="reference internal" href="330_bivariate_growth_models.html">35. Modelli di crescita latenti bivariati</a></li>
<li class="toctree-l1"><a class="reference internal" href="331_inv_measurement.html">36. Invarianza di misurazione</a></li>
<li class="toctree-l1"><a class="reference internal" href="332_latent_change.html">37. Modello LCS univariato</a></li>
<li class="toctree-l1"><a class="reference internal" href="333_biv_change.html">38. Modello LCS bivariato</a></li>
<li class="toctree-l1"><a class="reference internal" href="351_lgm_meas_inv.html">39. Invarianza fattoriale nei modelli LGM</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bibliografia</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="z_biblio.html">40. Bibliografia</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendici</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="900_lin_alg.html">41. Elementi di algebra lineare</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ccaudek/cfa_book_2023" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ccaudek/cfa_book_2023/issues/new?title=Issue%20on%20page%20%2F010_regression.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/010_regression.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>L’analisi di regressione</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regressione-bivariata">2.1. Regressione bivariata</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regressori-centrati">2.1.1. Regressori centrati</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#minimi-quadrati">2.1.2. Minimi quadrati</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relazione-tra-b-e-r">2.1.3. Relazione tra <span class="math notranslate nohighlight">\(b\)</span> e <span class="math notranslate nohighlight">\(r\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#attenuazione">2.1.4. Attenuazione</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coefficiente-di-determinazione">2.1.5. Coefficiente di determinazione</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-standard-della-regressione">2.1.6. Errore standard della regressione</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regressione-multipla">2.2. Regressione multipla</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#significato-dei-coefficienti-parziali-di-regressione">2.2.1. Significato dei coefficienti parziali di regressione</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relazioni-causali">2.2.2. Relazioni causali</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-di-specificazione">2.2.3. Errore di specificazione</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#soppressione">2.2.4. Soppressione</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stepwise-regression">2.2.5. Stepwise regression</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proprieta-degli-stimatori-dei-minimi-quadrati">2.3. Proprietà degli stimatori dei minimi quadrati</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ipotesi-statistiche-e-statistica-test">2.3.1. Ipotesi statistiche e statistica test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#riportare-i-risultati">2.3.2. Riportare i risultati</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#regola-di-decisione">2.3.2.1. Regola di decisione</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#considerazioni-conclusive">2.3.3. Considerazioni conclusive</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="l-analisi-di-regressione">
<h1><span class="section-number">2. </span>L’analisi di regressione<a class="headerlink" href="#l-analisi-di-regressione" title="Permalink to this headline">#</a></h1>
<p>La padronanza dell’analisi di regressione è fondamentale per comprendere la teoria classica dei test, l’analisi fattoriale e i modelli di equazioni strutturali. Sebbene le tecniche di analisi di regressione si concentrino esclusivamente sulle variabili osservate, i principi della regressione costituiscono la base per tecniche più avanzate che incorporano anche le variabili latenti. Questo capitolo fornisce una sintesi dei concetti fondamentali.</p>
<section id="regressione-bivariata">
<h2><span class="section-number">2.1. </span>Regressione bivariata<a class="headerlink" href="#regressione-bivariata" title="Permalink to this headline">#</a></h2>
<p>Il modello di regressione bivariata descrive l’associazione tra il valore atteso di <span class="math notranslate nohighlight">\(Y \mid x_i\)</span> e <span class="math notranslate nohighlight">\(x\)</span> nei termini di una relazione lineare:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}(Y \mid x_i) = \alpha + \beta x_i,
\]</div>
<p>dove i valori <span class="math notranslate nohighlight">\(x_i\)</span> sono considerati fissi per disegno. Nel modello “classico”, si assume che le distribuzioni <span class="math notranslate nohighlight">\(Y \mid x_i\)</span> siano Normali con deviazione standard <span class="math notranslate nohighlight">\(\sigma_\varepsilon\)</span>.</p>
<p>Il significato dei coefficienti di regressione è semplice:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span> è il valore atteso di <span class="math notranslate nohighlight">\(Y\)</span> quando <span class="math notranslate nohighlight">\(X = 0\)</span>;</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta\)</span> è l’incremento atteso nel valore atteso di <span class="math notranslate nohighlight">\(Y\)</span> quando <span class="math notranslate nohighlight">\(X\)</span> aumenta di un’unità.</p></li>
</ul>
<p>Il modello statistico della regressione bivariata è rappresentato nella figura seguente.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<img alt="_images/6704838f98272e3e7969fcd5d2a0c9716257d7c8b5bcd997b5dfaaa66a6fb61b.png" src="_images/6704838f98272e3e7969fcd5d2a0c9716257d7c8b5bcd997b5dfaaa66a6fb61b.png" />
</div>
</div>
<p>Per fare un esempio pratico, consideriamo i dati dell’antropologo Sahlins, il quale si è chiesto se esiste un’associazione tra l’ampiezza del clan (<code class="docutils literal notranslate"><span class="pre">consumers</span></code>) e l’area occupata da quel clan (<code class="docutils literal notranslate"><span class="pre">acres</span></code>) in una popolazione di cacciatori-raccoglitori. I dati sono i seguenti:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="p">(</span><span class="n">Sahlins</span><span class="p">)</span>
<span class="n">head</span><span class="p">(</span><span class="n">Sahlins</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A data.frame: 6 × 2</caption>
<thead>
	<tr><th></th><th scope=col>consumers</th><th scope=col>acres</th></tr>
	<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>1</th><td>1.00</td><td>1.71</td></tr>
	<tr><th scope=row>2</th><td>1.08</td><td>1.52</td></tr>
	<tr><th scope=row>3</th><td>1.15</td><td>1.29</td></tr>
	<tr><th scope=row>4</th><td>1.15</td><td>3.09</td></tr>
	<tr><th scope=row>5</th><td>1.20</td><td>2.21</td></tr>
	<tr><th scope=row>6</th><td>1.30</td><td>2.26</td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">options</span><span class="p">(</span><span class="nb">repr</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">width</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="nb">repr</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">height</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">Sahlins</span> <span class="o">%&gt;%</span> 
  <span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">consumers</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">acres</span><span class="p">))</span> <span class="o">+</span>
  <span class="n">geom_point</span><span class="p">()</span> <span class="o">+</span>
  <span class="n">geom_smooth</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">lm</span><span class="p">,</span> <span class="n">se</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>`geom_smooth()` using formula = &#39;y ~ x&#39;
</pre></div>
</div>
<img alt="_images/25fa4705c865f8a01afc7d89a2d661683686a6d352901c40fa757747664efd02.png" src="_images/25fa4705c865f8a01afc7d89a2d661683686a6d352901c40fa757747664efd02.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fm &lt;- lm(acres ~ consumers, data = Sahlins)
fm$coef
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.dl-inline {width: auto; margin:0; padding: 0}
.dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}
.dl-inline>dt::after {content: ":\0020"; padding-right: .5ex}
.dl-inline>dt:not(:first-of-type) {padding-left: .5ex}
</style><dl class=dl-inline><dt>(Intercept)</dt><dd>1.37564454847979</dd><dt>consumers</dt><dd>0.516320060092059</dd></dl>
</div></div>
</div>
<p>Dalla figura notiamo che, se <code class="docutils literal notranslate"><span class="pre">consumers</span></code> aumenta di un’unità (da 1.2 a 2.2), allora la retta di regressione (ovvero, il valore atteso di <span class="math notranslate nohighlight">\(Y\)</span>) aumenta di circa 0.5 punti – esattamente, aumenta di 0.5163 punti, come indicato dalla stima del coefficiente <span class="math notranslate nohighlight">\(\beta\)</span>. L’interpretazione del coefficiente <span class="math notranslate nohighlight">\(\alpha\)</span> è più problematica, perché non ha senso pensare ad un clan di ampiezza 0. Per affrontare questo problema, centriamo il predittore.</p>
<section id="regressori-centrati">
<h3><span class="section-number">2.1.1. </span>Regressori centrati<a class="headerlink" href="#regressori-centrati" title="Permalink to this headline">#</a></h3>
<p>Esprimiamo la variabile <code class="docutils literal notranslate"><span class="pre">consumers</span></code> nei termini degli scarti dalla media:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Sahlins</span> <span class="o">&lt;-</span> <span class="n">Sahlins</span> <span class="o">%&gt;%</span> 
  <span class="n">mutate</span><span class="p">(</span>
    <span class="n">xc</span> <span class="o">=</span> <span class="n">consumers</span> <span class="o">-</span> <span class="n">mean</span><span class="p">(</span><span class="n">consumers</span><span class="p">)</span>
  <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Svolgiamo nuovamente l’analisi di regressione con il nuovo predittore:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fm1 &lt;- lm(acres ~ xc, data = Sahlins)
fm1$coef
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.dl-inline {width: auto; margin:0; padding: 0}
.dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}
.dl-inline>dt::after {content: ":\0020"; padding-right: .5ex}
.dl-inline>dt:not(:first-of-type) {padding-left: .5ex}
</style><dl class=dl-inline><dt>(Intercept)</dt><dd>2.162</dd><dt>xc</dt><dd>0.51632006009206</dd></dl>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Sahlins</span> <span class="o">%&gt;%</span> 
  <span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">xc</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">acres</span><span class="p">))</span> <span class="o">+</span>
  <span class="n">geom_point</span><span class="p">()</span> <span class="o">+</span>
  <span class="n">geom_smooth</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">lm</span><span class="p">,</span> <span class="n">se</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>`geom_smooth()` using formula = &#39;y ~ x&#39;
</pre></div>
</div>
<img alt="_images/e93649aa872cec9af45d774cd7bfb8a648a3d9b089f438106324fe1484280200.png" src="_images/e93649aa872cec9af45d774cd7bfb8a648a3d9b089f438106324fe1484280200.png" />
</div>
</div>
<p>La stima di <span class="math notranslate nohighlight">\(\beta\)</span> è rimasta invariata ma ora possiamo attribuire un significato alla stima di <span class="math notranslate nohighlight">\(\alpha\)</span>: questo coefficiente indica il valore atteso della <span class="math notranslate nohighlight">\(Y\)</span> quando <span class="math notranslate nohighlight">\(X\)</span> assume il suo valore medio.</p>
</section>
<section id="minimi-quadrati">
<h3><span class="section-number">2.1.2. </span>Minimi quadrati<a class="headerlink" href="#minimi-quadrati" title="Permalink to this headline">#</a></h3>
<p>La stima dei coefficienti del modello di regressione può essere effettuata in modi diversi: massima verosimiglianza o metodi bayesiani. Se ci limitiamo qui alla massima verosimiglianza possiamo semplificare il problema assumento che le distribuzioni condizionate <span class="math notranslate nohighlight">\(Y \mid x\)</span> siano Normali. In tali circostanze, la stima dei coefficienti del modello di regressione può essere trovata con il metodo dei minimi quadrati.</p>
<p>In pratica, questo significa trovare i coefficienti <span class="math notranslate nohighlight">\(a\)</span> e <span class="math notranslate nohighlight">\(b\)</span> che minimizzano</p>
<div class="math notranslate nohighlight">
\[
SS_{\text{res}} = \sum(y_i - \hat{y}_i)^2,
\]</div>
<p>con <span class="math notranslate nohighlight">\(\hat{y}_i = a + b x_i\)</span>.</p>
<p>Per fornire un’idea di come questo viene fatto, usiamo una simulazione. Per semplicità, supponiamo di conoscere <span class="math notranslate nohighlight">\(a = 1.3756445\)</span> e di volere stimare <span class="math notranslate nohighlight">\(b\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>x &lt;- Sahlins$consumers
y &lt;- Sahlins$acres
a &lt;- 1.3756445

nrep &lt;- 1e3
b &lt;- seq(0, 1, length.out = nrep)

ssres &lt;- rep(NA, nrep)
for (i in 1:nrep) {
  yhat &lt;- a + b[i] * x
  ssres[i] &lt;- sum((y - yhat)^2)
}
</pre></div>
</div>
</div>
</div>
<p>Un grafico di <span class="math notranslate nohighlight">\(SS_{\text{res}}\)</span> in funzione di <span class="math notranslate nohighlight">\(b\)</span> mostra che il valore <span class="math notranslate nohighlight">\(b\)</span> che minimizza <span class="math notranslate nohighlight">\(SS_{\text{res}}\)</span> corrisponde, appunto, a 0.5163.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tibble</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">ssres</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">b</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">ssres</span><span class="p">))</span> <span class="o">+</span>
  <span class="n">geom_line</span><span class="p">()</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a24b38d11305ab54fc3b2fa9cab6225c16cf31d5d508dd963beec2e1a60faabe.png" src="_images/a24b38d11305ab54fc3b2fa9cab6225c16cf31d5d508dd963beec2e1a60faabe.png" />
</div>
</div>
</section>
<section id="relazione-tra-b-e-r">
<h3><span class="section-number">2.1.3. </span>Relazione tra <span class="math notranslate nohighlight">\(b\)</span> e <span class="math notranslate nohighlight">\(r\)</span><a class="headerlink" href="#relazione-tra-b-e-r" title="Permalink to this headline">#</a></h3>
<p>Un altro modo per interpretare <span class="math notranslate nohighlight">\(b\)</span> è quello di considerare la relazione tra la pendenza della retta di regressione e il coefficiente di correlazione:</p>
<div class="math notranslate nohighlight">
\[
b_X = r_{XY} \frac{S_X}{S_Y}
\]</div>
<p>L’equazione precedente rende chiaro che, se i dati sono standardizzati, <span class="math notranslate nohighlight">\(b = r\)</span>.</p>
<p>Verifichiamo:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Sahlins</span> <span class="o">%&gt;%</span> 
  <span class="n">dplyr</span><span class="p">::</span><span class="n">select</span><span class="p">(</span><span class="n">acres</span><span class="p">,</span> <span class="n">consumers</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="n">cor</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A matrix: 2 × 2 of type dbl</caption>
<thead>
	<tr><th></th><th scope=col>acres</th><th scope=col>consumers</th></tr>
</thead>
<tbody>
	<tr><th scope=row>acres</th><td>1.0000000</td><td>0.3756561</td></tr>
	<tr><th scope=row>consumers</th><td>0.3756561</td><td>1.0000000</td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fm2 &lt;- lm(scale(acres) ~ scale(consumers), data = Sahlins)
fm2$coef
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.dl-inline {width: auto; margin:0; padding: 0}
.dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}
.dl-inline>dt::after {content: ":\0020"; padding-right: .5ex}
.dl-inline>dt:not(:first-of-type) {padding-left: .5ex}
</style><dl class=dl-inline><dt>(Intercept)</dt><dd>9.91710589115135e-17</dd><dt>scale(consumers)</dt><dd>0.375656119968214</dd></dl>
</div></div>
</div>
</section>
<section id="attenuazione">
<h3><span class="section-number">2.1.4. </span>Attenuazione<a class="headerlink" href="#attenuazione" title="Permalink to this headline">#</a></h3>
<p>Il fenomeno dell’attenuazione si verifica quando <span class="math notranslate nohighlight">\(X\)</span> viene misurato con una componente di errore. Esaminiamo la seguente simulazione.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">n</span> <span class="o">&lt;-</span> <span class="mi">100</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="n">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
<span class="n">y</span> <span class="o">&lt;-</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">tibble</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span> <span class="o">+</span>
  <span class="n">geom_point</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7d9dbbff8886a40b8ac2540a480f881a6cffcc09227c028b9472b026ebb8000a.png" src="_images/7d9dbbff8886a40b8ac2540a480f881a6cffcc09227c028b9472b026ebb8000a.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sim_dat &lt;- tibble(x, y)
fm &lt;- lm(y ~ x, sim_dat)
fm$coef
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.dl-inline {width: auto; margin:0; padding: 0}
.dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}
.dl-inline>dt::after {content: ":\0020"; padding-right: .5ex}
.dl-inline>dt:not(:first-of-type) {padding-left: .5ex}
</style><dl class=dl-inline><dt>(Intercept)</dt><dd>0.422107439446964</dd><dt>x</dt><dd>1.46522006762439</dd></dl>
</div></div>
</div>
<p>Questi sono i coefficienti di regressione quando <span class="math notranslate nohighlight">\(X\)</span> è misurata senza errori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sim_dat &lt;- sim_dat %&gt;% 
  mutate(
    x1 = x + rnorm(n, 0, 2)
  )

fm1 &lt;- lm(y ~ x1, sim_dat)
fm1$coef
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.dl-inline {width: auto; margin:0; padding: 0}
.dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}
.dl-inline>dt::after {content: ":\0020"; padding-right: .5ex}
.dl-inline>dt:not(:first-of-type) {padding-left: .5ex}
</style><dl class=dl-inline><dt>(Intercept)</dt><dd>8.38721756937908</dd><dt>x1</dt><dd>0.629592427655326</dd></dl>
</div></div>
</div>
<p>Aggiungendo una componente d’errore su <span class="math notranslate nohighlight">\(X\)</span>, la grandezza del coefficiente <span class="math notranslate nohighlight">\(b\)</span> diminuisce.</p>
</section>
<section id="coefficiente-di-determinazione">
<h3><span class="section-number">2.1.5. </span>Coefficiente di determinazione<a class="headerlink" href="#coefficiente-di-determinazione" title="Permalink to this headline">#</a></h3>
<p>Tecnicamente, il coefficiente di determinazione è dato da:</p>
<div class="math notranslate nohighlight">
\[
R^2 = \frac{\sum(\hat{y} - \bar{y})^2}{\sum(y_i - \bar{y})^2}
\]</div>
<p>Al denominatore abbiamo la <em>devianza totale</em>, ovvero una misura della dispersione di <span class="math notranslate nohighlight">\(y_i\)</span> rispetto alla media <span class="math notranslate nohighlight">\(\bar{y}\)</span>. Al numeratore abbiamo una misura della dispersione del valore atteso della <span class="math notranslate nohighlight">\(Y\)</span> rispetto alla sua media. Il rapporto, dunque, ci dice qual è la quota della variabilità totale di <span class="math notranslate nohighlight">\(Y\)</span> che può essere predetta in base al modello lineare.</p>
<p>Per i dati di Sahlins abbiamo:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>mod &lt;- lm(acres ~ consumers, data = Sahlins)
a &lt;- mod$coef[1]
b &lt;- mod$coef[2]
yhat &lt;- a + b * Sahlins$consumers
ss_tot &lt;- sum((Sahlins$acres - mean(Sahlins$acres))^2)
ss_reg &lt;- sum((yhat - mean(Sahlins$acres))^2)
r2 &lt;- ss_reg / ss_tot
r2
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">0.141117520469573</div></div>
</div>
<p>Verifichiamo:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">(</span><span class="n">mod</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = acres ~ consumers, data = Sahlins)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.8763 -0.1873 -0.0211  0.2135  1.1206 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)   1.3756     0.4684   2.937  0.00881 **
consumers     0.5163     0.3002   1.720  0.10263   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.4543 on 18 degrees of freedom
Multiple R-squared:  0.1411,	Adjusted R-squared:  0.0934 
F-statistic: 2.957 on 1 and 18 DF,  p-value: 0.1026
</pre></div>
</div>
</div>
</div>
<p>Da cui deriva che <span class="math notranslate nohighlight">\(R^2\)</span> è uguale al quadrato del coefficiente di correlazione:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>cor(Sahlins$acres, Sahlins$consumers)^2
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">0.141117520469573</div></div>
</div>
</section>
<section id="errore-standard-della-regressione">
<h3><span class="section-number">2.1.6. </span>Errore standard della regressione<a class="headerlink" href="#errore-standard-della-regressione" title="Permalink to this headline">#</a></h3>
<p>L’errore standard della regressione è una stima della dispersione di <span class="math notranslate nohighlight">\(y \mid x_i\)</span> nella popolazione.  Non è altro che la deviazione standard dei residui</p>
<div class="math notranslate nohighlight">
\[
e = y_i - \hat{y}_i
\]</div>
<p>che, al denominatore, riporta <span class="math notranslate nohighlight">\(n-2\)</span>. La ragione è che, per calcolare <span class="math notranslate nohighlight">\(\hat{y}\)</span>, vengono “perduti” due gradi di libertà – il calcolo di <span class="math notranslate nohighlight">\(\hat{y}\)</span> è basato sulla stima di due coefficienti: <span class="math notranslate nohighlight">\(a\)</span> e <span class="math notranslate nohighlight">\(b\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>e &lt;- yhat - Sahlins$acres
(sum(e^2) / (length(Sahlins$acres) - 2)) %&gt;% 
  sqrt()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">0.454317872037872</div></div>
</div>
<p>Il valore trovato corrisponde a quello riportato nell’output di <code class="docutils literal notranslate"><span class="pre">lm()</span></code>.</p>
</section>
</section>
<section id="regressione-multipla">
<h2><span class="section-number">2.2. </span>Regressione multipla<a class="headerlink" href="#regressione-multipla" title="Permalink to this headline">#</a></h2>
<p>Nella regressione multipla vengono utilizzati <span class="math notranslate nohighlight">\(k &gt; 1\)</span> predittori:</p>
<div class="math notranslate nohighlight">
\[
y_i = \alpha + \sum_{j=1}^k \beta_j x_i + \varepsilon_i.
\]</div>
<p>L’interpretazione geometrica è simile a quella del modello bivariato. Nel caso di due predittori, il valore atteso della <span class="math notranslate nohighlight">\(y\)</span> può essere rappresentato da un piano; nel caso di <span class="math notranslate nohighlight">\(k &gt; 2\)</span> predittori, da un iper-piano. Nel caso di <span class="math notranslate nohighlight">\(k=2\)</span>, tale piano è posto in uno spazio di dimensioni <span class="math notranslate nohighlight">\(x_1\)</span>, <span class="math notranslate nohighlight">\(x_2\)</span> (che possiamo immaginare definire un piano orizzontale) e <span class="math notranslate nohighlight">\(y\)</span> (ortogonale a tale piano). La superficie piana che rappresenta <span class="math notranslate nohighlight">\(\mathbb{E}(y)\)</span> è inclinata in maniera tale che l’angolo tra il piano e l’asse <span class="math notranslate nohighlight">\(x_1\)</span> corrisponde a <span class="math notranslate nohighlight">\(\beta_1\)</span> e l’angolo tra il piano e l’asse <span class="math notranslate nohighlight">\(x_2\)</span> corrisponde a <span class="math notranslate nohighlight">\(\beta_2\)</span>.</p>
<section id="significato-dei-coefficienti-parziali-di-regressione">
<h3><span class="section-number">2.2.1. </span>Significato dei coefficienti parziali di regressione<a class="headerlink" href="#significato-dei-coefficienti-parziali-di-regressione" title="Permalink to this headline">#</a></h3>
<p>Ai coefficienti parziali del modello di regressione multipla possiamo assegnare la seguente interpretazione:</p>
<p><em>Il coefficiente parziale di regressione <span class="math notranslate nohighlight">\(\beta_j\)</span> rappresenta l’incremento atteso della <span class="math notranslate nohighlight">\(y\)</span> se <span class="math notranslate nohighlight">\(x_j\)</span> viene incrementata di un’unità, tenendo costante il valore delle altre variabili indipendenti.</em></p>
<p>Un modo per interpretare la locuzione “al netto dell’effetto delle altre variabili indipendenti” è quello di esaminare la relazione tra la <span class="math notranslate nohighlight">\(y\)</span> parzializzata e la <span class="math notranslate nohighlight">\(x_j\)</span> parzializzata. In questo contesto, parzializzare significa decomporre una variabile di due componenti: una componente che è linearmente predicibile da una o più altre variabili e una componente che è linearmente incorrelata con tali varibili “terze”.</p>
<p>Se eseguiamo questa “depurazione” dell’effetto delle variabili “terze” sia sulla <span class="math notranslate nohighlight">\(y\)</span> sia su <span class="math notranslate nohighlight">\(x_j\)</span>, possiamo poi esaminare la relazione bivariata che intercorre tra la componente della <span class="math notranslate nohighlight">\(y\)</span> linearmente indipendente dalle variabili “terze” e la componente della <span class="math notranslate nohighlight">\(x_j\)</span> linearmente indipendente dalle variabili “terze”. Il coefficiente di regressione bivariato così ottenuto sarà identico al coefficiente parziale di regressione nel modello di regressione multipla. Questa procedura ci consente di assegnare un’interpretazione “intuitiva” al coefficiente parziale di regressione <span class="math notranslate nohighlight">\(\beta_j\)</span>.</p>
<p>Esaminiamo un caso concreto.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d</span> <span class="o">&lt;-</span> <span class="n">rio</span><span class="p">::</span><span class="n">import</span><span class="p">(</span><span class="s2">&quot;data/kidiq.dta&quot;</span><span class="p">)</span>
<span class="n">glimpse</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Rows: 434
Columns: 5
$ kid_score &lt;dbl&gt; 65, 98, 85, 83, 115, 98, 69, 106, 102, 95, 91, 58, 84, 78, 1…
$ mom_hs    &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, …
$ mom_iq    &lt;dbl&gt; 121.11753, 89.36188, 115.44316, 99.44964, 92.74571, 107.9018…
$ mom_work  &lt;dbl&gt; 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 4, 2, 1, 3, 3, 4, 3, …
$ mom_age   &lt;dbl&gt; 27, 25, 27, 25, 27, 18, 20, 23, 24, 19, 23, 24, 27, 26, 24, …
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fm &lt;- lm(
  kid_score ~ mom_iq + mom_work + mom_age + mom_hs, data = d
)
fm$coef
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.dl-inline {width: auto; margin:0; padding: 0}
.dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}
.dl-inline>dt::after {content: ":\0020"; padding-right: .5ex}
.dl-inline>dt:not(:first-of-type) {padding-left: .5ex}
</style><dl class=dl-inline><dt>(Intercept)</dt><dd>20.8226117032724</dd><dt>mom_iq</dt><dd>0.562081421559238</dd><dt>mom_work</dt><dd>0.133728709291299</dd><dt>mom_age</dt><dd>0.219859856510774</dd><dt>mom_hs</dt><dd>5.56117805423644</dd></dl>
</div></div>
</div>
<p>Eseguiamo la parzializzazione di <span class="math notranslate nohighlight">\(y\)</span> in funzione delle variabili <code class="docutils literal notranslate"><span class="pre">mom_work</span></code>, <code class="docutils literal notranslate"><span class="pre">mom_age</span></code> e <code class="docutils literal notranslate"><span class="pre">mom_hs</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fm_y</span> <span class="o">&lt;-</span> <span class="n">lm</span><span class="p">(</span><span class="n">kid_score</span> <span class="o">~</span> <span class="n">mom_work</span> <span class="o">+</span> <span class="n">mom_age</span> <span class="o">+</span> <span class="n">mom_hs</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Lo stesso per <code class="docutils literal notranslate"><span class="pre">mom_iq</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fm_x</span> <span class="o">&lt;-</span> <span class="n">lm</span><span class="p">(</span><span class="n">mom_iq</span> <span class="o">~</span> <span class="n">mom_work</span> <span class="o">+</span> <span class="n">mom_age</span> <span class="o">+</span> <span class="n">mom_hs</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Esaminiamo ora la regressione bivariata tra le componenti parzializzate della <span class="math notranslate nohighlight">\(y\)</span> e di <span class="math notranslate nohighlight">\(x_j\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>mod &lt;- lm(fm_y$residuals ~ fm_x$residuals)
mod$coef
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.dl-inline {width: auto; margin:0; padding: 0}
.dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}
.dl-inline>dt::after {content: ":\0020"; padding-right: .5ex}
.dl-inline>dt:not(:first-of-type) {padding-left: .5ex}
</style><dl class=dl-inline><dt>(Intercept)</dt><dd>-1.65185057983985e-15</dd><dt>fm_x$residuals</dt><dd>0.562081421559238</dd></dl>
</div></div>
</div>
<p>Si vede come il coefficiente di regressione bivariato risulta identico al corrispondente coefficiente parziale di regressione.</p>
</section>
<section id="relazioni-causali">
<h3><span class="section-number">2.2.2. </span>Relazioni causali<a class="headerlink" href="#relazioni-causali" title="Permalink to this headline">#</a></h3>
<p>Un altro modo per interpretare i coefficienti parziali di regressione è nell’ambito dei quelli che vengono chiamati i <em>path diagrams</em>. I diagrammi di percorso, che tratteremo in seguito e qui solo anticipiamo, descrivono le relazioni “causali” tra variabili: le variabili a monte del diagramma di percorso rappresentano le “cause” esogene e le variabili a valle indicano gli effetti, ovvero le variabili endogene. I coefficienti di percorso vengono rappresentati graficamente come frecce orientate e corrispondono all’effetto <em>diretto</em> sulla variabile verso cui punta la freccia della variabile a monte della freccia. In tale rappresentazione grafica, i coefficienti di percorso non sono altro che i coefficienti parziali di regressione del modello di regressione multipla. In questo contesto, indicano l’effetto <em>diretto</em> atteso sulla variabile endogena in conseguenza dell’incremento di un’unità della variabile esogena, <em>lasciano immutate tutte le altre relazioni strutturali</em> del modello.</p>
<p>Usiamo la funzione <code class="docutils literal notranslate"><span class="pre">sem()</span></code> del pacchetto <code class="docutils literal notranslate"><span class="pre">lavaan</span></code> per definire il modello rappresentato nel successivo diagramma di percorso:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">&lt;-</span> <span class="s2">&quot;</span>
  <span class="n">kid_score</span> <span class="o">~</span> <span class="n">mom_hs</span> <span class="o">+</span> <span class="n">mom_iq</span> <span class="o">+</span> <span class="n">mom_work</span> <span class="o">+</span> <span class="n">mom_age</span>
<span class="s2">&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>Adattiamo il modello ai dati</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fit</span> <span class="o">&lt;-</span> <span class="n">sem</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Il diagramma di percorso si ottiene con le seguenti istruzioni:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">options</span><span class="p">(</span><span class="nb">repr</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">width</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="nb">repr</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">height</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">semPaths</span><span class="p">(</span>
  <span class="n">fit</span><span class="p">,</span> <span class="s2">&quot;est&quot;</span><span class="p">,</span>
  <span class="n">posCol</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s2">&quot;black&quot;</span><span class="p">),</span>
  <span class="n">edge</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">cex</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
  <span class="n">sizeMan</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span> 
  <span class="n">what</span> <span class="o">=</span> <span class="s2">&quot;path&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="n">Error</span> <span class="ow">in</span> <span class="nb">eval</span><span class="p">(</span><span class="n">expr</span><span class="p">,</span> <span class="n">envir</span><span class="p">,</span> <span class="n">enclos</span><span class="p">):</span> <span class="nb">object</span> <span class="s1">&#39;fit&#39;</span> <span class="ow">not</span> <span class="n">found</span>
<span class="ne">Traceback</span>:

<span class="mi">1</span><span class="o">.</span> <span class="n">semPaths</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="s2">&quot;est&quot;</span><span class="p">,</span> <span class="n">posCol</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s2">&quot;black&quot;</span><span class="p">),</span> <span class="n">edge</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">cex</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span> 
 <span class="o">.</span>     <span class="n">sizeMan</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span> <span class="n">what</span> <span class="o">=</span> <span class="s2">&quot;path&quot;</span><span class="p">)</span>
<span class="mi">2</span><span class="o">.</span> <span class="s2">&quot;semPlotModel&quot;</span> <span class="o">%</span><span class="k">in</span>% class(object)
</pre></div>
</div>
</div>
</div>
<p>Come indicato nel diagramma, l’effetto diretto di <code class="docutils literal notranslate"><span class="pre">mom_iq</span></code> su <code class="docutils literal notranslate"><span class="pre">kid_score</span></code> è identico al corrispondente coefficiente parziale di regressione.</p>
<p>Il problema di capire se sia appropriato utilizzare un modello di regressione per descrivere le relazioni causali tra le variabili è affrontato nel prossimo paragrafo in riferimento all’errore di specificazione.</p>
</section>
<section id="errore-di-specificazione">
<h3><span class="section-number">2.2.3. </span>Errore di specificazione<a class="headerlink" href="#errore-di-specificazione" title="Permalink to this headline">#</a></h3>
<p>Spiritosamente chiamato “heartbreak of L.O.V.E.” [Left-Out Variable Error; &#64;mauro1990understanding], l’errore di specificazione è una caratteristica fondamentale dei modelli di regressione che deve sempre essere tenuta a mente quando interpretiamo i risultati di questa tecnica di analisi statistica.</p>
<p>L’errore di specificazione si verifica quando escludiamo dal modello di regressione una variabile che ha due caratteristiche:</p>
<ul class="simple">
<li><p>è associata con altre variabili inserite nel modello,</p></li>
<li><p>ha un effetto diretto sulla <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
</ul>
<p>Come conseguenza dell’errore di specificazione, l’intensità e il segno dei coefficienti parziali di regressione risultano sistematicamente distorti.</p>
<p>Consideriamo un esempio con dati simulati nei quali immaginiamo che la prestazione sia positivamente associata alla motivazione e negativamente associata all’ansia. Immaginiamo inoltre che vi sia una correlazione positiva tra ansia a motivazione. Ci chiediamo cosa succede al coefficiente parziale della variabile “motivazione” se la variabile “ansia” viene esclusa dal modello di regressione.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">n</span> <span class="o">&lt;-</span> <span class="mi">400</span>
<span class="n">anxiety</span> <span class="o">&lt;-</span> <span class="n">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
<span class="n">motivation</span> <span class="o">&lt;-</span> <span class="mf">4.0</span> <span class="o">*</span> <span class="n">anxiety</span> <span class="o">+</span> <span class="n">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">)</span>
<span class="n">cor</span><span class="p">(</span><span class="n">anxiety</span><span class="p">,</span> <span class="n">motivation</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">0.861770572096146</div></div>
</div>
<p>Creo la variabile <code class="docutils literal notranslate"><span class="pre">performance</span></code> come una combinazione lineare di motivazione e ansia nella quale la motivazione ha un effetto piccolo, ma positivo, sulla prestazione, e l’ansia ha un grande effetto negativo sulla prestazione:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">performance</span> <span class="o">&lt;-</span>  <span class="mf">0.5</span> <span class="o">*</span> <span class="n">motivation</span> <span class="o">-</span> <span class="mf">5.0</span> <span class="o">*</span> <span class="n">anxiety</span> <span class="o">+</span> <span class="n">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Salvo i dati in un DataFrame:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sim_dat2</span> <span class="o">&lt;-</span> <span class="n">tibble</span><span class="p">(</span><span class="n">performance</span><span class="p">,</span> <span class="n">motivation</span><span class="p">,</span> <span class="n">anxiety</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Eseguo l’analisi di regressione specificando in maniera corretta il modello, ovvero usando come predittori sia l’ansia che la depressione:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fm1</span> <span class="o">&lt;-</span> <span class="n">lm</span><span class="p">(</span><span class="n">performance</span> <span class="o">~</span> <span class="n">motivation</span> <span class="o">+</span> <span class="n">anxiety</span><span class="p">,</span> <span class="n">sim_dat2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Le stime dei coefficienti parziali di regressione recuperano correttamente l’intensità e il segno dei coefficienti utilizzati nel modello generatore dei dati:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coef</span><span class="p">(</span><span class="n">fm1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.dl-inline {width: auto; margin:0; padding: 0}
.dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}
.dl-inline>dt::after {content: ":\0020"; padding-right: .5ex}
.dl-inline>dt:not(:first-of-type) {padding-left: .5ex}
</style><dl class=dl-inline><dt>(Intercept)</dt><dd>1.37119646932022</dd><dt>motivation</dt><dd>0.495388553436189</dd><dt>anxiety</dt><dd>-5.10521755591756</dd></dl>
</div></div>
</div>
<p>Eseguo ora l’analisi di regressione ignorando il predittore <code class="docutils literal notranslate"><span class="pre">anxiety</span></code> che ha le due caratteristiche di essere associato a <code class="docutils literal notranslate"><span class="pre">motivation</span></code> e di avere un effetto diretto sulla prestazione:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fm2</span> <span class="o">&lt;-</span> <span class="n">lm</span><span class="p">(</span><span class="n">performance</span> <span class="o">~</span> <span class="n">motivation</span><span class="p">,</span> <span class="n">sim_dat2</span><span class="p">)</span>
<span class="n">summary</span><span class="p">(</span><span class="n">fm2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = performance ~ motivation, data = sim_dat2)

Residuals:
    Min      1Q  Median      3Q     Max 
-13.501  -3.409   0.005   3.311  12.616 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -12.39720    1.44591  -8.574 2.24e-16 ***
motivation   -0.43717    0.03553 -12.305  &lt; 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 4.866 on 398 degrees of freedom
Multiple R-squared:  0.2756,	Adjusted R-squared:  0.2738 
F-statistic: 151.4 on 1 and 398 DF,  p-value: &lt; 2.2e-16
</pre></div>
</div>
</div>
</div>
<p>Si noti che, al di là della “significatività statistica” (si vedano le considerazioni fornite nel paragrafo sulla stepwise regression), il risultato prodotto dal modello di regressione è totalmente sbagliato: come conseguenza dell’errore di specificazione, il segno del coefficiente parziale di regressione della variabile “motivazione” è negativo, anche se nel modello generatore dei dati tale coefficiente aveva il segno opposto.</p>
<p>Quindi, se interpretiamo il coefficiente parziale ottenuto in termini casuali, siamo portati a concludere che la motivazione fa diminuire la prestazione. Ma in realtà è vero l’opposto.</p>
<p>È facile vedere perché si verifica l’errore di specificazione. Supponiamo che il vero modello sia</p>
<div class="math notranslate nohighlight">
\[
y = \alpha + \beta_1 X_1 + \beta_2 X_2 + \varepsilon
\]</div>
<p>il quale verrebbe stimato da</p>
<div class="math notranslate nohighlight">
\[
y = a + b_1 X_1 + b_2 X_2 + e.
\]</div>
<p>Supponiamo però che il ricercatore creda invece che</p>
<div class="math notranslate nohighlight">
\[
y = \alpha^\prime + \beta_1^\prime X_1 + \varepsilon^\prime
\]</div>
<p>e quindi stimi</p>
<div class="math notranslate nohighlight">
\[
y = a^\prime + b_1^\prime X_1 + e^\prime
\]</div>
<p>omettendo <span class="math notranslate nohighlight">\(X_2\)</span> dal modello.</p>
<p>Per capire che relazione intercorre tra <span class="math notranslate nohighlight">\(b_1^\prime\)</span> e <span class="math notranslate nohighlight">\(b_1\)</span>, iniziamo a scrivere la formula per <span class="math notranslate nohighlight">\(b_1^\prime\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\begin{equation}
b_1^\prime = \frac{Cov(X_1, Y)}{Var(X_1)}.
\end{equation}
\]</div>
<p>Sviluppando, otteniamo</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
\begin{aligned}
b_1^\prime &amp;= \frac{Cov(X_1, a + b_1 X_1 + b_2 X_2 + e)}{Var(X_1)}\notag\\
&amp;= \frac{Cov(X_1, a)+b_1 Cov(X_1, X_1) + b_2 Cov(X_1, X_2) + Cov(X_1, e)}{Var(X_1)}\notag\\
&amp;= \frac{0 + b_1 Var(X_1) + b_2 Cov(X_1, X_2) + 0}{Var(X_1)}\notag\\
&amp;= b_1 + b_2 \frac{Cov(X_1, X_2)}{Var(X_1)}.
\end{aligned}
\end{equation}
\end{split}\]</div>
<p>Quindi, se erroneamente omettiamo <span class="math notranslate nohighlight">\(X_2\)</span> dal modello, abbiamo che</p>
<div class="math notranslate nohighlight" id="equation-eq-specific-err">
<span class="eqno">(2.1)<a class="headerlink" href="#equation-eq-specific-err" title="Permalink to this equation">#</a></span>\[
\begin{equation}
\mathbb{E}(b_1^\prime) = \beta_1 + \beta_2 \frac{\sigma_{12}}{\sigma_1^2}.
\end{equation}
\]</div>
<p>Verifichiamo tale conclusione per i dati dell’esempio che stiamo discutendo. Nel caso presente, <span class="math notranslate nohighlight">\(X_1\)</span> è <code class="docutils literal notranslate"><span class="pre">motivation</span></code> e <span class="math notranslate nohighlight">\(X_2\)</span> è <code class="docutils literal notranslate"><span class="pre">anxiety</span></code>. Applicando l’eq. <a class="reference internal" href="#equation-eq-specific-err">(2.1)</a> otteniamo lo stesso valore per il coefficiente di regressione associato a <code class="docutils literal notranslate"><span class="pre">motivation</span></code> che era stato ottenuto adattando ai dati il modello <code class="docutils literal notranslate"><span class="pre">performance</span> <span class="pre">~</span> <span class="pre">motivation</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fm1$coef[2] +  fm1$coef[3] * 
  cov(sim_dat2$motivation, sim_dat2$anxiety) / 
  var(sim_dat2$motivation)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><strong>motivation:</strong> -0.437167456259783</div></div>
</div>
<p>Possiamo dunque concludere che <span class="math notranslate nohighlight">\(b_1^\prime\)</span> è uno stimatore distorto di <span class="math notranslate nohighlight">\(\beta_1\)</span>. Si noti che questa distorsione non scompare all’aumentare della numerosità campionaria, il che (in termini statistici) significa che un tale stimatore è <em>inconsistente</em>. Quello che succede in pratica è che alla variabile <span class="math notranslate nohighlight">\(X_1\)</span> vengono attribuiti gli effetti delle variabili che sono state omesse dal modello. Si noti che una tale distorsione sistematica di <span class="math notranslate nohighlight">\(b_1^\prime\)</span> può essere evitata solo se si verificano due condizioni:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\beta_2 = 0\)</span>. Questo è ovvio, dato che, se <span class="math notranslate nohighlight">\(\beta_2 = 0\)</span>, ciò significa che il modello non è specificato in modo errato, cioè <span class="math notranslate nohighlight">\(X_2\)</span> non appartiene al modello perché non ha un effetto diretto sulla <span class="math notranslate nohighlight">\(Y\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_{12} = 0\)</span>. Cioè, se <span class="math notranslate nohighlight">\(X_1\)</span> e <span class="math notranslate nohighlight">\(X_2\)</span> sono incorrelate, allora l’omissione di una delle due variabili non comporta stime distorte dell’effetto dell’altra.</p></li>
</ul>
</section>
<section id="soppressione">
<h3><span class="section-number">2.2.4. </span>Soppressione<a class="headerlink" href="#soppressione" title="Permalink to this headline">#</a></h3>
<p>Le conseguenze dell’errore di specificazione sono chiamate “soppressione” (<em>suppression</em>). In generale, si ha soppressione quando (1) il valore assoluto del peso beta di un predittore è maggiore di quello della sua correlazione bivariata con il criterio o (2) i due hanno segni opposti.</p>
<ul class="simple">
<li><p>L’esempio descritto sopra è un caso di <em>soppressione negativa</em>, dove il predittore ha correlazioni bivariate positive con il criterio, ma si riceve un peso beta negativo nell’analisi di regressione multipla.</p></li>
<li><p>Un secondo tipo di soppressione è la <em>soppressione classica</em>, in cui un predittore non è correlato al criterio ma riceve un peso beta diverso da zero.</p></li>
<li><p>C’è anche la <em>soppressione reciproca</em> che può verificarsi quando due variabili sono correlate positivamente con il criterio ma negativamente tra loro.</p></li>
</ul>
</section>
<section id="stepwise-regression">
<h3><span class="section-number">2.2.5. </span>Stepwise regression<a class="headerlink" href="#stepwise-regression" title="Permalink to this headline">#</a></h3>
<p>Un’implicazione della soppressione è che i predittori non dovrebbero essere selezionati in base ai valori delle correlazioni bivariate con il criterio. Queste associazioni, dette di ordine zero, non controllano gli effetti degli altri predittori, quindi i loro valori possono essere fuorvianti rispetto ai coefficienti di regressione parziale per le stesse variabili. Per lo stesso motivo, il fatto che le correlazioni bivariate con il criterio siano statisticamente significative o meno è irrilevante per quanto riguarda la selezione dei predittori. Sebbene le procedure informatiche di regressione  rendano facile i processi di selezione dei predittori in base a tali criteri, tali procedure sono da evitare. Il rischio è che anche piccole, ma non rilevate, non-linearità o effetti indiretti tra i predittori possano seriamente distocere i coefficienti di regressione parziale. È meglio selezionare giudiziosamente il minor numero di predittori sulla base di ragioni teoriche o dei risultati di ricerche precedenti. In altri termini, le procedure di stepwise regression non dovrebbero mai essere usate.</p>
<p>Una volta che sono stati selezionati, i predittori possono essere inseriti nell’equazione di regressione in due modi diversi:</p>
<ul class="simple">
<li><p>tutti i predittori possono essere inseriti nel modello contemporaneamente;</p></li>
<li><p>i predittori possono essere inseriti nel modello sequenzialmente, mediante una serie di passaggi.</p></li>
</ul>
<p>L’ordine di ingresso può essere determinato in base a standard: teorici (razionali) o empirici (statistici). Lo standard razionale corrisponde alla <em>regressione gerarchica</em>, in cui si comunica al computer un ordine fisso per inserire i predittori. Ad esempio, a volte le variabili demografiche vengono inserite nel primo passaggio, quindi nel secondo passaggio viene inserita una variabile psicologica di interesse. Questo ordine non solo controlla le variabili demografiche ma permette anche di valutare il potere predittivo della variabile psicologica, al di là di quello delle semplici variabili demografiche. Quest’ultimo può essere stimato come l’aumento della correlazione multipla al quadrato, o <span class="math notranslate nohighlight">\(\Delta R^2\)</span>, da quella della fase 1 con solo predittori demografici a quella della fase 2 con tutti i predittori nell’equazione di regressione.</p>
<p>Un esempio di standard statistico è la regressione <em>stepwise</em>, in cui il computer seleziona l’inserimento dei predittori in base esclusivamente alla significatività statistica; cioè, viene chiesto: quale predittore, se inserito nell’equazione, avrebbe il valore_<span class="math notranslate nohighlight">\(p\)</span> più piccolo per il test del suo coefficiente di regressione parziale? Dopo la selezione, i predittori in una fase successiva possono essere rimossi dall’equazione di regressione in base ai loro valori-<span class="math notranslate nohighlight">\(p\)</span> (ad esempio, se <span class="math notranslate nohighlight">\(p \geq\)</span> .05). Il processo stepwise si interrompe quando, aggiungendo più predittori, <span class="math notranslate nohighlight">\(\Delta R^2\)</span> non migliora. Varianti della regressione stepwise includono <em>forward inclusion</em>, in cui i predittori selezionati non vengono successivamente rimossi dal modello, e <em>backward elimination</em>, che inizia con tutti i predittori nel modello per poi rimuoverne alcuni in passi successivi. Per le ragioni descritte nel paragrafo sull’errore di specificazione, i metodi basati sulle procedure di stepwise regression non dovrebbero mai essere usati. Infatti, i problemi relativi a tale procedura sono così gravi che varie riviste non accettano studi che fanno uso di una tale tecnica statistica. I risultati ottenuti con tali metodi, infatti, sono quasi certamente non replicabili in campioni diversi.</p>
<p>Una considerazione finale riguarda l’idea di rimuovere i predittori “non significativi” dal modello di regressione. Questa è una cattiva idea. Il ricercatore non deve sentirsi in dovere di trascurare quei predittore che non risultano “statisticamente significativi”. In campioni piccoli, la potenza dei test di significatività è  bassa e la rimozione di un predittore non significativo può alterare sostanzialmente la soluzione. Se c’è una buona ragione per includere un predittore, allora è meglio lasciarlo nel modello, fino a prova contraria. In termini generali, qualsiasi considerazione basata sulla “significatività statistia” è fuorviante.</p>
</section>
</section>
<section id="proprieta-degli-stimatori-dei-minimi-quadrati">
<h2><span class="section-number">2.3. </span>Proprietà degli stimatori dei minimi quadrati<a class="headerlink" href="#proprieta-degli-stimatori-dei-minimi-quadrati" title="Permalink to this headline">#</a></h2>
<p>Consideriamo il problema dell’inferenza statistica nel caso più semplice, quello della regressione bivariata. Il caso generale della regressione multipla segue lo stesso approccio, anche se le formule sono più complesse in quanto vengono formulate nei termini dell’albebra matriciale.</p>
<p>Per il caso bivariato, si può dire che il coefficiente dei minimi quadrati <span class="math notranslate nohighlight">\(b\)</span> è una combinazione lineare delle osservazioni <span class="math notranslate nohighlight">\(y_i\)</span>. Tale proprietà è importante perché consente di derivare la distribuzione di <span class="math notranslate nohighlight">\(b\)</span> dalla distribuzione delle <span class="math notranslate nohighlight">\(y_i\)</span>.
Può essere dimostrato che la formula per il calcolo di <span class="math notranslate nohighlight">\(b\)</span> si può scrivere nel modo seguente:</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
b &amp;= \sum_i \left[\frac{x_i-\bar{x}}{\sum_j(x_j-\bar{x})^2}\right]y_i = \textstyle\sum m_i y_i,
\end{align}
\]</div>
<p>dove <span class="math notranslate nohighlight">\(m_i \triangleq (x_i-\bar{x}) / \sum (x_j-\bar{x})^2\)</span> è il peso associato a ciascun valore <span class="math notranslate nohighlight">\(y_i\)</span>. Dato che i valori <span class="math notranslate nohighlight">\(x_i\)</span> sono fissi e <span class="math notranslate nohighlight">\(m_i\)</span> dipende solo da <span class="math notranslate nohighlight">\(x_i\)</span>, anche i pesi <span class="math notranslate nohighlight">\(m_i\)</span> sono fissi.</p>
<p>Il valore atteso di <span class="math notranslate nohighlight">\(b\)</span> è uguale a</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
E(b) &amp;= \textstyle\sum m_i E(y_i)\notag\\ 
&amp;= \textstyle\sum m_i (\alpha + \beta x_i)\notag\\ 
&amp;= \textstyle\alpha\sum m_i + \beta \sum m_i x_i\notag\\
&amp;= \frac{\alpha \sum(x_i-\bar{x})}{\sum(x_i-\bar{x})^2} + \beta \frac{\sum(x_i-\bar{x})x_i}{\sum(x_i-\bar{x})^2}\notag\\
&amp;= 0 + \beta \frac{\sum x_i^2 -\bar{x}\sum x_i}{\sum(x_i-\bar{x})^2}\notag\\ 
&amp;= \beta \frac{\sum x_i^2 - n\bar{x}^2}{\sum(x_i-\bar{x})^2}\notag\\ 
&amp;= \beta.
\end{align}
\end{split}\]</div>
<p>Il coefficiente dei minimi quadrati <span class="math notranslate nohighlight">\(b\)</span> è dunque uno stimatore corretto di <span class="math notranslate nohighlight">\(\beta\)</span>. In maniera equivalente si può dimostrare che <span class="math notranslate nohighlight">\(E(a) = \alpha\)</span>.</p>
<p>Sotto le ipotesi di omoschedasticità <span class="math notranslate nohighlight">\(\big[ var(y_i) = var(\varepsilon_i)=\sigma^2_{\varepsilon}\big]\)</span> e indipendenza, la varianza di <span class="math notranslate nohighlight">\(b\)</span> è</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
var(b) &amp;= \textstyle var\big(\sum m_i y_i\big)\notag\\
&amp;= \textstyle\mathop{\sum m_i^2} var(y_i)\notag\\ 
&amp;= \textstyle\mathop{\sum m_i^2} \sigma^2_{\varepsilon}\notag\\
&amp;= \frac{\mathop{\sigma^2_{\varepsilon}} \textstyle\sum(x_i-\bar{x})^2}{\big[\textstyle\sum(x_i-\bar{x})^2\big]^2}\notag\\
&amp;= \frac{\sigma^2_{\varepsilon}}{\sum(x_i-\bar{x})^2}.
\end{align}
\end{split}\]</div>
<p>In maniera simile si dimostra che la varianza di <span class="math notranslate nohighlight">\(a\)</span> è</p>
<div class="math notranslate nohighlight">
\[
var(a)= \frac{\sigma^2_{\varepsilon} \textstyle\sum x_i^2}{n \textstyle\sum (x_i-\bar{x})^2}.
\]</div>
<p>Dato che sia <span class="math notranslate nohighlight">\(a\)</span> che <span class="math notranslate nohighlight">\(b\)</span> sono funzioni lineari di <span class="math notranslate nohighlight">\(y_i\)</span>, se i valori <span class="math notranslate nohighlight">\(y_i\)</span> seguono la distribuzione gaussiana, allora anche  <span class="math notranslate nohighlight">\(a\)</span> e <span class="math notranslate nohighlight">\(b\)</span> saranno distribuiti secondo una distribuzione normale. In conclusione,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
b &amp;\sim \mathcal{N}\bigg(\beta,  \frac{\sigma^2_{\varepsilon}}{\sum(x_i-\bar{x})^2}\bigg),\\
a &amp;\sim \mathcal{N}\bigg(\alpha, \frac{\sigma^2_{\varepsilon}\textstyle\sum x_i^2}{n \textstyle\sum (x_i-\bar{x})^2} \bigg).
\end{align}
\end{split}\]</div>
<section id="ipotesi-statistiche-e-statistica-test">
<h3><span class="section-number">2.3.1. </span>Ipotesi statistiche e statistica test<a class="headerlink" href="#ipotesi-statistiche-e-statistica-test" title="Permalink to this headline">#</a></h3>
<p>Una volta definite le proprietà delle distribuzioni degli stimatori dei minimi quadrati è possibile procedere con l’inferenza sui parametri del modello di regressione.
L’inferenza statistica si articola nella formulazione degli intervalli di confidenza per i parametri di interesse e nei test di significatività statistica.</p>
<p>Un’ipotesi che viene frequentemente sottoposta a verifica è quella di significatività, cioè l’ipotesi che alla variabile esplicativa sia associato un coefficiente nullo.
In tal caso, l’ipotesi nulla è</p>
<div class="math notranslate nohighlight">
\[H_0:\beta=0\]</div>
<p>e l’ipotesi alternativa è</p>
<div class="math notranslate nohighlight">
\[H_1:\beta \neq 0.\]</div>
<p>Sotto l’ipotesi nulla <span class="math notranslate nohighlight">\(H_0: \beta = 0\)</span> la statistica</p>
<div class="math notranslate nohighlight">
\[
 t_{\hat{\beta}} = \frac{\hat{\beta}}{s_{\hat{\beta}}}
\]</div>
<p>si distribuisce come una variabile aleatoria <span class="math notranslate nohighlight">\(t\)</span> di Student con <span class="math notranslate nohighlight">\(n-2\)</span> gradi di libert{`a}.</p>
<p>Di fronte al problema di decidere se il valore stimato <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> sia sufficientemente “distante” da zero, in modo da respingere l’ipotesi nulla che il vero valore <span class="math notranslate nohighlight">\(\beta\)</span> sia nullo, non è sufficiente basarsi soltanto sul valore numerico assunto da <span class="math notranslate nohighlight">\(\hat{\beta}\)</span>, ma occorre tener conto della variabilità campionaria.
La statistica ottenuta dividendo <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> per la stima del suo errore standard, <span class="math notranslate nohighlight">\(s_{\hat{\beta}}\)</span>, ci permette di utilizzare la distribuzione <span class="math notranslate nohighlight">\(t\)</span> di  Student come metrica per stabilire se la stima trovata si debba considerare “diversa” da quanto ipotizzato sotto <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<p>L’ipotesi nulla viene rifiutata quando il valore assoluto del rapporto è esterno alla regione di accettazione, i cui limiti sono definiti dai valori critici della distribuzione <span class="math notranslate nohighlight">\(t\)</span> di Student con <span class="math notranslate nohighlight">\(n - 2\)</span> gradi di libertà per il livello di significatività <span class="math notranslate nohighlight">\(\alpha\)</span> prescelto.
Se l’ipotesi nulla viene rifiutata si dice che il coefficiente <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> è \enquote{statisticamente significativo} ammettendo così la possibilità di descrivere con un modello lineare la relazione esistente tra le  variabili <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span>.
Quando non si può rifiutare l’ipotesi nulla nel modello di regressione, si conclude che il coefficiente angolare della retta non risulta significativamente diverso da zero, individuando  così nella popolazione una retta parallela all’asse delle</p>
</section>
<section id="riportare-i-risultati">
<h3><span class="section-number">2.3.2. </span>Riportare i risultati<a class="headerlink" href="#riportare-i-risultati" title="Permalink to this headline">#</a></h3>
<p>È consuetudine riportare i risultati dell’analisi di regressione in modo che insieme alle stime dei coefficienti vengano riportati i rispettivi errori standard stimati. Il valore-<span class="math notranslate nohighlight">\(p\)</span> esprime la probabilità di ottenere un valore del test uguale o superiore a quello ottenuto nel campione esaminato, utilizzando la distribuzione campionaria del test sotto l’ipotesi nulla.
Se <span class="math notranslate nohighlight">\(t_{\hat{\beta}}\)</span> è il valore osservato del rapporto <span class="math notranslate nohighlight">\(t\)</span> per il coefficiente angolare della retta di regressione, allora il { <span class="math notranslate nohighlight">\(p\)</span>-valore} è dato da</p>
<div class="math notranslate nohighlight">
\[
p = 2 \times Pr(t \geq |t_{\hat{\beta}}|),
\]</div>
<p>dove <span class="math notranslate nohighlight">\(t\)</span> è il valore di una variabile aleatoria <span class="math notranslate nohighlight">\(t\)</span> di Student con <span class="math notranslate nohighlight">\((n-2)\)</span> gradi di libertà.</p>
<section id="regola-di-decisione">
<h4><span class="section-number">2.3.2.1. </span>Regola di decisione<a class="headerlink" href="#regola-di-decisione" title="Permalink to this headline">#</a></h4>
<p>Ogni volta che il <span class="math notranslate nohighlight">\(p\)</span>-valore del test è inferiore al livello di significatività che si è scelto per <span class="math notranslate nohighlight">\(H_0\)</span>, il test porta al rifiuto dell’ipotesi nulla.
Solitamente si sceglie un livello <span class="math notranslate nohighlight">\(\alpha\)</span> pari a 0.05 o 0.01.</p>
<p>I test di significatività possono essere eseguiti con R, utilizzando la funzione \texttt{summary()} applicata all’oggetto creato dal \texttt{lm()}.</p>
<p>Il test statistico sul parametro <span class="math notranslate nohighlight">\(\beta\)</span> del modello di regressione verifica l’ipotesi nulla di indipendenza, ovvero l’ipotesi che, nella popolazione, la pendenza della retta di regressione sia uguale a zero. Pi{`u} informativo del test statistico <span class="math notranslate nohighlight">\(H_0: \beta=0\)</span> è  l’intervallo di confidenza per il parametro <span class="math notranslate nohighlight">\(\beta\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta} \pm t_{\alpha/2} s_{\hat{\beta}}.
\]</div>
</section>
</section>
<section id="considerazioni-conclusive">
<h3><span class="section-number">2.3.3. </span>Considerazioni conclusive<a class="headerlink" href="#considerazioni-conclusive" title="Permalink to this headline">#</a></h3>
<p>Il modello di regressione lineare semplice è un metodo per studiare la relazione tra due variabili e per prevedere il valore della variabile dipendente in base alla variabile indipendente. Tuttavia, questo modello è limitato poiché si concentra solo sulla relazione tra una singola variabile indipendente e la variabile dipendente. Quando ci sono più variabili indipendenti, il modello di regressione diventa più complesso e richiede l’uso dell’algebra matriciale. Questo modello può includere variabili indipendenti sia quantitative che qualitative e può essere utilizzato anche per l’analisi della varianza. Il modello lineare è alla base dell’analisi fattoriale, una tecnica ampiamente utilizzata per la costruzione e la validazione dei test psicometrici.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="05_intro_r.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1. </span>Linguaggio di programmazione R</p>
      </div>
    </a>
    <a class="right-next"
       href="035_ctt.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Fondamenti teorici</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regressione-bivariata">2.1. Regressione bivariata</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regressori-centrati">2.1.1. Regressori centrati</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#minimi-quadrati">2.1.2. Minimi quadrati</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relazione-tra-b-e-r">2.1.3. Relazione tra <span class="math notranslate nohighlight">\(b\)</span> e <span class="math notranslate nohighlight">\(r\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#attenuazione">2.1.4. Attenuazione</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coefficiente-di-determinazione">2.1.5. Coefficiente di determinazione</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-standard-della-regressione">2.1.6. Errore standard della regressione</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regressione-multipla">2.2. Regressione multipla</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#significato-dei-coefficienti-parziali-di-regressione">2.2.1. Significato dei coefficienti parziali di regressione</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relazioni-causali">2.2.2. Relazioni causali</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-di-specificazione">2.2.3. Errore di specificazione</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#soppressione">2.2.4. Soppressione</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stepwise-regression">2.2.5. Stepwise regression</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proprieta-degli-stimatori-dei-minimi-quadrati">2.3. Proprietà degli stimatori dei minimi quadrati</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ipotesi-statistiche-e-statistica-test">2.3.1. Ipotesi statistiche e statistica test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#riportare-i-risultati">2.3.2. Riportare i risultati</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#regola-di-decisione">2.3.2.1. Regola di decisione</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#considerazioni-conclusive">2.3.3. Considerazioni conclusive</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>