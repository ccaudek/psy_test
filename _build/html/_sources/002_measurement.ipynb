{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(measurement-notebook)=\n",
    "# Misurazione: affidabilità, validazione di costrutto e costruzione di Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'obiettivo di questo capitolo è presentare una panoramica degli argomenti che verranno trattati nel corso della dispensa.\n",
    "\n",
    "## Definizione di misurazione\n",
    "\n",
    "Una delle prime definizioni di cosa sia la misurazione proviene da Stevens (1951), uno dei fondatori della teoria della misurazione. Egli ha suggerito che la misurazione consiste nell'assegnare numeri a oggetti o eventi secondo delle regole stabilite. Tuttavia, l'opinione generale è ormai concorde sul fatto che la misurazione richieda un approccio più articolato. È condivisibile l'idea che la misurazione debba essere considerata come il processo di creazione di modelli che rappresentano i fenomeni di interesse, prevalentemente in forma quantitativa. Di conseguenza, la misurazione consiste in regole che attribuiscono scale o valori alle entità che rappresentano i costrutti di interesse. Come tutti i modelli, quelli di misurazione (come test, scale o variabili) devono essere semplificazioni per risultare utili. Perciò, è essenziale specificare in modo chiaro i modelli di misurazione per poterli valutare, confutare e migliorare. Inoltre, non è opportuno domandarsi se un modello sia vero o corretto; al contrario, è più utile sviluppare diversi modelli alternativi plausibili e chiedersi: quale modello è meno inaccurato? Questo metodo di confronto dei modelli rappresenta la strategia migliore per valutare e perfezionare le procedure di misurazione.\n",
    "\n",
    "## Approcci alla misurazione psicologica\n",
    "\n",
    "Possiamo individuare due approcci alla misurazione psicologica: l'approccio rappresentazionale e l'approccio non rappresentazionale.\n",
    "\n",
    "In breve, l'assunto basilare dell'approccio di misurazione rappresentazionale è che vengano attribuiti numeri alle entità in modo che le proprietà di tali numeri (come ad esempio \"maggiore di\" o \"moltiplicazione\") riflettano relazioni empiriche effettive. Un esempio chiaro di misurazione rappresentazionale è la Scala di Mohs della durezza, che valuta la durezza dei materiali attraverso una scala ordinale (Dawes & Smith, 1985). In questa scala, il materiale X è considerato più duro del materiale Y se e solo se X è in grado di graffiare Y. Uno dei punti di forza di questi modelli di misurazione risiede nella loro capacità di formulare previsioni sul comportamento delle entità misurate, fornendo così verifiche di coerenza interna che possono essere utilizzate per confutare il modello. Ad esempio, la scala di durezza ordinale deve rispettare il principio di transitività: se il materiale X è più duro del materiale Y e Y è più duro del materiale Z, allora X deve essere più duro di Z. Questa previsione può essere verificata empiricamente controllando se il materiale X graffia effettivamente il materiale Z.\n",
    "\n",
    "D'altra parte, l'approccio psicometrico non offre tali controlli di coerenza interna. Ad esempio, sebbene spesso vengano associati valori numerici alle risposte dei partecipanti su scale di valutazione (come ad esempio 1 = fortemente in disaccordo, 5 = fortemente d'accordo), questi numeri non sono investiti di un significato rappresentazionale forte che consentirebbe controlli di coerenza. Invece, l'approccio psicometrico si basa su schemi aggregati di dati per valutare un modello di misurazione proposto. Questo avviene perché si presume che ogni singola risposta o osservazione sia così suscettibile all'errore da rendere i controlli di coerenza a questo livello di misurazione sostanzialmente inutili e poco informativi. In altre parole, a differenza delle rocce, le persone manifestano un comportamento molto meno coerente, che coinvolga graffiature o altri aspetti. Di conseguenza, l'approccio psicometrico spesso trascura i controlli di coerenza a livello individuale e invece si affida a schemi di varianza e covarianza che riflettono relazioni a livello aggregato in forma probabilistica (ad esempio, in un campione specifico, le persone che hanno assegnato valutazioni relativamente alte a \"generoso\" sono state poco propense a assegnare valutazioni alte a \"stinge\").\n",
    "\n",
    "Nonostante l'approccio di misurazione rappresentazionale avesse originariamente promesso di costituire una base solida e difendibile per la misurazione psicologica, finora non è riuscito a mantenere questa promessa. Come evidenziato da Cliff (1992), \"la misurazione rappresentazionale è rara nel campo delle attitudini; invece, questo campo è pervaso da questionari e scale di valutazione\". Egli ha definito la misurazione rappresentazionale come \"la rivoluzione che non è mai avvenuta\". Di conseguenza, esamineremo l'approccio psicometrico con maggiore dettaglio.\n",
    "\n",
    "È possibile introdurre l'approccio psicometrico considerando diversi temi principali. Innanzitutto, il concetto di affidabilità, che è stato storicamente proposto  per primo, ma poi successivamente per passare a visioni più recenti e sempre più complesse che enfatizzano la validazione del costrutto e il test dei modelli come approccio più ampio e integrato. Infine, il test dei modelli nella validazione del costrutto e nella costruzione delle scale, che include modelli di misurazione nel contesto del modello ad equazioni strutturali (SEM), la questione della dimensionalità come aspetto della validità strutturale e le tematiche della costruzione dei questionari."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affidabilità e generalizzabilità\n",
    "\n",
    "It should by now be obvious that most measurement procedures in psychology are subject to “error.” Many different sources may contribute to such error. Reliability refers to the consistency of a measure- ment procedure, and indices of reliability describe the extent to which the scores produced by the measure- ment procedure are reproducible.\n",
    "\n",
    "### Teoria classica dei test\n",
    "\n",
    "Le questioni di affidabilità sono state tradizionalmente affrontate all'interno del quadro della teoria classica dei test (Lord & Novick, 1968). Se una misurazione data X è soggetta a un errore e, allora la misurazione senza l'errore, X − e, rappresenterebbe la misurazione accurata o \"vera\" T. Questa formulazione apparentemente semplice, che ogni misurazione può essere suddivisa in un punteggio vero, T, e un errore di misurazione, e, è l'assunzione fondamentale della teoria classica dei test.\n",
    "\n",
    "Tutte le concezioni di affidabilità coinvolgono l'idea di misurazioni ripetute. La teoria classica dei test ha fatto ampio uso dell'idea di test paralleli, ovvero due test che hanno la stessa media, varianza e caratteristiche distributive e che correlano allo stesso modo con variabili esterne (Lord & Novick, 1968). In queste ipotesi, il punteggio vero e l'errore di misurazione possono essere considerati indipendenti. Ne consegue che la varianza dei punteggi osservati è uguale alla somma della varianza dei punteggi veri e della varianza dell'errore di misurazione: Varianza (X) = Varianza (T + e) = Varianza (T ) + Varianza (e ).\n",
    "\n",
    "L'affidabilità può quindi essere definita come il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato: Affidabilità = Varianza (T ) / Varianza (X).\n",
    "\n",
    "In altre parole, se non ci fosse errore, l'affidabilità sarebbe 1; se ci fosse solo errore e nessuna varianza del punteggio vero, l'affidabilità sarebbe 0. La correlazione tra la variabile osservata e il punteggio vero è la radice quadrata dell'affidabilità.\n",
    "\n",
    "\n",
    "#### Molteplici evidenze di affidabilità\n",
    "\n",
    "Poiché la teoria classica dei test definiva i test paralleli in termini puramente matematici, essa forniva scarse specificazioni sostanziali o restrizioni dei tipi di procedure di misurazione che potessero essere considerate parallele. A partire dagli anni '50, diversi disegni furono distinti:\n",
    "- Testare i partecipanti in momenti diversi con la stessa forma (retest)\n",
    "- Testare i partecipanti in un unico momento con due forme che coprono lo stesso contenuto (equivalenza)\n",
    "- Testare i partecipanti con (a) correlazione tra più elementi in un unico momento (a. split-half; b. coerenza interna)\n",
    "- Ottenere valutazioni da giudici multipli su una stessa forma e occasione (coerenza interna).\n",
    "\n",
    "### Coefficiente alpha\n",
    "\n",
    "Ora consideriamo il coefficiente alpha (Cronbach, 1951), poiché questo indice di coerenza interna gioca un ruolo molto importante nella letteratura psicologica. Perché alpha è diventato lo standard dell'affidabilità di misurazione? Uno dei motivi è che questo indice può essere ottenuto con grande facilità. Alpha non richiede la raccolta di dati in due momenti diversi dagli stessi partecipanti, come invece è richiesto dall'affidabilità test-retest, o la costruzione di due forme alternative di una scala, come richiederebbe l'affidabilità delle forme parallele. Alpha è l'indice di affidabilità \"meno impegnativo\"; è facile da calcolare. Tuttavia, contrariamente alla credenza comune, alpha non misura l'omogeneità delle intercorrelazioni tra gli elementi, né indica che una scala sia unidimensionale.\n",
    "\n",
    "Poiché alpha non può affrontare questa questione, l'unidimensionalità deve essere stabilita in altri modi. L'approccio più rigoroso consiste nell'utilizzare la parte l'analisi fattoriale confermativa e i modelli di equazioni strutturali (SEM). Il SEM ci consente di testare quanto bene la matrice di correlazione tra gli elementi si adatti a un modello a singolo fattore, piuttosto che a un modello multifattoriale. In altre parole, quanto bene le saturazioni fattoriali su un singolo fattore possono riprodurre la matrice di correlazione effettivamente osservata.\n",
    "\n",
    "È importante sottolineare che la questione dell'errore (o dell'affidabilità) presente in un item è separata dalla questione della multidimensionalità. Nelle analisi SEM, le saturazioni degli item rappresentano quanto della varianza dell'item è condivisa tra gli item (quindi generalizzabile), mentre l'errore è catturato dalla varianza residua dell'item, indicando quanto della varianza è unica per quell'item. La multidimensionalità, d'altra parte, è catturata dalla relativa bontà di adattamento del modello a un fattore rispetto a modelli a più fattori.\n",
    "\n",
    "Una volta che sappiamo che un test è multidimensionale, possiamo continuare a utilizzare alpha come indice di affidabilità? La risposta è no: infatti, se il test non è unidimensionale, alpha sottostima l'affidabilità.\n",
    "\n",
    "### Attenuazione\n",
    "\n",
    "Secondo la teoria classica dei test (ad esempio, Lord & Novick, 1968), i ricercatori dovrebbero preoccuparsi dell'affidabilità poiché essa limita quanto fortemente una misura può correlare con un'altra variabile (ad esempio, un criterio esterno). Se l'errore è veramente casuale, come assume la teoria classica dei test, il limite superiore della correlazione per una misura non è 1.0, ma la radice quadrata della sua affidabilità. Di conseguenza, la vera correlazione tra la misura e un'altra variabile viene sottostimata (cioè attenuata) quando l'affidabilità è inadeguata. \n",
    "\n",
    "### Oltre alla Teoria Classica dei Test: Teoria della Generalizzabilità\n",
    "\n",
    "Le distinzioni tra i \"tipi di affidabilità\" sottolineati dalla letteratura e sintetizzati in precedenza hanno avuto diverse conseguenze negative. In primo luogo, hanno nascosto un'importante lacuna nella teoria classica dei test: se le misurazioni fossero effettivamente parallele e gli errori veramente casuali, allora tutti questi approcci all'affidabilità dovrebbero giungere alla stessa conclusione. Purtroppo, non è così; l'affidabilità dipende dalla specifica dimensione di generalizzazione che viene considerata. In secondo luogo, ciò che inizialmente era inteso come una procedura euristica è stato poi cristallizzato in concetti come \"il Coefficiente di Stabilità\" o \"il Coefficiente Alfa\", nonostante l'idea di affidabilità fosse concepita in maniera più ampia e sfaccettata.\n",
    "\n",
    "Pertanto, l'*American Psychological Association* (APA) nel 1985 ha proposto nelle edizioni successive degli \"Standard per il Testing Educativo e Psicologico\" l'abolizione di queste distinzioni e terminologie, sostituendole con un approccio più ampio promosso dalla teoria della generalizzabilità (Cronbach et al., 1963). Tuttavia, purtroppo, nel corso degli anni la pratica non ha subito sufficienti cambiamenti e la teoria della generalizzabilità non ha ancora completamente soppiantato queste nozioni più semplicistiche. Per mettere in luce l'incompletezza dell'approccio classico, possiamo esaminare diverse dimensioni della generalizzabilità che vengono considerate e approfondite all'interno di questa teoria.\n",
    "\n",
    "- *Dimensione temporale*: La teoria della generalizzabilità riconosce che le misurazioni possono variare in base al momento in cui vengono effettuate. Ad esempio, le risposte dei partecipanti a un questionario possono essere diverse in momenti diversi, influenzate da fattori come lo stato d'animo, le circostanze o l'esperienza. La variazione temporale è una delle dimensioni chiave che la teoria della generalizzabilità considera, cercando di stabilire quanto l'affidabilità di una misura possa variare in base al momento in cui viene effettuata.\n",
    "- *Dimensione delle forme*: Un altro fattore cruciale è la variabilità delle diverse versioni di uno strumento di misura. Ad esempio, se un questionario ha più versioni, è importante determinare quanto l'affidabilità possa variare tra queste diverse forme. La teoria della generalizzabilità considera come le varie forme di un test o strumento possono influenzare la coerenza delle misurazioni e come questa variabilità possa essere gestita per ottenere misurazioni affidabili.\n",
    "- *Dimensione degli elementi*: La variabilità tra gli item o domande di un test è un altro aspetto critico nell'ambito della teoria della generalizzabilità. Differenti item possono suscitare risposte diverse da parte dei partecipanti, e questa variabilità può contribuire all'errore nella misura complessiva. La teoria della generalizzabilità cerca di affrontare come la scelta e la disposizione degli item possono influenzare l'affidabilità.\n",
    "- *Dimensione dei giudici o osservatori*: Nelle situazioni in cui le misurazioni sono basate su valutazioni soggettive o osservazioni da parte di giudici o osservatori, la variabilità tra questi individui può essere significativa. La teoria della generalizzabilità analizza come l'affidabilità di una misura può variare in base alle differenze tra i giudici o gli osservatori coinvolti e come questa variabilità possa essere gestita.\n",
    "\n",
    "La teoria della generalizzabilità sostiene che la nostra attenzione all'\"affidabilità\" di un'osservazione o misurazione deriva dalla necessità di estendere tale osservazione a una varietà di altre situazioni. Ad esempio, la preoccupazione per l'accordo tra giudici in realtà riguarda la precisione con cui possiamo applicare le valutazioni da un determinato gruppo di giudici a un altro. Allo stesso modo, potremmo voler capire quanto bene i punteggi su una scala di atteggiamento, sviluppati attraverso un certo insieme di procedure, siano validi su un'altra scala creata con procedure diverse. In sintesi, mentre la teoria classica dei test si focalizza sulla stima della parte di varianza attribuibile all'\"errore\", la teoria della generalizzabilità punta a quantificare l'influenza di fonti specifiche di varianza sui punteggi del test in contesti specifici.\n",
    "\n",
    "Di conseguenza, al posto dei convenzionali coefficienti di affidabilità precedentemente menzionati, dovremmo impiegare stime più ampie, come il coefficiente di correlazione intraclasse, per esaminare aspetti specifici dell'affidabilità delle misure. La teoria della generalizzabilità si rivela di particolare utilità quando si raccolgono dati in strutture nidificate e diverse dimensioni possono influire sull'affidabilità. In questo contesto, gli approcci di valutazione ecologica momentanea rappresentano un caso rilevante e moderno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoria della Risposta agli Item\n",
    "\n",
    "Il modello di misurazione e le tecniche della teoria classica dei test sono stati oggetto di critiche da parte dei psicometristi che sostengono la teoria della risposta agli item (IRT) come un approccio alternativo e più avanzato (Embretson, 1996; Mellenbergh, 1996). Nella concezione classica dell'affidabilità, le caratteristiche dell'individuo che si sottopone al test e le caratteristiche del test stesso sono considerate indivisibili (Hambleton, Swaminathan e Rogers, 1991). Questo implica che la posizione o il livello dell'individuo sulla scala del costrutto latente è definita unicamente dalle sue risposte a quel test specifico. Di conseguenza, la stessa persona potrebbe apparire con convinzioni liberali su un test con numerosi item che misurano vedute estremamente conservative, mentre sembrerebbe conservatrice su un test che include item che misurano prospettive liberali radicali. Inoltre, le proprietà psicometriche del test dipendono dal gruppo specifico di partecipanti sottoposti all'analisi.\n",
    "\n",
    "Un altro limite della teoria classica dei test è l'assunzione che l'errore di misurazione sia uniforme per tutti gli individui nel campione - un presupposto poco realistico, considerando che i test e gli item variano nella loro capacità di discriminare tra i partecipanti a diversi livelli del costrutto latente.\n",
    "\n",
    "La IRT affronta queste limitazioni stabilendo una relazione tra le risposte degli individui a un item specifico e il costrutto latente, utilizzando una funzione chiamata *curva caratteristica dell'item*. Questa curva illustra la probabilità che individui con diversi livelli del costrutto condividano il contenuto dell'item; fornisce quindi informazioni su quanto efficacemente l'item distingue tra individui con livelli elevati rispetto a quelli con livelli bassi del tratto latente, oltre a misurare la difficoltà dell'item stesso. Queste informazioni sono particolarmente utili per i ricercatori che intendono individuare eventuali bias negli item. Secondo la IRT, un item è privo di bias nel misurare un costrutto, come ad esempio il conservatorismo, se gli individui che condividono lo stesso livello di conservatorismo ottengono punteggi attesi simili sull'item, indipendentemente da dimensioni concettualmente non rilevanti come genere, etnia o background culturale.\n",
    "\n",
    "Nel contesto della creazione e valutazione di scale psicometriche, le procedure della IRT presentano due vantaggi notevoli. In primo luogo, consentono ai ricercatori di selezionare gli item basandosi sia sulla difficoltà che sulla discriminazione, anziché fare affidamento esclusivamente sulle correlazioni tra l'item e il punteggio totale, come proposto dalla teoria classica dei test. In secondo luogo, le procedure della IRT possono valutare la posizione di un individuo sul costrutto latente senza la necessità di somministrare l'intera scala, utilizzando un approccio noto come testing adattivo computerizzato.\n",
    "\n",
    "In un senso più ampio, la IRT fornisce metodi quantitativi per delineare la relazione tra un item  specifico e il costrutto latente misurata in termini di parametri di difficoltà e discriminazione. Queste informazioni sono di grande valore per l'analisi degli item e lo sviluppo delle scale, permettendo ai ricercatori di selezionare gli item che misurano al meglio un particolare livello del costrutto di interesse e individuare item che possono mostrare bias per gruppi specifici di individui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validità\n",
    "\n",
    "Come descritto da Cronbach e Meehl (1955), il comitato APA sui test psicologici inizialmente ha fatto una distinzione tra diversi tipi di validità.\n",
    "\n",
    "- *Validità di Contenuto*: in che misura gli item costituiscono un campione rappresentativo del dominio da misurare.\n",
    "- *Validità di Facciata*: in che misura gli item sembrano misurare il costrutto inteso.\n",
    "- *Validità Orientata al Criterio* (o *Esterna*):\n",
    "    (a) *Predittiva*: in che misura gli item il punteggio futuro di un individuo su un criterio è predetto dai punteggi precedenti nel test.\n",
    "    (b) *Concorrente*: in che misura i punteggi del test stimano il punteggio attuale di un individuo su un criterio.\n",
    "- *Validità di Costrutto*: se la misura riflette con precisione il costrutto che si intende misurare.\n",
    "\n",
    "Presto si capì che l'idea iniziale dei vari tipi distinti di validità era in realtà frammentata e fuorviante. Un costrutto rappresenta un concetto ipotetico, un processo o un'altra regolarità nel comportamento di individui, gruppi o altre entità. I metodi per valutare la validità di una misura devono essere allineati alle procedure scientifiche generali usate per sviluppare e confermare teorie. In altre parole, ciò che sembrava essere una serie di diversi tipi di validità sono in realtà diverse fonti di evidenza che affrontano domande specifiche riguardo alla validità di un costrutto.\n",
    "\n",
    "Oggi c'è un ampio accordo sul fatto che la validità di costrutto delle nostre variabili osservate sia il punto centrale della misurazione. Questo rappresenta un cambiamento significativo rispetto alla teoria classica dei test, che afferma che le misure sono indicatori imperfetti dei costrutti a causa dell'errore casuale di misurazione o dell'inaffidabilità che contengono. Messick (1989, 1995) ha sviluppato un programma esaustivo per la validazione di costrutto che riguarda il significato dei punteggi nell'interpretazione e nell'uso dei test. La sua prospettiva sottolinea che la validità è un \"giudizio valutativo integrativo del grado in cui le evidenze e le giustificazioni teoriche supportano l'adeguatezza e la pertinenza\" della specifica formulazione teorica del costrutto (Messick, 1989, p. 13). Di conseguenza, la validità è considerata una caratteristica dell'interpretazione di una misura piuttosto che della misura stessa. Come qualsiasi altra teoria o modello, la validità dell'interpretazione specifica del punteggio non può mai essere stabilita definitivamente, ma continua a evolversi per formare una crescente \"rete nomologica\" di relazioni che sostengono la validità (Wiggins, 1973)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifica di modelli nella validazione di costrutto e nella costruzione di scale\n",
    "\n",
    "L'Analisi Fattoriale Confermativa (CFA) si basa sull'idea che un vasto insieme di osservazioni o elementi sia direttamente riconducibile (o costituisca l'espressione) di un numero più limitato di fonti latenti (ovvero costrutti non osservati, ipotetici o dedotti). Il modello CFA affronta alcune delle problematiche arbitrarie spesso criticate nell'Analisi Fattoriale Esplorativa. Innanzitutto, richiede ai ricercatori di esplicitare un modello (o più modelli concorrenti) che delinei come le variabili osservate (o misurate) siano connesse ai fattori latenti ipotizzati. In secondo luogo, il CFA mette a disposizione avanzate tecniche statistiche che consentono di verificare quanto bene il modello predefinito si adatti ai dati specifici; ancor più importante, offre la possibilità di comparare il modello predefinito con modelli alternativi o concorrenti, per determinare quale tra essi si adatti meglio (o peggio) ai dati.\n",
    "\n",
    "I modelli CFA possono essere rappresentati in forma grafica, facilitando la comunicazione delle diverse assunzioni incorporate in ciascun modello. Questa rappresentazione è comunemente nota come analisi dei percorsi.\n",
    "\n",
    "L'analisi della coerenza interna di una scala, che tradizionalmente veniva effettuata con i metodi della teoria classica dei test, può beneficiare delle più avanzate metodologie statistiche offerte dai modelli CFA.\n",
    "\n",
    "I Modelli di Equazioni Strutturali (SEM) estendono il modello CFA introducendo la possibilità di esaminare gli effetti di regressione tra variabili manifeste e variabili latenti, o tra variabili latenti.\n",
    "\n",
    "Le analisi CFA e SEM consentono anche di sottoporre a un rigoroso esame le ipotesi sulla dimensionalità di un costrutto.\n",
    "\n",
    "Modelli più complessi includono anche aspetti di validità esterna. Attraverso l'uso del disegno di Matrice Multitrait-Multi Method (MTMM) per affrontare la validità esterna, è possibile raccogliere evidenze sia sulla validità convergente (ad esempio, confrontando misure autoreportate con misure provenienti da altre fonti di dati) sia sulla validità discriminante (ad esempio, confrontando misure di costrutti differenti provenienti dalla stessa fonte di dati)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La costruzione di scale psicologiche\n",
    "\n",
    "La costruzione di questionari rappresenta un procedimento complesso che svolge un ruolo fondamentale non solo nello sviluppo di misure psicologiche preesistenti, ma anche nella loro successiva validazione. Sebbene la validazione di costrutto possa essere discussa in relazione a misure già esistenti, è di primaria importanza riconoscere che il processo di validazione di costrutto è strettamente intrecciato con varie fasi dell'elaborazione delle misure, soprattutto nella costruzione di questionari o scale. Questo aspetto della misurazione psicologica, insieme agli altri, deve essere inquadrato all'interno di un ampio quadro di validazione di costrutto.\n",
    "\n",
    "Negli anni '50, emersero tre diversi approcci alla costruzione di questionari, ciascuno saldamente allineato a un aspetto specifico di validità. Tali approcci miravano a massimizzare un preciso tipo di validità, con il possibile svantaggio di trascurare altri aspetti. Ad esempio, l'\"approccio esterno\" poneva un'accentuata enfasi sulla massimizzazione della validità di criterio. Tale metodo prevedeva la somministrazione di ampi insiemi di elementi del questionario a gruppi distinti di criterio e controllo, allo scopo di individuare empiricamente gli elementi che mostrassero una significativa differenziazione tra i due gruppi. Indipendentemente dal contenuto o dal significato teorico degli elementi individuati, essi venivano mantenuti per formare la scala risultante. Esempi noti di questo approccio includono il Minnesota Multiphasic Personality Inventory (MMPI) e il California Psychological Inventory (CPI).\n",
    "\n",
    "D'altra parte, l'\"approccio razionale\" si concentrava su teorie solidamente fondate. I ricercatori aderenti a tale approccio si concentravano esclusivamente sulla validità di contenuto e di faccia, generando elementi basati sulle loro teorie. Le scale risultanti, caratterizzate da una evidente validità di contenuto, godevano spesso di grande popolarità, come ad esempio il Myers-Briggs Type Indicator (MBTI), basato in parte sulle teorie di Carl Jung.\n",
    "\n",
    "Parallelamente, l'\"approccio induttivo\" emergeva con un'enfasi sulla validità strutturale e il diffondersi dell'analisi fattoriale esplorativa. Questo approccio consisteva nell'esplorare la struttura fattoriale di ampi insiemi di elementi, senza focalizzarsi in modo specifico su una rappresentazione o selezione dettagliata dei contenuti. Tuttavia, questa attenzione interna poteva talvolta andare a discapito di altre fonti di evidenza di validità.\n",
    "\n",
    "Risulta rilevante sottolineare che la costruzione odierna di questionari raramente si attiene esclusivamente a uno dei suddetti approcci iniziali. Piuttosto, questo processo implica una serie di iterazioni, partendo dalla generazione di ipotesi, dalla costruzione di modelli e alternative plausibili, dalla formulazione di elementi in base alle definizioni di costrutto e alle procedure di validità di contenuto, dalla raccolta e analisi dei dati, dalla conferma o modifica dei modelli iniziali e dalla raffinazione delle ipotesi per ulteriori cicli. Questo processo iterativo prosegue fino a quando un modello operativo raggiunge un grado di validità ritenuto \"sufficientemente buono\".\n",
    "\n",
    "In conclusione, la costruzione di questionari rappresenta un'interazione dinamica tra lo sviluppo teorico e la convalida empirica, richiedendo un processo accurato e in continua evoluzione che si allinea con l'ampio contesto della validazione di costrutto.\n",
    "\n",
    "## Considerazioni conclusive\n",
    "\n",
    "In questo capitolo abbiamo esaminato i coefficienti di affidabilità tradizionali, come l'alpha, ma abbiamo incoraggiato il lettore a riflettere sulle dimensioni della generalizzabilità, come il tempo, gli elementi e gli osservatori. Abbiamo discusso di un'approccio unificato alla validità di costrutto. Abbiamo inoltre offerto una breve panoramica delle potenzialità delle tecniche SEM e accennato alle questioni legate alla costruzione di scale psicologiche. Chi volesse approfondire ulteriormente questi argomenti, può fare riferimento al capitolo di {cite:t}`john2014measurement`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
