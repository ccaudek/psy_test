{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51bd483a",
   "metadata": {},
   "source": [
    "(val-sol-fact-notebook)=\n",
    "# Valutare e rifinire la soluzione fattoriale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4614ea9c",
   "metadata": {
    "tags": [
     "remove_cell"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"_common.R\")\n",
    "# install.packages(\"devtools\")\n",
    "# devtools::install_github(\"cddesja/hemp\")\n",
    "suppressPackageStartupMessages({\n",
    "    library(\"lavaan\")\n",
    "    library(\"hemp\")\n",
    "})\n",
    "options(repr.plot.width = 6, repr.plot.height = 6)\n",
    "set.seed(42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a66cb5b9",
   "metadata": {},
   "source": [
    "## Valutazione della matrice pattern\n",
    "\n",
    "La maggior parte di strumenti usati nell'assessment psicologico e\n",
    "neuropsicologico non valuta una singola dimensione psicologica, ma\n",
    "piuttosto misura molteplici aspetti di un costrutto. Di conseguenza,\n",
    "l'analisi fattoriale produce solitamente una soluzione a più \n",
    "fattori. Idealmente, dopo la rotazione, ciascun item saturerà fortemente\n",
    "su un singolo fattore e debolmente sugli altri. In realtà, anche dopo la\n",
    "rotazione degli assi fattoriali, spesso si presentano item che\n",
    "saturano debolmente su tutti i fattori, oppure item che saturano\n",
    "fortemente su più di un fattore.\n",
    "\n",
    "Uno dei primi passi da compiere per  rifinire la soluzione\n",
    "fattoriale è quello di valutare la matrice struttura e intervenire utilizzando il \n",
    "criterio della \"struttura semplice\", per poi valutare gli effetti delle\n",
    "azioni intraprese (es., eliminazione di alcuni item) nella matrice pattern.\n",
    "Ricordiamo che la matrice struttura contiene le correlazioni tra item\n",
    "e fattori, mentre la matrice pattern contiene le saturazioni fattoriali.\n",
    "\n",
    "### Item con basse saturazioni su tutti i fattori\n",
    "\n",
    "Prima di procedere con l'analisi fattoriale è auspicabile esaminare la\n",
    "matrice di correlazioni tra gli item ed eliminare quegli item che sono\n",
    "insufficientemente correlati con gli altri item della matrice.\n",
    "Tuttavia, anche dopo questo screening iniziale, è possibile che vi siano item\n",
    "caratterizzati da saturazioni basse su tutti i fattori. Dal punto di vista pratico,\n",
    "si considerano \"basse\" le saturazioni il cui valore assoluto è\n",
    "minore di 0.30 (Hair et al., 1995). Hair e collaboratori suggeriscono\n",
    "due soluzioni nel caso di item con  saturazioni basse su tutti i fattori:\n",
    "\n",
    "- eliminare gli item con basse saturazioni, \n",
    "- valutare le comunalità degli item problematici e il contributo specifico che forniscono allo strumento. \n",
    "\n",
    "Se un item ha una bassa comunalità, o se il contributo di un item nei confronti del significato generale dello strumento è di poca importanza, allora l'item dovrebbe essere eliminato. Dopo l'eliminazione degli item critici, si procede calcolando una nuova soluzione fattoriale e si esaminano i risultati ottenuti.\n",
    "\n",
    "Se vi sono degli item con basse saturazioni su tutti i fattori che però\n",
    "contribuiscono in maniera importante a determinare il significato della\n",
    "scala nel suo complesso, allora questi item dovrebbero essere mantenuti.\n",
    "Alle volte, per tali item è possibile creare delle sottoscale separate\n",
    "dalle altre.\n",
    "\n",
    "### Item con saturazioni evevate su più di un fattore\n",
    "\n",
    "È comune anche il caso opposto, ovvero quello nel quale ci sono item che saturano su fattori multipli (con saturazioni fattoriali $>$ .30), specialmente nel caso di soluzioni fattoriali ottenutie dopo una rotazione obliqua. Kline (2000) suggerisce di eliminare tali item in quanto rendono difficile da interpretare il significato della scala che così si ottiene. Hair e collaboratori (1995) ritengono invece che tali\n",
    "item dovrebbero essere mantenuti, dato possono chiarire il significato dei\n",
    "fattori che la scala identifica.\n",
    "\n",
    "## Valutazione dell'attendibilità\n",
    "\n",
    "All'interno del problema della costruzione di uno strumento vengono\n",
    "esaminati tre aspetti dell'attendibilità: la consistenza interna, la\n",
    "stabilità e l'equivalenza.\n",
    "\n",
    "### Consistenza interna\n",
    "\n",
    "#### La procedura split-half\n",
    "\n",
    "La consistenza interna misura il grado di coerenza tra gli item che\n",
    "costituiscono lo strumento o le sottoscale dello strumento. Se tutti gli\n",
    "item che costituiscono uno strumento o una sua sottoscala misurano la\n",
    "stessa cosa, allora saranno fortemente associati tra loro. \n",
    "\n",
    "È possibile misurare la consistenza interna con il metodo dello split-half, ovvero mediante la correlazione di Pearson tra i punteggi ottenuti\n",
    "utilizzando ciascuna delle due metà degli item dello strumento. Usando\n",
    "un software, è meglio trovare la media delle correlazioni inter-item\n",
    "ricavabili a partire da tutte le possibili divisioni a metà dell'insieme\n",
    "di item che costituiscono lo strumento. La correlazione trovata in\n",
    "questo modo viene poi corretta utilizzando la formula \"profetica\" di\n",
    "Spearman-Brown per tenere in considerazione il fatto che l'attendibilità\n",
    "è stata calcolata utilizzando soltanto metà degli item dello strumento.\n",
    "\n",
    "Si noti che la formula di Spearman-Brown è basata sull'assunzione che le\n",
    "due metà dello strumento siano parallele, ovvero che abbiano identici\n",
    "punteggi veri e uguali varianze d'errore (questa assunzione comporta la\n",
    "conseguenza per cui le due metà degli item devono producono punteggi aventi la stessa media e la stessa varianza). Se queste assunzioni molto stringenti non vengono\n",
    "soddisfatte, allora la procedura descritta sopra conduce ad una sovrastima dell'attendibilità quale consisenza interna della scala.\n",
    "\n",
    "#### L'analisi della varianza\n",
    "\n",
    "Se tutti gli item di uno strumento o di una sottoscala sono espressione\n",
    "dello stesso costrutto, allora ci dobbiamo aspettare che anche le medie\n",
    "dei punteggi sugli item siano uguali. Come è stato detto sopra, questa è\n",
    "infatti una delle assunzioni delle forme strettamente parallele di un\n",
    "test. È dunque possibile verificare questa assunzione mediante un'ANOVA\n",
    "che sottopone a test l'ipotesi nulla dell'uguaglianza delle\n",
    "medie di gruppi. Nel caso degli item di un test, dato che ciascun soggetto\n",
    "completa tutti gli item che costituiscono lo strumento, è appropriato\n",
    "usare un'ANOVA per misure ripetute che, nella sua declinazione più\n",
    "moderna, corrisponde ad un modello multi-livello (*mixed-effect model*).\n",
    "\n",
    "#### L'indice $\\alpha$ di Cronbach\n",
    "\n",
    "L'indice $\\alpha$ di Cronbach è comunque la misura più utilizzata per valutare\n",
    "l'attendibilità quale consistenza interna di uno strumento. L'$\\alpha$\n",
    "di Cronbach è stato interpretato come la proporzione di varianza della\n",
    "scala che può essere attribuita al fattore comune (DeVellis, 1991). Può\n",
    "anche essere interpretato come la correlazione stimata tra i punteggi\n",
    "della scala e un'altro strumento della stessa lunghezza tratto\n",
    "dall'universo degli item possibili che costituiscono il dominio del\n",
    "costrutto (Kline, 1986). La radice quadrata del coefficiente $\\alpha$ di\n",
    "Cronbach rappresenta la correlazione stimata tra i punteggi ottenuti\n",
    "tramite lo strumento e i punteggi veri (Nunnally & Bernstein, 1994).\n",
    "\n",
    "In precedenza abbiamo descritto una serie di limiti del coefficiente $\\alpha$ di Cronbach. In generale, molti ricercatori suggeriscono di usare al suo posto l'indice $\\omega$ di McDonald.\n",
    "\n",
    "### Stabilità temporale\n",
    "\n",
    "La stabilità temporale viene valutata attraverso la procedura di\n",
    "test-retest. La correlazione tra le misure ottenute in due momenti negli\n",
    "stessi rispondenti ci fornisce l'attendibilità di test-retest.\n",
    "\n",
    "Kline (2000) ha messo in evidenza come l'attendibilità di test-retest\n",
    "sia influenzata da molteplici fattori, tra cui le caratteristiche del\n",
    "campione, la maturità dei rispondenti, i cambiamenti nello stato\n",
    "emozionale, le differenze nelle condizioni di somministrazione del test,\n",
    "la possibilità di ricordare le risposte date in precedenza, la\n",
    "difficoltà degli item, la grandezza del campione e le caratteristiche\n",
    "del costrutto (ad esempio, stato vs. tratto).\n",
    "\n",
    "Particolare attenzione deve essere rivolta all'intervallo temporale\n",
    "usato nella procedura di test-retest. Se il periodo di tempo che\n",
    "intercorre tra le due somministrazioni è troppo corto, i risultati\n",
    "possono risultare distorti a causa del fatto che i soggetti si ricordano\n",
    "le risposte date in precedenza. Questo può condurre ad una sovrastima\n",
    "dell'attendibilità test-retest (Pedhazur & Schmelkin, 1991). Un\n",
    "intervallo temporale troppo lungo tra le due somministrazioni ha invece\n",
    "come limite il fatto che, in questo caso, vi è un'alta possibilità che\n",
    "intervengano dei cambiamenti nei rispondenti rispetto al costrutto in\n",
    "esame. Alla luce di queste considerazioni è stato suggerito di\n",
    "utilizzare un intervallo temporale abbastanza breve, ovvero di una o due\n",
    "settimane (Nunnally & Bernstein, 1994; Pedhazur & Schmelkin, 1991). Se è\n",
    "necessario valutare la stabilità temporale nel corso di un lungo arco\n",
    "temporale, Nunnally e Bernstein (1994) suggeriscono di utilizzare un\n",
    "intervallo di sei mesi o maggiore.\n",
    "\n",
    "### Equivalenza\n",
    "\n",
    "Per cercare di evitare i problemi associati all'attendibilità quale\n",
    "stabilità temporale, alcuni autori si sono posti il problema di\n",
    "esaminare la correlazione tra forme parallele (o equivalenti) dello\n",
    "strumento. La correlazione tra forme parallele di uno strumento va sotto\n",
    "il nome di coefficiente di equivalenza e fornisce una misura alternativa\n",
    "dell'attendibilità dello strumento (Burns & Grove, 2001; Pedhazur &\n",
    "Schmelkin, 1991; Polit & Hungler, 1999).\n",
    "\n",
    "Nunnally e Bernstein (1994) suggeriscono di confrontare i risultati\n",
    "ottenuti con la somministrazione delle forme parallele lo stesso giorno\n",
    "con quelli ottenuti nel caso di un intervallo temporale di due\n",
    "settimane. Kline (2000) ritiene che l'attendibilità tra due forme\n",
    "parallele debba essere di almeno 0.9 perché, per valori inferiori,\n",
    "sarebbe difficile sostenere che le forme sono veramente parallele.\n",
    "\n",
    "È tuttavia molto oneroso predisporre due forme parallele di uno\n",
    "strumento. Per questa ragione, il coefficiente di equivalenza viene\n",
    "raramente usato.\n",
    "\n",
    "## Selezione di un sottoinsieme di item\n",
    "\n",
    "Tipicamente, la costruzione di un test viene realizzata somministrando\n",
    "un grande numero di item per poi selezionare gli item \"migliori\" che\n",
    "andranno a fare parte del test vero e proprio. Si supponga di\n",
    "somministrare inizialmente $m$ item, quando si desidera che il test\n",
    "finale sia costituito da $p < m$ item. Un modo di affrontare questo\n",
    "problema potrebbe essere quello di calcolare l'attendibilità del test\n",
    "(coefficiente $\\omega$) per tutti i possibili sottoinsiemi di $p$ item,\n",
    "così da individuare il sottoinsieme migliore. Questo modo di procedere,\n",
    "però, è problematico perché richiede la valutazione di un elevatissimo\n",
    "numero di possibilità. Per esempio, da un insieme iniziale neanche\n",
    "troppo numeroso di 100 item, il numero di sottoinsiemi di 20 item è\n",
    "uguale a \n",
    "\n",
    "$$\n",
    "\\binom{100}{20} = 5.36 \\times 10^{20}.\n",
    "$$ \n",
    "\n",
    "È dunque necessario trovare metodi alternativi che evitino una tale esplosione combinatoria. A questo fine, ovvero per procedere alla selezione del sottoinsieme dei  \"migliori\" item, {cite:t}`mcdonald2013test` suggerisce di calcolare la *quantità di informazione* di ciascun item. La quantità di informazione di un item è definita come rapporto tra segnale/rumore, in relazione alla scomposizione della varianza dell'item:\n",
    "\n",
    "$$\n",
    "\\frac{\\lambda_i^2}{\\psi_{ii}}.\n",
    "$$ \n",
    "\n",
    "{cite:t}`mcdonald2013test` mostra come l'omissione di uno o più item produce sempre una riduzione dell'attendibilità del test (ovvero, una riduzione nel valore del coefficiente $\\omega$). Tuttavia, tale riduzione è tanto più piccola quanto più piccola è la quantità di informazione degli item omessi. Il processo di selezione degli item può dunque essere guidato da un semplice principio:\n",
    "si selezionano gli item aventi la quantità di informazione maggiore. Ovvero, in altre parole, si rimuovono gli item aventi la quantità di informazione più bassa.\n",
    "\n",
    "**Esempio.** Per fare un esempio, consideriamo nuovamente la matrice di varianze e di covarianze della scala SWLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a29682",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "varnames <- c(\"Y1\", \"Y2\", \"Y3\", \"Y4\", \"Y5\")\n",
    "SWLS <- matrix(c(\n",
    "  2.565, 1.424, 1.481, 1.328, 1.529,\n",
    "  1.424, 2.493, 1.267, 1.051, 1.308,\n",
    "  1.481, 1.267, 2.462, 1.093, 1.360,\n",
    "  1.328, 1.051, 1.093, 2.769, 1.128,\n",
    "  1.529, 1.308, 1.360, 1.128, 3.355\n",
    "),\n",
    "ncol = 5, byrow = TRUE,\n",
    "dimnames = list(varnames, varnames)\n",
    ")\n",
    "SWLS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "495213a4",
   "metadata": {},
   "source": [
    "Utilizzando la funzione `cfa()` contenuta nel pacchetto `lavaan`, il modello\n",
    "ad un fattore viene definito nel modo seguente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626aeb0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mod_1 <- \"\n",
    "  F =~ Y1 + Y2 + Y3 + Y4 + Y5\n",
    "\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63661a79",
   "metadata": {},
   "source": [
    "Otteniamo così una stima dei pesi fattoriali e delle unicità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109beefa",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fit <- lavaan::cfa(\n",
    "  mod_1,\n",
    "  sample.cov = SWLS,\n",
    "  sample.nobs = 215,\n",
    "  std.lv = TRUE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20ad3e42",
   "metadata": {},
   "source": [
    "Calcoliamo la quantità di informazione fornita da ciascun item. Iniziamo a estrarre dall'oggetto `fit` la matrice delle saturazioni fattoriali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65039a39",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "lambda <- inspect(fit, what=\"std\")$lambda\n",
    "lambda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e8ade0c",
   "metadata": {},
   "source": [
    "Estraiamo da `fit` le specificità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087af5b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "theta <- diag(inspect(fit, what=\"std\")$theta)\n",
    "theta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6105258d",
   "metadata": {},
   "source": [
    "Possiamo ora calcolare quantità di informazione degli item facendo il rapporto tra ciascuna saturazione fattoriale innalzata al quadrato e la corrispondente specificità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6de96e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for (i in 1:5) {\n",
    "  print(lambda[i]^2 / theta[i])\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f89acf75",
   "metadata": {},
   "source": [
    "Il risultato ottenuto indica che il quarto item è il meno informativo e che il\n",
    "quinto item è il secondo meno informativo. Se un solo item deve essere\n",
    "eliminato, dunque, elimineremo il quarto item. Se devono essere\n",
    "eliminati due item, andranno eliminati il quarto e il quinto\n",
    "item.\n",
    "\n",
    "\n",
    "### Attendibilità e numero di item \n",
    "\n",
    "Di quanto cambia l'attendibilità di uno strumento se viene variato il\n",
    "numero di item? Una risposta a questa domanda può essere fornita dalla\n",
    "formula profetica di Spearman-Brown. Supponiamo che nella formula di\n",
    "Spearman-Brown, \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\rho_p = \\frac{p \\rho_1}{(p-1)\\rho_1 + 1},\n",
    "\\end{equation}\n",
    "$$(eq-spearman-brown)\n",
    " \n",
    "$\\rho_1$ rappresenti l'attendibilità di un test costituito da un certo numero di item. Se poniamo $p=2$, la {eq}`eq-spearman-brown` ci fornisce una stima dell'attendibilità che si otterrebbe raddoppiando il numero di item nel test. Valori di $p$ minori di $1$, invece, vengono usati per predire la diminuizione dell'attendibilità conseguente ad una diminuzione nel numero degli item del test.\n",
    "\n",
    "Ricordiamo però che le predizioni della formula di Spearman-Brown sono\n",
    "accurate solo se la forma allungata o accorciata del test è parallela rispetto al\n",
    "test considerato. Per esempio, se ad un test con un coefficiente di\n",
    "attendibilità molto alto vengono aggiunti item aventi una bassa\n",
    "attendibilità, allora l'attendibilità del test allungato sarà minore di\n",
    "quella predetta dalla formula di Spearman-Brown.\n",
    "\n",
    "Anche se la formula di Spearman-Brown ha un ruolo centrale nella teoria\n",
    "classica dei test, si tenga conto che non rappresenta l'unico strumento\n",
    "che può essere utilizzato per valutare la relazione tra attendibilità e numero degli item del test. La quantità detta *informazione dell'item* (*item information*), formulata dai modelli IRT, consente di predire i cambiamenti nella qualità della misura a seguito dell'aggiunta o della cancellazione di un sottoinsieme di item.\n",
    "\n",
    "**Esempio.** Si consideri la scala SWLS. Chiediamoci come varia l'attendibilità della\n",
    "scala se il numero di item aumenta da 5 a 20. Poniamo che l'attendibilità della\n",
    "scala SWLS costituita da 5 item sia uguale a 0.824. Applicando la formula di\n",
    "Spearman-Brown otteniamo la stima seguente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d9065",
   "metadata": {
    "lines_to_next_cell": 0,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "(4 * 0.824) / ((4 - 1) * 0.824 + 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d98e135",
   "metadata": {},
   "source": [
    "**Esempio.** Possiamo giungere al risultato precedente in un altro modo. Supponiamo che i 15 item aggiuntivi abbiano le stesse saturazioni fattoriali medie ($\\bar{\\lambda}$) e le stesse varianze specifiche medie ($\\bar{\\psi}$) rispetto agli item originali.\n",
    "Mediante gli item di cui disponiamo, stimiamo l'attendibilità di un\n",
    "\"item medio\" nel modo seguente\n",
    "\n",
    "$$\n",
    "\\rho_1 = \\frac{\\bar{\\lambda}^2}{\\bar{\\lambda}^2 + \\bar{\\psi}},\n",
    "$$\n",
    "\n",
    "ovvero otteniamo la stima di 0.48:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1bfa65",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rho_1 <- mean(lambda)^2 / (mean(lambda)^2 + mean(theta)) \n",
    "rho_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07d47286",
   "metadata": {},
   "source": [
    "L'attendibilità predetta di un test costituito da 20 item sarà dunque\n",
    "uguale a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f824d37e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "(20 * rho_1) / ((20 - 1) * rho_1 + 1) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f55d1787",
   "metadata": {},
   "source": [
    "il che replica il risultato ottenuto precedentemente.\n",
    "\n",
    "**Esempio.** Un altro modo ancora per ottenere lo stesso risultato è quello di utilizzare \n",
    "un modello mono-fattoriale per item paralleli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fee507b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mod_2 <- \"\n",
    "  F =~ a*Y1 + a*Y2 + a*Y3 + a*Y4 + a*Y5\n",
    "  Y1 ~~ b*Y1\n",
    "  Y2 ~~ b*Y2\n",
    "  Y3 ~~ b*Y3\n",
    "  Y4 ~~ b*Y4\n",
    "  Y5 ~~ b*Y5\n",
    "\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d6ac026",
   "metadata": {},
   "source": [
    "Adattiamo il modello ai dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769228ee",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fit2 <- lavaan::cfa(\n",
    "  mod_2,\n",
    "  sample.cov = SWLS,\n",
    "  sample.nobs = 215,\n",
    "  std.lv = TRUE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11541bfb",
   "metadata": {},
   "source": [
    "Estraiamo dall'oggetto `fit2` le saturazioni fattoriali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b699f0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "lambda <- inspect(fit2, what=\"std\")$lambda\n",
    "lambda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cfa63d2",
   "metadata": {},
   "source": [
    "Estraiamo da `fit2` le specificità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff5041",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "theta <- diag(inspect(fit2, what=\"std\")$theta)\n",
    "theta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b47f946b",
   "metadata": {},
   "source": [
    "Calcoliamo l'attendibilità dell'item \"medio\" usando $\\lambda$ e $\\psi$ (chiamato `theta` da `lavaan`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edbd4c5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rho_1 <- lambda[1]^2 / (lambda[1]^2 + theta[2])\n",
    "rho_1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb9c9992",
   "metadata": {},
   "source": [
    "Posso ora applicare la formula di Spearman-Brown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6d387",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "(20 * rho_1) / ((20 - 1) * rho_1 + 1) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1755bfd",
   "metadata": {},
   "source": [
    "Il risultato è praticamente identico a quelli trovati in precedenza.\n",
    "\n",
    "### Numero di item e affidabilità\n",
    "\n",
    "La formula di Spearman-Brown può anche essere riarrangiata in maniera tale da consentirci di predire il numero degli item necessari per raggiungere un determinato livello di affidabilità: \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "p = \\frac{\\rho_p (1-\\rho_1)}{\\rho_1(1-\\rho_p)}, \n",
    "\\end{equation}\n",
    "$$(eq-s-b-inv)\n",
    "\n",
    "dove $\\rho_1$ è l'attendibilità stimata di un \"item medio,\" $\\rho_p$ è il livello desiderato di attendibilità del test allungato e $p$ è il numero di item del test allungato.\n",
    "\n",
    "**Esempio.** L'attendibilità della scala SWLS costituita da 5 item è\n",
    "$\\omega = 0.824$. Quanti item devono essere aggiunti se si vuole\n",
    "raggiungere un livello di attendibilità pari a $0.95$?\n",
    "\n",
    "Ponendo $\\rho_p = 0.95$ e $\\rho_1= 0.479$, in base alla {eq}`eq-s-b-inv` si ottiene che"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807193d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "(.95 * (1 - rho_1)) / (rho_1 * (1 - .95))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc8e6826",
   "metadata": {},
   "source": [
    "il test dovrà essere costituito da 21 item.\n",
    "\n",
    "## Analisi degli item\n",
    "\n",
    "L'analisi degli item svolge un ruolo importante nello sviluppo e nella revisione dei test psicometrici. L'analisi degli item esamina le risposte fornite ai singoli item del\n",
    "questionario allo scopo di valutare la qualità degli item e del\n",
    "questionario nel suo complesso. Sotto al rubrica di analisi degli item\n",
    "possiamo raggruppare le procedure che possono essere utilizzate per\n",
    "descrivere la difficoltà degli item, le relazioni tra coppie di item, il\n",
    "punteggio totale del test, le relazioni tra gli item e il punteggio\n",
    "totale del test. Tali analisi statistiche vengono usate per la selezione\n",
    "degli item al fine di costruire un questionario omogeneo, attendibile e\n",
    "dotato di validità predittiva.\n",
    "\n",
    "La selezione degli item di un test, però, non può essere svolta in maniera automatica usando soltanto criteri statistici quali quelli elencati sopra. La selezione degli item, invece, deve anche tenere includere considerazioni di ordine teorico basate sulla centralità degli item rispetto alla definizione del costrutto e considerazioni relative agli scopi della misurazione e al modo in cui l'item è stato formulato e costruito. Se alcuni aspetti di un costrutto non vengono rappresentanti da item che\n",
    "soddisfano i criteri statistici descritti sopra, o se c'è un numero insufficiente\n",
    "di item per produrre uno strumento attendibile, allora alcuni item\n",
    "dovranno essere riscritti. Nella riformulazione degli item, risultano utili le\n",
    "intuizioni che si sono guadagnate dalle analisi statistiche degli item che si sono dovuti scartare.\n",
    "\n",
    "### Difficoltà degli item\n",
    "\n",
    "Una statistica comune da calcolare durante l'analisi degli item è la proporzione di esaminandi che rispondono correttamente ad ogni item. Questa è nota come *difficoltà dell'item*, *p*. La proporzione $p_j$ di partecipanti che rispondono\n",
    "correttamente all'item $j$-esimo, o proporzione di partecipanti che si dichiarano in accordo con l'affermazione espressa dall'item, se il test non è di prestazione, fornisce una stima del *livello di difficoltà* $\\pi_j$ dell'item. \n",
    "\n",
    "In realtà, $p_j$ dovrebbe essere chiamato \"facilità dell'item\" in quanto assume il suo valore maggiore (ovvero $1$) quando tutti i rispondenti rispondono correttamente\n",
    "all'item e il suo valore minimo (ovvero $0$) quando le risposte sono tutte sbagliate. Questo valore non va confuso con la difficoltà dell'item nella teoria della risposta agli item o con il valore-$p$ dei test di ipotesi frequentisti. \n",
    "\n",
    "I valori $p_j$ giocano un ruolo importante nelle procedure di selezione degli item. La difficoltà degli item deve essere interpretata in riferimento alla\n",
    "probabilità di indovinare la risposta corretta. Si suppone, infatti, che\n",
    "i rispondenti tirino ad indovinare quando non conoscono la risposta alla\n",
    "domanda di un questionario. Nel caso di item dicotomici, per esempio, ci\n",
    "possiamo aspettare un valore $p_j$ pari a $0.50$ sulla base del caso\n",
    "soltanto; nel caso di item a risposta multipla con quattro opzioni di\n",
    "scelta, invece, $p_j$ assume un valore pari a $0.25$ quando i\n",
    "rispondenti tirano ad indovinare.\n",
    "\n",
    "Se il test è composto per la maggior parte da item \"facili\", allora il\n",
    "test non sarà in grado di discriminare tra rispondenti con diversi livelli di\n",
    "abilità, in quanto quasi tutti i rispondenti saranno in grado di\n",
    "fornire una risposta corretta alla maggioranza degli item. Lo stesso si\n",
    "può dire per un test composto da item \"difficili\". Se il test è composto unicamente da item di difficoltà media, non potrà differenziare i rispondenti che hanno un grado di abilità media da quelli con abilità superiori alla media, dato che non ci sono item \"difficili\", e neppure da quelli con abilità inferiori alla media, dato\n",
    "che non ci sono item \"facili\". \n",
    "\n",
    "In generale, dunque, è buona pratica costruire test composti da item che coprano\n",
    "tutti i livelli di difficoltà. La scelta che viene usualmente fatta è\n",
    "quella di una dispersione moderata e simmetrica del livello di\n",
    "difficoltà attorno ad un valore leggermente superiore al valore che sta\n",
    "a metà tra il livello del caso ($1.0$ diviso per il numero di\n",
    "alternative) e il punteggio pieno ($1.0$). \n",
    "\n",
    "Per item che presentano cinque alternative di risposta, ad esempio, il livello del caso è pari a $1.0 / 5 = 0.20$. Il livello ottimale di difficoltà è uguale a \n",
    "\n",
    "$$\n",
    "0.20 + (1.0 - 0.20) / 2 = 0.60.\n",
    "$$ \n",
    "    \n",
    "Per item dicotomici, il livello del caso è $1.0 / 2 = 0.50$ e il livello ottimale di difficoltà è uguale a \n",
    "\n",
    "$$\n",
    "0.50 + (1.00 - 0.50) / 2 = 0.75.\n",
    "$$ \n",
    "\n",
    "In generale, item con livelli di difficoltà superiore a $0.90$ o inferiore a $0.20$ dovrebbero essere utilizzati con cautela.\n",
    "\n",
    "**Esempio.** Riporto qui sotto le proporzioni di risposte corrette (usando la correzione per il guessing) di 192 studenti di Psicometria nel primo parziale dell'AA 2021/2022. Il test aveva 16 item con 5 alternative di risposta ciascuno. Dunque la difficoltà media ottimale è pari a 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fcddd1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "item_par_1 <- c(\n",
    "  0.54255319, 0.76063830, 0.64361702, 0.65957447, 0.67021277, 0.12234043,\n",
    "  0.14361702, 0.18085106, 0.76063830, 0.82978723, 0.81914894, 0.84042553,\n",
    "  0.07978723, 0.07978723, 0.76063830, 0.79255319\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4df1b5a",
   "metadata": {},
   "source": [
    "Nel compito, la difficoltà media è risultata essere un po' inferiore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1119a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mean(item_par_1) %>% \n",
    "  round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "737e8b37",
   "metadata": {},
   "source": [
    "La distribuzione dei livelli di difficoltà degli item suggerisce che forse alcuni item \"difficili\" si sarebbero potuti sostituire con item di difficoltà media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9539ad",
   "metadata": {
    "lines_to_next_cell": 0,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(density(item_par_1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8dd3cc6",
   "metadata": {},
   "source": [
    ":::\n",
    "\n",
    "Un altro esempio riguarda il data set `SAPA` del pacchetto `hemp`. Per questi dati possiamo utilizzare la funzione `colMeans` per calcolare la difficoltà degli item. Poiché abbiamo dei partecipanti che hanno risposte mancanti su alcuni item, dobbiamo passare l'argomento `na.rm = TRUE` per ignorare i dati mancanti. In caso contrario, la funzione `colMeans` restituirebbe `NA` per gli item che hanno almeno un valore mancante. Per rendere più leggibili i valori di difficoltà degli item, arrotondiamo a tre decimali utilizzando la funzione `round`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd5126c",
   "metadata": {
    "lines_to_next_cell": 0,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "item_diff <- colMeans(SAPA, na.rm = TRUE)\n",
    "round(item_diff, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f78f2eee",
   "metadata": {},
   "source": [
    "L'output mostra che gli item `reason.16` e `reason.17` ottengono i livelli di difficoltà  più alti, mentre `rotate.8` ha il livello di difficoltà più basso. Circa il 70% degli studenti è stato in grado di rispondere correttamente a `reason.16` e `reason.17`, mentre solo il 19% ha risposto correttamente a `rotate.8`.\n",
    "\n",
    "### Correzione per guessing\n",
    "\n",
    "Alle volte i valori $p_j$ sono calcolati introducendo una correzione per\n",
    "le risposte fornite casualmente dai soggetti (*guessing*). Si consideri\n",
    "un test a scelta multipla composto da item aventi ciascuno $C$\n",
    "alternative di risposta ed una sola risposta corretta. Si supponga che\n",
    "un rispondente risponda correttamente a $R$ item e risponda in maniera\n",
    "sbagliata a $W$ item.\n",
    "\n",
    "La correzione per guessing si ottiene applicando una formula basata sul\n",
    "seguente ragionamento. Se assumiamo che un rispondente si limita a\n",
    "tirare ad indovinare allora, ogni $C$ risposte, ci aspettiamo 1 risposta\n",
    "giusta e $C-1$ risposte sbagliate. Per calcolare il punteggio totale del\n",
    "test in modo da eliminare il numero di risposte corrette ottenute\n",
    "tirando ad indovinare è necessario sottrarre 1 punto per ogni $C-1$ item\n",
    "a cui è stata fornita una risposta corretta. Questo ragionamento conduce\n",
    "alla seguente formula: \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "FS = R - \\frac{W}{C - 1},\n",
    "\\end{equation}\n",
    "$$(eq-guessing)\n",
    "\n",
    "con $R$ = \\# risposte corrette, $W$ = \\# risposte\n",
    "sbagliate, $C$ = \\# alternative di risposta. Per esempio, se $C=5$,\n",
    "allora è necessario sottrarre un punto ogni 4, il che è proprio quello\n",
    "che fa la {eq}`eq-guessing`. \n",
    "\n",
    "La {eq}`eq-guessing` produce un punteggio totale corretto per il guessing identico a quello che si otterrebbe assegnando 1 punto a ciascuna risposta corretta e assegnando $- \\frac{1}{C-1}$ punti alle risposte sbagliate; le risposte non date non vengono considerate.\n",
    "\n",
    "La correzione per guessing rappresenta il tentativo di scomporre il\n",
    "numero totale di risposte corrette in due componenti: le risposte\n",
    "corrette dovute alle conoscenze del soggetto, le risposte che risultano\n",
    "corrette come effetto del caso. La stessa formula può anche essere\n",
    "utilizzata per calcolare la difficoltà degli item corretta per il guessing (come è stato fatto nell'esempio del parziale di Psicometria).\n",
    "\n",
    "### Discriminatività\n",
    "\n",
    "La discriminatività è una misura di quanto ogni item è in grado di\n",
    "distinguere i soggetti con elevati livelli nel costrutto da quelli con\n",
    "un livello basso. L'indice di discriminatività $D$ per i test di\n",
    "prestazione massima si trova nel modo seguente. Dopo avere calcolato il\n",
    "punteggio totale al test, si dividono i soggetti in due gruppi: soggetti\n",
    "con basso punteggio e soggetti con alto punteggio. Una volta definiti i\n",
    "due gruppi, l'indice di discriminatività $D$ sarà dato da:\n",
    "\n",
    "$$D = P(\\text{alto}) - P(\\text{basso}),$$ \n",
    "\n",
    "dove $P(\\text{alto}$ è la proporzione di soggetti che ha risposto correttamente all'item nel gruppo con punteggi alti e $P(\\text{basso}$ è la proporzione di soggetti\n",
    "che ha risposto correttamente all'item nel gruppo con punteggi bassi. Il\n",
    "valore di $D$ può variare da -1 a +1. Nella tabella seguente sono fornite le linee guida per l'interpretazione di questo indice (Ebel, 1965).\n",
    "\n",
    "  | Valore di $D$       |   Commento |\n",
    "  | ------------------- | ------------------------------------------ |\n",
    "  | $D \\geq 0.40$        |  Ottima, nessuna revisione |\n",
    "  | $0.30 \\leq D < 0.40$ |  Buona, revisioni minime |\n",
    "  | $0.20 \\leq D < 0.30$ |  Sufficiente, revisioni parziali |\n",
    "  | $D < 0.20$           |  Insufficiente, riformulazione o eliminazione |\n",
    "\n",
    "La discriminatività degli item di tipo Likert viene valutata con la\n",
    "medesima procedura degli item dei testi di prestazione massima, anche se\n",
    "cambiano le procedure statistiche da utilizzare. Si può dividere la\n",
    "distribuzione dei punteggi totali (o punteggi medi) in quartili e\n",
    "confrontare il punteggio medio o mediano del quartile superiore con\n",
    "quello del quartile inferiore, oppure, se il test è orientato al\n",
    "criterio e lo scopo è selezionare gli item che discriminano meglio due\n",
    "gruppi precostituiti di soggetto, eseguire i medesimi confronti tra il\n",
    "gruppo target (ad esempio, pazienti) e quello \"di controllo\" (per\n",
    "esempio, popolazione generale). \n",
    "\n",
    "È consigliabile valutare la dimensione dell'effetto, ad esempio attraverso l'indice $d$ di Cohen. La dimensione dell'effetto dovrebbe essere almeno moderata ($d > |0.50|$).\n",
    "\n",
    "**Esempio.** Per il primo parziale di Psicometria AA 2021/2022, l'indice $d$ di Cohen calcolato sulla proporzione di risposte corrette per il gruppo di studenti con i punteggi più bassi (primo quartile) e il gruppo di studenti con i punteggi più alti (ultimo quartile) è stato di 4.76, 95% CI [4.0, 5.51]. L'indice *complessivo* di discriminatività sembra dunque adeguato. Sarebbe però necessario calcolare questo indice item per item."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be52fdd8",
   "metadata": {},
   "source": [
    "### Potere discriminante dell'item e analisi fattoriale\n",
    "\n",
    "Un'altra statistica ampiamente utilizzata nell'analisi degli item è il potere discriminante degli item, che si riferisce alla capacità dell'item nel distinguere gli esaminandi con una alta abilità da quelli con una bassa abilità. Sebbene esistano molti modi per calcolare la discriminazione degli item, la forma più comune è la correlazione punto-biseriale tra le risposte degli esaminandi all'item e il loro punteggio totale nel test. Valori grandi e positivi indicano una forte relazione tra il rispondere correttamente all'item e avere un punteggio alto nel test, mentre valori vicini allo zero indicano nessuna relazione e valori negativi indicano che il rispondere correttamente all'item è associato a un punteggio complessivo del test più basso. Valori vicini allo zero o negativi suggeriscono che l'item potrebbe non funzionare correttamente. Alcune delle ragioni per ottenere una discriminazione degli item bassa o negativa potrebbero essere l'utilizzo di una chiave di risposta errata per l'item o l'assenza di risposte corrette. Indipendentemente dalla causa, gli item con correlazioni punto-biseriale basse o negative devono essere modificati, se il test/strumento è in fase di revisione, o rimossi dal test e dal punteggio.\n",
    "\n",
    "Per calcolare il potere discriminante dell'item per i dati SAPA, prima calcoliamo il punteggio totale del test utilizzando la funzione `rowSums` insieme all'opzione `na.rm = TRUE` e lo salviamo come `total_score`. Successivamente, correlaziamo gli item in SAPA con il punteggio totale del test utilizzando la funzione `cor`. Specificamente, usiamo l'argomento `use = \"pairwise.complete.obs\"` nella funzione `cor` a causa della presenza di risposte mancanti. Infine, salviamo la matrice di correlazione come `item_discr` e la stampiamo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2013d1f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "total_score <- rowSums(SAPA, na.rm = TRUE)\n",
    "item_discr <- cor(SAPA, total_score, use = \"pairwise.complete.obs\")\n",
    "round(item_discr, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2027abf",
   "metadata": {},
   "source": [
    "I risultati mostrano che tutti gli item del test SAPA sono moderatamente e positivamente correlati con il punteggio totale del test. Questo indica che tutti gli item funzionano correttamente e non fornisce informazioni salienti su quali item rimuovere o modificare.\n",
    "\n",
    "Un altro modo per calcolare il potere discriminante degli item consiste nel dividere i candidati in due gruppi (ad esempio, 1 = alto rendimento e 0 = basso rendimento) in base ai loro punteggi totali nel test e correlare questa variabile di raggruppamento con le risposte agli item. Questo è noto come *indice di discriminazione degli item*. Un'opzione per creare gruppi di alto e basso rendimento è selezionare il 25% più alto e il 25% più basso dei candidati in base ai loro punteggi totali nel test. Va notato che la decisione di utilizzare il 25% è arbitraria. Potremmo utilizzare un altro valore (ad esempio, il 10% o il 20%) per definire i gruppi di alto e basso rendimento. Dopo aver definito il punto di cut-off per i gruppi, calcoliamo la proporzione di candidati che hanno risposto correttamente all'elemento nei gruppi di alto e basso rendimento.\n",
    "\n",
    "Nell'esempio seguente, calcoliamo l'indice di discriminazione dell'elemento `reason.4` nel set di dati SAPA utilizzando la funzione `idi` del pacchetto `hemp`. Per specificare i gruppi di alto e basso rendimento, utilizziamo il valore `perc_cut = .25` nella funzione `idi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840985ee",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "idi(SAPA, SAPA$reason.4, perc_cut = .25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf08f99f",
   "metadata": {},
   "source": [
    "Abbiamo scoperto che l'81% dei candidati nel gruppo di alto rendimento ha risposto correttamente all'item `reason.4`, mentre solo il 19% dei candidati nel gruppo di basso rendimento ha risposto correttamente. Questo suggerisce che l'item era più facile per i candidati di alto rendimento e più difficile per quelli di basso rendimento. Pertanto, possiamo dire che questo particolare item risulta utile per differenziare i due gruppi, ma non necessariamente all'interno di ciascun gruppo.\n",
    "\n",
    "Secondo McDondald (1999), la nozione di potere discriminante dell'item\n",
    "può essere trattata in maniera più precisa nell'ambito del modello\n",
    "monofattoriale. Se l'insieme di item a disposizione non è eccessivamente\n",
    "grande (200 o meno), infatti, è possibile procedere alla selezione degli\n",
    "item migliori tramite l'analisi fattoriale -- ovvero, scegliendo gli\n",
    "item con le saturazioni maggiori."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eb2ec72",
   "metadata": {},
   "source": [
    "### Punteggio sull'item e punteggio totale\n",
    "\n",
    "Il grado di associazione tra il punteggio sull'item e il punteggio\n",
    "totale viene considerato dalla teoria classica dei test come un indice che descrive il potere discriminante dell'item. Se il test fornisce una misura\n",
    "attendibile di un unico attributo, e se un item è fortemente associato\n",
    "al punteggio del test, allora l'item sarà in grado di\n",
    "distinguere tra rispondenti che ottengono un punteggio basso nel test e\n",
    "rispondenti che ottengono un punteggio alto nel test.\n",
    "\n",
    "Nel caso di una forte associazione positiva tra il punteggio sull'item e\n",
    "il punteggio totale, la probabilità di risposta corretta sull'item è\n",
    "alta per rispondenti che ottengono un punteggio totale alto, e bassa per\n",
    "i rispondenti che ottengono un punteggio totale basso. Nel caso di una\n",
    "debole associazione tra il punteggio sull'item e il punteggio totale,\n",
    "invece, la probabilità di risposta corretta all'item non è predittiva\n",
    "del punteggio totale. Gli item con un basso potere discriminante\n",
    "dovrebbero dunque essere rimossi dal reattivo.\n",
    "\n",
    "È necessario distinguere i casi in cui gli item sono dicotomici dal caso\n",
    "di item continui. Nel caso di item dicotomici e di un test\n",
    "unidimensionale, il potere discriminante viene calcolato mediante la\n",
    "correlazione biseriale o punto-biseriale.\n",
    "\n",
    "### Relazioni tra coppie di item\n",
    "\n",
    "Le relazioni tra coppie di item sono importanti sia per la costruzione\n",
    "sia per la validazione dei test psicometrici. La teoria classica dei test definisce\n",
    "l'attendibilità di un test (o di un item) come il rapporto tra la\n",
    "varianza del punteggio vero e la varianza del punteggio osservato. Il\n",
    "coefficiente di attendibilità può però essere calcolato anche trovando\n",
    "la correlazione tra due forme parallele di un test (o tra due item).\n",
    "Inoltre, è possibile interpretare la correlazione tra due forme\n",
    "parallele di un test (o tra due item) come il quadrato del coefficiente\n",
    "di correlazione tra i punteggi osservati e i punteggi veri di un test (o\n",
    "di un item).\n",
    "\n",
    "Molti indici sono disponibili per misurare il grado di associazione tra item. Per item quantitativi, possiamo usare la correlazione di Pearson o la covarianza. Per item qualitativi politomici ordinali, usiamo la correlazione policorica. Per item ordinali dicotomici, usiamo la correlazione tetracorica. Per item dicotomici usiamo, ad esempio, l'indice $\\phi$.\n",
    "\n",
    "### Ridondanza\n",
    "\n",
    "Nel processo di raffinamento del test occorre anche tenere conto degli item\n",
    "ridondanti, ossia degli item che sono troppo associati tra loro. La\n",
    "ridondanza può essere valutata con indici statistici quali la\n",
    "correlazione: se due o più item hanno tra loro una correlazione maggiore\n",
    "di $|0.70|$ viene mantenuto nell'item pool solo uno di essi, dato che gli\n",
    "altri item forniscono la stessa informazione.\n",
    "\n",
    "### Massimizzazione della varianza del punteggio totale\n",
    "\n",
    "Uno dei criteri che possono essere utilizzati per la selezionare degli item\n",
    "che andranno a costituire la versione finale di un test è la massimizzazione della varianza del punteggio totale. Più in particolare, si vuole massimizzare il rapporto tra la varianza del punteggio totale e la somma delle varianze dei punteggi dei $p$ item. Dato che il coefficiente $\\alpha$ di Cronbach ha la seguente forma:\n",
    "\n",
    "$$\\alpha = \\frac{p}{p-1}\\left[1- \\frac{\\sum \\sigma^2_{Y_i}}{\\sigma^2_T} \\right],$$\n",
    "\n",
    "la scelta di massimizzare il rapporto definito in precedenza avrà anche\n",
    "la conseguenza di massimizzare $\\alpha$.\n",
    "\n",
    "{cite:t}`mcdonald2013test` fa notare che una procedura di selezione degli item\n",
    "basata sul principio della massimizzazione di $\\alpha$ ha però dei\n",
    "limiti. In primo luogo, tale procedura è appropriata solo quando\n",
    "l'insieme di item è troppo grande per selezionare gli item in base\n",
    "all'esame delle saturazioni fattoriali ottenute applicando il modello\n",
    "mono-fattoriale. In secondo luogo, {cite:t}`mcdonald2013test` nota che la procedura di selezione basata sulla massimizzazione di $\\alpha$ è adeguata solo nel caso di una struttura mono-fattoriale. La selezione degli item basata sulla massimizzazione di $\\alpha$  deve dunque essere accompagnata da considerazione relative al contenuto e alla struttura del costrutto.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5506ddb",
   "metadata": {},
   "source": [
    "### Indice di affidabilità dell'item\n",
    "\n",
    "Oltre agli indici di difficoltà e discriminazione degli item, un'altra statistica utile per l'analisi degli item è l'indice di affidabilità dell'item. L'indice di affidabilità dell'item (IRI) è definito come:\n",
    "\n",
    "$$\n",
    "IRI = S_i \\cdot r_{i,tt},\n",
    "$$\n",
    "\n",
    "dove $S_i$ è la deviazione standard dell'item $i$ e $r_{i,tt}$ è la correlazione tra l'item $i$ e il punteggio totale del test. L'IRI può teoricamente variare tra -0.5 e 0.5, con valori grandi e positivi indicativi di alta affidabilità. \n",
    "\n",
    "Di seguito calcoliamo l'IRI per tutti gli item nel set di dati SAPA. Possiamo farlo utilizzando la funzione `iri` in `hemp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bee395f0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 16 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>reason.4</th><td>0.2820989</td></tr>\n",
       "\t<tr><th scope=row>reason.16</th><td>0.2451971</td></tr>\n",
       "\t<tr><th scope=row>reason.17</th><td>0.2692675</td></tr>\n",
       "\t<tr><th scope=row>reason.19</th><td>0.2717135</td></tr>\n",
       "\t<tr><th scope=row>letter.7</th><td>0.2865325</td></tr>\n",
       "\t<tr><th scope=row>letter.33</th><td>0.2757209</td></tr>\n",
       "\t<tr><th scope=row>letter.34</th><td>0.2897118</td></tr>\n",
       "\t<tr><th scope=row>letter.58</th><td>0.2863221</td></tr>\n",
       "\t<tr><th scope=row>matrix.45</th><td>0.2544930</td></tr>\n",
       "\t<tr><th scope=row>matrix.46</th><td>0.2562540</td></tr>\n",
       "\t<tr><th scope=row>matrix.47</th><td>0.2668171</td></tr>\n",
       "\t<tr><th scope=row>matrix.55</th><td>0.2161230</td></tr>\n",
       "\t<tr><th scope=row>rotate.3</th><td>0.2016459</td></tr>\n",
       "\t<tr><th scope=row>rotate.4</th><td>0.2276081</td></tr>\n",
       "\t<tr><th scope=row>rotate.6</th><td>0.2539219</td></tr>\n",
       "\t<tr><th scope=row>rotate.8</th><td>0.1867207</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 16 × 1 of type dbl\n",
       "\\begin{tabular}{r|l}\n",
       "\treason.4 & 0.2820989\\\\\n",
       "\treason.16 & 0.2451971\\\\\n",
       "\treason.17 & 0.2692675\\\\\n",
       "\treason.19 & 0.2717135\\\\\n",
       "\tletter.7 & 0.2865325\\\\\n",
       "\tletter.33 & 0.2757209\\\\\n",
       "\tletter.34 & 0.2897118\\\\\n",
       "\tletter.58 & 0.2863221\\\\\n",
       "\tmatrix.45 & 0.2544930\\\\\n",
       "\tmatrix.46 & 0.2562540\\\\\n",
       "\tmatrix.47 & 0.2668171\\\\\n",
       "\tmatrix.55 & 0.2161230\\\\\n",
       "\trotate.3 & 0.2016459\\\\\n",
       "\trotate.4 & 0.2276081\\\\\n",
       "\trotate.6 & 0.2539219\\\\\n",
       "\trotate.8 & 0.1867207\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 16 × 1 of type dbl\n",
       "\n",
       "| reason.4 | 0.2820989 |\n",
       "| reason.16 | 0.2451971 |\n",
       "| reason.17 | 0.2692675 |\n",
       "| reason.19 | 0.2717135 |\n",
       "| letter.7 | 0.2865325 |\n",
       "| letter.33 | 0.2757209 |\n",
       "| letter.34 | 0.2897118 |\n",
       "| letter.58 | 0.2863221 |\n",
       "| matrix.45 | 0.2544930 |\n",
       "| matrix.46 | 0.2562540 |\n",
       "| matrix.47 | 0.2668171 |\n",
       "| matrix.55 | 0.2161230 |\n",
       "| rotate.3 | 0.2016459 |\n",
       "| rotate.4 | 0.2276081 |\n",
       "| rotate.6 | 0.2539219 |\n",
       "| rotate.8 | 0.1867207 |\n",
       "\n"
      ],
      "text/plain": [
       "          [,1]     \n",
       "reason.4  0.2820989\n",
       "reason.16 0.2451971\n",
       "reason.17 0.2692675\n",
       "reason.19 0.2717135\n",
       "letter.7  0.2865325\n",
       "letter.33 0.2757209\n",
       "letter.34 0.2897118\n",
       "letter.58 0.2863221\n",
       "matrix.45 0.2544930\n",
       "matrix.46 0.2562540\n",
       "matrix.47 0.2668171\n",
       "matrix.55 0.2161230\n",
       "rotate.3  0.2016459\n",
       "rotate.4  0.2276081\n",
       "rotate.6  0.2539219\n",
       "rotate.8  0.1867207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iri(SAPA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3dad12f",
   "metadata": {},
   "source": [
    "I risultati restituiti dalla funzione `iri` mostrano che l'IRI varia da circa 0.19 a 0.29 per il set di dati SAPA. Tutti questi sono valori ragionevoli per l'IRI (ovvero nessuno è negativo o vicino allo zero).\n",
    "\n",
    "### Indice di validità dell'item\n",
    "\n",
    "Quando invece del punteggio totale del test viene utilizzato un criterio esterno, questo indice è noto come *indice di validità dell'item* (IVI). L'IVI può variare anche tra -0.5 e 0.5, con valori elevati (in valore assoluto) che indicano una validità maggiore. Valori negativi elevati indicano una maggiore validità quando ci si aspetta che gli elementi siano correlati in modo negativo con il criterio.\n",
    "\n",
    "Nell'esempio seguente, utilizziamo la funzione `ivi` in `hemp` con \"reason.17\" come criterio esterno e \"reason.4\" come elemento di interesse e troviamo che l'IVI è 0.19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a10c874",
   "metadata": {
    "lines_to_next_cell": 2,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.190321881267834"
      ],
      "text/latex": [
       "0.190321881267834"
      ],
      "text/markdown": [
       "0.190321881267834"
      ],
      "text/plain": [
       "[1] 0.1903219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ivi(item = SAPA$reason.4, crit = SAPA$reason.17)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5710629f",
   "metadata": {},
   "source": [
    "### Distrattori\n",
    "\n",
    "Un altro aspetto importante degli elementi che deve essere analizzato sono le opzioni di risposta. Nel contesto dei test a scelta multipla, le opzioni di risposta alternative (cioè sbagliate) vengono definite \"distrattori\". I distrattori svolgono un ruolo importante in un elemento a scelta multipla. Per garantire elementi a scelta multipla di alta qualità, è cruciale includere distrattori plausibili e ben funzionanti che siano più probabili di attirare i candidati con conoscenze parziali. I distrattori non plausibili potrebbero dover essere riscritti o sostituiti con un distrattore migliore. La qualità dei distrattori viene tipicamente valutata attraverso l'analisi dei distrattori. L'analisi dei distrattori viene spesso condotta osservando la proporzione di candidati che scelgono un distrattore particolare.\n",
    "\n",
    "Per illustrare l'analisi dei distrattori, utilizziamo gli item del data set `multiplechoice` in `hemp`. Si tratta di un ipotetico test a scelta multipla composto da 27 item somministrati a 496 candidati. Le quattro opzioni di risposta sono codificate come 1, 2, 3 e 4 nel data set. Utilizziamo la funzione `distract` in `hemp` per calcolare la proporzione di candidati che selezionano ciascun distrattore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35811d27",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 6 × 4 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>1</th><th scope=col>2</th><th scope=col>3</th><th scope=col>4</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>item1</th><td>0.044</td><td>0.058</td><td>0.052</td><td>0.845</td></tr>\n",
       "\t<tr><th scope=row>item2</th><td>0.109</td><td>0.069</td><td>0.792</td><td>0.030</td></tr>\n",
       "\t<tr><th scope=row>item3</th><td>0.188</td><td>0.562</td><td>0.058</td><td>0.192</td></tr>\n",
       "\t<tr><th scope=row>item4</th><td>0.034</td><td>0.125</td><td>0.742</td><td>0.099</td></tr>\n",
       "\t<tr><th scope=row>item5</th><td>0.351</td><td>0.254</td><td>0.042</td><td>0.353</td></tr>\n",
       "\t<tr><th scope=row>item6</th><td>0.081</td><td>0.198</td><td>0.558</td><td>0.163</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 4 of type dbl\n",
       "\\begin{tabular}{r|llll}\n",
       "  & 1 & 2 & 3 & 4\\\\\n",
       "\\hline\n",
       "\titem1 & 0.044 & 0.058 & 0.052 & 0.845\\\\\n",
       "\titem2 & 0.109 & 0.069 & 0.792 & 0.030\\\\\n",
       "\titem3 & 0.188 & 0.562 & 0.058 & 0.192\\\\\n",
       "\titem4 & 0.034 & 0.125 & 0.742 & 0.099\\\\\n",
       "\titem5 & 0.351 & 0.254 & 0.042 & 0.353\\\\\n",
       "\titem6 & 0.081 & 0.198 & 0.558 & 0.163\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 4 of type dbl\n",
       "\n",
       "| <!--/--> | 1 | 2 | 3 | 4 |\n",
       "|---|---|---|---|---|\n",
       "| item1 | 0.044 | 0.058 | 0.052 | 0.845 |\n",
       "| item2 | 0.109 | 0.069 | 0.792 | 0.030 |\n",
       "| item3 | 0.188 | 0.562 | 0.058 | 0.192 |\n",
       "| item4 | 0.034 | 0.125 | 0.742 | 0.099 |\n",
       "| item5 | 0.351 | 0.254 | 0.042 | 0.353 |\n",
       "| item6 | 0.081 | 0.198 | 0.558 | 0.163 |\n",
       "\n"
      ],
      "text/plain": [
       "      1     2     3     4    \n",
       "item1 0.044 0.058 0.052 0.845\n",
       "item2 0.109 0.069 0.792 0.030\n",
       "item3 0.188 0.562 0.058 0.192\n",
       "item4 0.034 0.125 0.742 0.099\n",
       "item5 0.351 0.254 0.042 0.353\n",
       "item6 0.081 0.198 0.558 0.163"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distractors <- distract(multiplechoice)\n",
    "head(distractors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11781ec8",
   "metadata": {},
   "source": [
    "Nella tabella sopra, vediamo che molti item avevano distrattori selezionati circa il 5% delle volte o meno. Questi distrattori potrebbero essere candidati per una revisione in quanto sono stati approvati ad un livello così basso da suggerire che la maggior parte degli esaminandi non li ha considerati come opzioni plausibili. Per l'item 1, i distrattori funzionavano tutti più o meno allo stesso modo (ovvero circa il 5% delle volte ogniuno è stato approvato), suggerendo che funzionavano tutti bene rispetto l'uno all'altro, ma che l'item era troppo facile (la risposta corretta era l'opzione 4, selezionata dall'84.5% degli esaminandi). Al contrario, l'item 5 era un item più difficile, con la risposta corretta che ancora una volta era l'opzione 4. Le opzioni 1 e 2 erano molto probabilmente fraintendimenti, mentre l'opzione 3 potrebbe essere rivista o potenzialmente eliminata da questo item a causa del basso tasso di approvazione (solo il 4.2%). Dato l'approvazione molto alta dell'opzione 1 (35.1%), è molto probabile che anche questa opzione fosse corretta. Per ottenere una visione più completa del funzionamento dell'item, sarebbe consigliabile calcolare l'indice di discriminazione specifico per quell'item. Questo ci permetterebbe di ottenere ulteriori informazioni sulla capacità dell'item di distinguere tra candidati di alto e basso livello.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,eval,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
