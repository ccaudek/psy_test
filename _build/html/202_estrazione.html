

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>17. L’estrazione dei fattori &#8212; cfa_book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '202_estrazione';</script>
    <link rel="shortcut icon" href="_static/increasing.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="18. Il numero dei fattori" href="203_numero_fattori.html" />
    <link rel="prev" title="16. Valutazione della matrice di correlazione" href="201_valutare_le_matrici.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Modello lineare</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="05_intro_r.html">1. Linguaggio di programmazione R</a></li>
<li class="toctree-l1"><a class="reference internal" href="010_regression.html">2. L’analisi di regressione</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Teoria classica dei test</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="035_ctt.html">3. Fondamenti teorici</a></li>
<li class="toctree-l1"><a class="reference internal" href="037_err_std_mis.html">4. L’errore standard della misurazione</a></li>
<li class="toctree-l1"><a class="reference internal" href="038_err_std_stima.html">5. La stima del punteggio vero</a></li>
<li class="toctree-l1"><a class="reference internal" href="040_exercises_ctt.html">6. Applicazioni della CTT</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Analisi fattoriale</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="050_sviluppo_strumento.html">7. Utilizzo e costruzione di test psicometrici</a></li>
<li class="toctree-l1"><a class="reference internal" href="055_analisi_fattoriale_1.html">8. Il modello unifattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="056_analisi_fattoriale_2.html">9. Il modello statistico dell’analisi fattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="057_analisi_fattoriale_3.html">10. Il modello multifattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="058_factor_scores.html">11. I punteggi fattoriali</a></li>
<li class="toctree-l1"><a class="reference internal" href="060_path_analysis.html">12. Visualizzare i modelli di equazioni strutturali</a></li>
<li class="toctree-l1"><a class="reference internal" href="062_constraints_on_parms.html">13. Attendibilità e modello fattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="070_cfa_mod_comp.html">14. CFA: confronto tra modelli</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Costruzione di strumenti psicometrici</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="200_problema_strumento.html">15. Tipologie dei test psicometrici</a></li>
<li class="toctree-l1"><a class="reference internal" href="201_valutare_le_matrici.html">16. Valutazione della matrice di correlazione</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">17. L’estrazione dei fattori</a></li>
<li class="toctree-l1"><a class="reference internal" href="203_numero_fattori.html">18. Il numero dei fattori</a></li>
<li class="toctree-l1"><a class="reference internal" href="205_rotazione.html">19. La rotazione fattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="206_valutare_sol_fattoriale.html">20. Valutare e rifinire la soluzione fattoriale</a></li>
<li class="toctree-l1"><a class="reference internal" href="250_group_invariance.html">21. Invarianza di misura</a></li>
<li class="toctree-l1"><a class="reference internal" href="300_gof.html">22. Indici di bontà dell’adattamento</a></li>
<li class="toctree-l1"><a class="reference internal" href="310_refine_solution.html">23. La revisione del modello</a></li>
<li class="toctree-l1"><a class="reference internal" href="315_mmm.html">24. CFA per matrici multi-tratto multi-metodo</a></li>
<li class="toctree-l1"><a class="reference internal" href="500_cat_data.html">25. Dati non gaussiani e categoriali</a></li>
<li class="toctree-l1"><a class="reference internal" href="501_missing_data.html">26. Dati mancanti</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Modelli di equazioni strutturali</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="316_sem_intro.html">27. Introduzione ai modelli di equazioni struttural</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Curve di crescita latente</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="320_lgm_intro.html">28. Curve di crescita latente</a></li>
<li class="toctree-l1"><a class="reference internal" href="321_lgm_prelims.html">29. Dati longitudinali</a></li>
<li class="toctree-l1"><a class="reference internal" href="324_lgm_mixed.html">30. LGM e modelli misti</a></li>
<li class="toctree-l1"><a class="reference internal" href="326_growth_1.html">31. Curve di crescita latente</a></li>
<li class="toctree-l1"><a class="reference internal" href="327_growth_cont.html">32. Il tempo su una metrica continua</a></li>
<li class="toctree-l1"><a class="reference internal" href="328_time_inv_cov.html">33. Covariate indipendenti dal tempo</a></li>
<li class="toctree-l1"><a class="reference internal" href="329_growth_groups.html">34. Modelli di crescita latenti a gruppi multipli</a></li>
<li class="toctree-l1"><a class="reference internal" href="330_bivariate_growth_models.html">35. Modelli di crescita latenti bivariati</a></li>
<li class="toctree-l1"><a class="reference internal" href="331_inv_measurement.html">36. Invarianza di misurazione</a></li>
<li class="toctree-l1"><a class="reference internal" href="332_latent_change.html">37. Modello LCS univariato</a></li>
<li class="toctree-l1"><a class="reference internal" href="333_biv_change.html">38. Modello LCS bivariato</a></li>
<li class="toctree-l1"><a class="reference internal" href="351_lgm_meas_inv.html">39. Invarianza fattoriale nei modelli LGM</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bibliografia</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="z_biblio.html">40. Bibliografia</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendici</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="900_lin_alg.html">41. Elementi di algebra lineare</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ccaudek/cfa_book_2023" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ccaudek/cfa_book_2023/issues/new?title=Issue%20on%20page%20%2F202_estrazione.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/202_estrazione.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>L’estrazione dei fattori</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-delle-componenti-principali">17.1. Metodo delle componenti principali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-dei-fattori-principali">17.2. Metodo dei fattori principali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-dei-fattori-principali-iterato">17.3. Metodo dei fattori principali iterato</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#casi-di-heywood">17.3.1. Casi di Heywood</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-di-massima-verosimiglianza">17.4. Metodo di massima verosimiglianza</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="l-estrazione-dei-fattori">
<span id="extraction-notebook"></span><h1><span class="section-number">17. </span>L’estrazione dei fattori<a class="headerlink" href="#l-estrazione-dei-fattori" title="Permalink to this headline">#</a></h1>
<p>L’analisi fattoriale mira a descrivere in modo parsimonioso le relazioni tra un grande numero di item. L’obiettivo è identificare un piccolo numero di variabili latenti che, quando controllate, rendono uguali a zero le correlazioni parziali tra gli item. Una volta determinato il numero dei fattori comuni, è possibile stimare le saturazioni fattoriali, che corrispondono alle correlazioni o covarianze tra gli item e i fattori.</p>
<p>In termini matriciali, il modello multifattoriale si scrive</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\Sigma} =\boldsymbol{\Lambda} \boldsymbol{\Phi} \boldsymbol{\Lambda}^{\mathsf{T}} + \boldsymbol{\Psi} 
\]</div>
<p>dove <span class="math notranslate nohighlight">\(\boldsymbol{\Phi}\)</span> è la matrice di ordine <span class="math notranslate nohighlight">\(m \times m\)</span> di varianze
e covarianze tra i fattori comuni e <span class="math notranslate nohighlight">\(\boldsymbol{\Psi}\)</span> è una matrice
diagonale di ordine <span class="math notranslate nohighlight">\(p\)</span> con le unicità delle variabili.</p>
<p>In questo capitolo descriveremo alcuni dei metodi che possono essere usati per stimare <span class="math notranslate nohighlight">\(\boldsymbol{\Lambda}\)</span>. Esamineremo il metodo delle componenti principali, il metodo dei fattori principali, il metodo dei fattori principali iterato e il metodo di massima verosimiglianza.</p>
<section id="metodo-delle-componenti-principali">
<h2><span class="section-number">17.1. </span>Metodo delle componenti principali<a class="headerlink" href="#metodo-delle-componenti-principali" title="Permalink to this headline">#</a></h2>
<p>L’analisi fattoriale eseguita mediante il metodo delle componenti
principali, nonostante il nome, non è un’analisi delle componenti
principali. Il metodo delle componenti principali costituisce invece
un’applicazione del teorema di scomposizione spettrale di una matrice.
Il <em>teorema spettrale</em> afferma che, data la matrice simmetrica
<span class="math notranslate nohighlight">\(\textbf{S}_{p \times p}\)</span>, è sempre possibile trovare una matrice
<span class="math notranslate nohighlight">\(\textbf{C}_{p \times p}\)</span> ortogonale tale che
<span class="math notranslate nohighlight">\(
\textbf{S} = \textbf{C}\textbf{D}\textbf{C}^{\mathsf{T}}
\)</span>
con <strong>D</strong> diagonale. Il teorema specifica inoltre che gli elementi presenti sulla diagonale di <strong>D</strong> sono gli autovalori di <strong>S</strong>, mentre le colonne di <strong>C</strong> rappresentano i rispettivi autovettori normalizzati associati agli autovalori di <strong>S</strong>.</p>
<p>Facciamo un esempio numerico utilizzando i dati discussi da
Rencher(2002). Brown, Williams e Barlow (1984) hanno raccolto le
valutazioni di una ragazza dodicenne relativamente a sette persone di
sua conoscenza. Ciascuna persona veniva valutata su una scala a nove
punti rispetto a cinque variabili: <em>kind</em>, <em>intelligent</em>, <em>happy</em>,
<em>likeable</em> e <em>just</em>. La matrice di correlazione per tali variabili è
riportata di seguito:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">R</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span>
<span class="w">  </span><span class="m">1.000</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">296</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">881</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">995</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">545</span><span class="p">,</span>
<span class="w">  </span><span class="n">.</span><span class="m">296</span><span class="p">,</span><span class="w"> </span><span class="m">1.000</span><span class="p">,</span><span class="w"> </span><span class="m">-.022</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">326</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">837</span><span class="p">,</span>
<span class="w">  </span><span class="n">.</span><span class="m">881</span><span class="p">,</span><span class="w"> </span><span class="m">-.022</span><span class="p">,</span><span class="w"> </span><span class="m">1.000</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">867</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">130</span><span class="p">,</span>
<span class="w">  </span><span class="n">.</span><span class="m">995</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">326</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">867</span><span class="p">,</span><span class="w"> </span><span class="m">1.000</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">544</span><span class="p">,</span>
<span class="w">  </span><span class="n">.</span><span class="m">545</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">837</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">130</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">544</span><span class="p">,</span><span class="w"> </span><span class="m">1.000</span>
<span class="p">),</span>
<span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">byrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">T</span><span class="p">,</span><span class="w"> </span><span class="n">dimnames</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span>
<span class="w">  </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;K&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;I&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;H&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;L&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;J&quot;</span><span class="p">),</span>
<span class="w">  </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;K&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;I&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;H&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;L&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;J&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="p">)</span>
<span class="n">R</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A matrix: 5 × 5 of type dbl</caption>
<thead>
	<tr><th></th><th scope=col>K</th><th scope=col>I</th><th scope=col>H</th><th scope=col>L</th><th scope=col>J</th></tr>
</thead>
<tbody>
	<tr><th scope=row>K</th><td>1.000</td><td> 0.296</td><td> 0.881</td><td>0.995</td><td>0.545</td></tr>
	<tr><th scope=row>I</th><td>0.296</td><td> 1.000</td><td>-0.022</td><td>0.326</td><td>0.837</td></tr>
	<tr><th scope=row>H</th><td>0.881</td><td>-0.022</td><td> 1.000</td><td>0.867</td><td>0.130</td></tr>
	<tr><th scope=row>L</th><td>0.995</td><td> 0.326</td><td> 0.867</td><td>1.000</td><td>0.544</td></tr>
	<tr><th scope=row>J</th><td>0.545</td><td> 0.837</td><td> 0.130</td><td>0.544</td><td>1.000</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Gli autovalori e gli autovettori si calcolano con la funzione <code class="docutils literal notranslate"><span class="pre">eigen()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">eigen</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>eigen() decomposition
$values
[1] 3.2633766259 1.5383820947 0.1679692814 0.0300298228 0.0002421752

$vectors
           [,1]       [,2]        [,3]       [,4]       [,5]
[1,] -0.5367301 -0.1859819 -0.18991841 -0.1247931  0.7910052
[2,] -0.2874672  0.6505666  0.68488713 -0.1198141  0.1034406
[3,] -0.4343545 -0.4736877  0.40694897  0.6136634 -0.2115794
[4,] -0.5373909 -0.1692797 -0.09532905 -0.6293896 -0.5266275
[5,] -0.3896544  0.5377158 -0.56583170  0.4442491 -0.2037363
</pre></div>
</div>
</div>
</div>
<p>Come indicato in precedenza, la matrice <strong>R</strong> può essere espressa come</p>
<div class="math notranslate nohighlight">
\[
\textbf{R} = \textbf{C}\textbf{D}\textbf{C}^{\mathsf{T}}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">e</span><span class="o">$</span><span class="n">vectors</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="nf">diag</span><span class="p">(</span><span class="n">e</span><span class="o">$</span><span class="n">values</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="nf">t</span><span class="p">(</span><span class="n">e</span><span class="o">$</span><span class="n">vectors</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A matrix: 5 × 5 of type dbl</caption>
<tbody>
	<tr><td>1.000</td><td> 0.296</td><td> 0.881</td><td>0.995</td><td>0.545</td></tr>
	<tr><td>0.296</td><td> 1.000</td><td>-0.022</td><td>0.326</td><td>0.837</td></tr>
	<tr><td>0.881</td><td>-0.022</td><td> 1.000</td><td>0.867</td><td>0.130</td></tr>
	<tr><td>0.995</td><td> 0.326</td><td> 0.867</td><td>1.000</td><td>0.544</td></tr>
	<tr><td>0.545</td><td> 0.837</td><td> 0.130</td><td>0.544</td><td>1.000</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Esaminiamo ora gli autovalori. I primi due autovalori spiegano da soli
il 96% della varianza campionaria:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">e</span><span class="o">$</span><span class="n">values</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">e</span><span class="o">$</span><span class="n">values</span><span class="p">[</span><span class="m">2</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">5</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">0.960351744117911</div></div>
</div>
<p>Usando i primi due autovalori e i primi due autovettori è dunque
possibile riprodurre in maniera soddisfacente la matrice <strong>R</strong> operando
nel contempo una riduzione di dimensionalità dei dati.</p>
<p>Per fattorizzare
<span class="math notranslate nohighlight">\(\textbf{R} = \textbf{C}\textbf{D}\textbf{C}^{\mathsf{T}}\)</span>
nella forma
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Lambda}} \hat{\boldsymbol{\Lambda}}^{\mathsf{T}}\)</span>
iniziamo a scrivere</p>
<div class="math notranslate nohighlight">
\[
\textbf{D}= \textbf{D}^{1/2} \textbf{D}^{1/2}
\]</div>
<p>dove</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\textbf{D}^{1/2} = 
\left[
  \begin{array}{ c c c c }
     \sqrt{\theta_1} &amp; 0 &amp; \dots &amp; 0 \\
     0 &amp; \sqrt{\theta_2} &amp; \dots &amp; 0 \\
     \dots &amp; \dots &amp; &amp; \dots \\
     0 &amp; 0 &amp; \dots &amp;  \sqrt{\theta_p}
  \end{array} 
\right]
\end{split}\]</div>
<p>Viene qui usata la notazione <span class="math notranslate nohighlight">\(\theta\)</span> per denotare gli
autovalori anziché il tradizionale <span class="math notranslate nohighlight">\(\lambda\)</span> per evitare la confusione
con la notazione <span class="math notranslate nohighlight">\(\lambda_{jl}\)</span> usata per le saturazioni fattoriali. In
questo modo, possiamo scrivere</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
\begin{aligned}
\textbf{R} &amp;= \textbf{C}\textbf{D}\textbf{C}^{\mathsf{T}}\notag\\
&amp;= \textbf{C}\textbf{D}^{1/2}\textbf{D}^{1/2}\textbf{C}^{\mathsf{T}}\notag\\
&amp;= (\textbf{C}\textbf{D}^{1/2}) (\textbf{C}\textbf{D}^{1/2})^{\mathsf{T}}.
\end{aligned}
\end{equation}
\end{split}\]</div>
<p>Non possiamo però limiarci a definire
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Lambda}}=\textbf{C}\textbf{D}^{1/2}\)</span> in quanto
<span class="math notranslate nohighlight">\(\textbf{C}\textbf{D}^{1/2}\)</span> è di ordine <span class="math notranslate nohighlight">\(p \times p\)</span> e non otteniamo
quindi una riduzione di dimensioni. Quello che cerchiamo è una matrice
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Lambda}}\)</span> di ordine <span class="math notranslate nohighlight">\(p \times m\)</span> con <span class="math notranslate nohighlight">\(m &lt; p\)</span>. Dunque,
definiamo la matrice <span class="math notranslate nohighlight">\(\textbf{D}_1= \text{diag}(\theta_1,
\theta_2, \dots, \theta_m)\)</span> come la la matrice contenente gli <span class="math notranslate nohighlight">\(m\)</span>
autovalori più grandi di <strong>R</strong> e <span class="math notranslate nohighlight">\(\textbf{C}_1=( \textbf{c}_1,
\textbf{c}_2, \dots,  \textbf{c}_m)\)</span> come la matrice contenente i
rispettivi autovettori.</p>
<p>Mediante il metodo delle componenti principali,
le saturazioni fattoriali <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Lambda}}\)</span> vengono quindi
stimate nel modo seguente:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
\begin{aligned}
\hat{\boldsymbol{\Lambda}} &amp;= \textbf{C}_1 \textbf{D}_1^{1/2}\notag\\
&amp;= (\sqrt{\theta_1} \textbf{c}_1, \sqrt{\theta_2} \textbf{c}_2, 
\dots, \sqrt{\theta_m} \textbf{c}_m) 
\end{aligned}
\end{equation}
\end{split}\]</div>
<p>Per l’esempio presente, con <span class="math notranslate nohighlight">\(m=2\)</span> e <span class="math notranslate nohighlight">\(p=5\)</span>, avremo</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[
  \begin{array}{ c c }
 \hat{\lambda}_{11} &amp; \hat{\lambda}_{12} \\
 \hat{\lambda}_{21} &amp; \hat{\lambda}_{22} \\
 \hat{\lambda}_{31} &amp; \hat{\lambda}_{32} \\
 \hat{\lambda}_{41} &amp; \hat{\lambda}_{42} \\
 \hat{\lambda}_{51} &amp; \hat{\lambda}_{52} 
  \end{array} 
\right] =
\left[
  \begin{array}{ c c }
 c_{11} &amp; c_{12} \\
 c_{21} &amp; c_{22} \\
 c_{31} &amp; c_{32} \\
 c_{41} &amp; c_{42} \\
 c_{51} &amp; c_{52} 
  \end{array} 
\right]
\left[
  \begin{array}{ c c }
 \sqrt{\theta_1} &amp; 0\\
 0 &amp;\sqrt{\theta_2} 
  \end{array} 
\right]
\end{split}\]</div>
<p>Le saturazioni fattoriali stimate sono dunque uguali a</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[
  \begin{array}{ c c }
 \sqrt{\theta_1}c_{11} &amp; \sqrt{\theta_2}c_{12} \\
 \sqrt{\theta_1}c_{21} &amp; \sqrt{\theta_2}c_{22} \\
 \sqrt{\theta_1}c_{31} &amp; \sqrt{\theta_2}c_{32} \\
 \sqrt{\theta_1}c_{41} &amp; \sqrt{\theta_2}c_{42} \\
 \sqrt{\theta_1}c_{51} &amp; \sqrt{\theta_2}c_{52} 
  \end{array} 
\right]
\end{split}\]</div>
<p>Svolgendo i calcoli con <span class="math notranslate nohighlight">\(\textsf{R}\)</span> otteniamo:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">L</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">cbind</span><span class="p">(</span>
<span class="w">  </span><span class="n">e</span><span class="o">$</span><span class="n">vectors</span><span class="p">[,</span><span class="w"> </span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">e</span><span class="o">$</span><span class="n">values</span><span class="p">[</span><span class="m">1</span><span class="p">]),</span>
<span class="w">  </span><span class="n">e</span><span class="o">$</span><span class="n">vectors</span><span class="p">[,</span><span class="w"> </span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">e</span><span class="o">$</span><span class="n">values</span><span class="p">[</span><span class="m">2</span><span class="p">])</span>
<span class="p">)</span>

<span class="nf">round</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A matrix: 5 × 2 of type dbl</caption>
<tbody>
	<tr><td>-0.970</td><td>-0.231</td></tr>
	<tr><td>-0.519</td><td> 0.807</td></tr>
	<tr><td>-0.785</td><td>-0.588</td></tr>
	<tr><td>-0.971</td><td>-0.210</td></tr>
	<tr><td>-0.704</td><td> 0.667</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>La matrice di correlazione riprodotta (con le comunalità sulla diagonale
principale) diventa</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">R_hat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">L</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="nf">t</span><span class="p">(</span><span class="n">L</span><span class="p">),</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
<span class="n">R_hat</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A matrix: 5 × 5 of type dbl</caption>
<tbody>
	<tr><td>0.993</td><td> 0.317</td><td> 0.896</td><td>0.990</td><td>0.529</td></tr>
	<tr><td>0.317</td><td> 0.921</td><td>-0.067</td><td>0.335</td><td>0.904</td></tr>
	<tr><td>0.896</td><td>-0.067</td><td> 0.961</td><td>0.885</td><td>0.160</td></tr>
	<tr><td>0.990</td><td> 0.335</td><td> 0.885</td><td>0.987</td><td>0.543</td></tr>
	<tr><td>0.529</td><td> 0.904</td><td> 0.160</td><td>0.543</td><td>0.940</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>La matrice di correlazioni residue (con le specificità sulla diagonale principale) è la seguente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">R</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">R_hat</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A matrix: 5 × 5 of type dbl</caption>
<thead>
	<tr><th></th><th scope=col>K</th><th scope=col>I</th><th scope=col>H</th><th scope=col>L</th><th scope=col>J</th></tr>
</thead>
<tbody>
	<tr><th scope=row>K</th><td> 0.007</td><td>-0.021</td><td>-0.015</td><td> 0.005</td><td> 0.016</td></tr>
	<tr><th scope=row>I</th><td>-0.021</td><td> 0.079</td><td> 0.045</td><td>-0.009</td><td>-0.067</td></tr>
	<tr><th scope=row>H</th><td>-0.015</td><td> 0.045</td><td> 0.039</td><td>-0.018</td><td>-0.030</td></tr>
	<tr><th scope=row>L</th><td> 0.005</td><td>-0.009</td><td>-0.018</td><td> 0.013</td><td> 0.001</td></tr>
	<tr><th scope=row>J</th><td> 0.016</td><td>-0.067</td><td>-0.030</td><td> 0.001</td><td> 0.060</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Possiamo ora capire il motivo del nome <em>metodo delle componenti
principali</em>: le saturazioni fattoriali sono proporzionali agli
autovettori di <span class="math notranslate nohighlight">\(\textbf{R}\)</span>. Tuttavia, l’interpretazione è diversa da
quella che viene assegnata ai risultati dell’analisi delle componenti
principali.</p>
<p>È possibile condurre l’analisi fattoriale con il metodo delle componenti
principali sia utilizzando la matrice <span class="math notranslate nohighlight">\(\textbf{S}\)</span> di
varianze-covarianze sia la matrice <span class="math notranslate nohighlight">\(\textbf{R}\)</span> delle correlazioni.
Tuttavia, le soluzioni ottenute usando <span class="math notranslate nohighlight">\(\textbf{S}\)</span> o <span class="math notranslate nohighlight">\(\textbf{R}\)</span> non
sono legate da una relazione algebrica: il metodo delle componenti
principali non è invariante rispetto ai cambiamenti di scala delle
osservazioni. Un altro svantaggio del metodo delle componenti principali
è che non fornisce un test di bontà di adattamento. Tale test può essere
invece svolto quando la soluzione viene trovata con il metodo della
massima verosimiglianza.</p>
</section>
<section id="metodo-dei-fattori-principali">
<h2><span class="section-number">17.2. </span>Metodo dei fattori principali<a class="headerlink" href="#metodo-dei-fattori-principali" title="Permalink to this headline">#</a></h2>
<p>Il <em>metodo dei fattori principali</em> (<em>principal factor method</em>, anche
detto <em>principal axis method</em>) è uno dei metodi maggiormente usati per
la stima delle saturazioni fattoriali e delle comunalità. Il metodo
delle componenti principali che abbiamo usato in precedenza trascura la specificità <span class="math notranslate nohighlight">\(\boldsymbol{\Psi}\)</span> e si limita a fattorializzare le covarianze di <strong>S</strong> o le correlazioni
di <strong>R</strong>. Il metodo dei fattori principali affronta questo problema ricorrendo ad una procedura simile
al metodo delle componenti principali, nella quale però viene utilizzata una matrice
ridotta di varianze-covarianze <span class="math notranslate nohighlight">\(\textbf{S} - \hat{\boldsymbol{\Psi}}\)</span> in cui una <em>stima delle comunalità</em> viene sostituita alle varianze presenti sulla diagonale principale della matrice <strong>S</strong> o  <strong>R</strong>.</p>
<p>Nel caso della matrice ridotta di correlazioni
<span class="math notranslate nohighlight">\(\textbf{R} - \hat{\boldsymbol{\Psi}}\)</span>, per la comunalità <span class="math notranslate nohighlight">\(i\)</span>-esima
<span class="math notranslate nohighlight">\(\sum_{j}\lambda_{ij}^2\)</span> si sceglie il quadrato del coefficiente di
correlazione multipla tra <span class="math notranslate nohighlight">\(Y_i\)</span> e tutte le altre <span class="math notranslate nohighlight">\(p-1\)</span> variabili. Tale
valore si può trovare nel modo seguente</p>
<div class="math notranslate nohighlight">
\[
\hat{h}^2_i=R^2_i=1-\frac{1}{r^{ii}},
\]</div>
<p>dove <span class="math notranslate nohighlight">\(r^{ii}\)</span> è l’elemento diagonale <span class="math notranslate nohighlight">\(i\)</span>-esimo di <span class="math notranslate nohighlight">\(\textbf{R}^{-1}\)</span>. Nel caso di una matrice
ridotta di varianze-covarianze <span class="math notranslate nohighlight">\(\textbf{S} - \hat{\boldsymbol{\Psi}}\)</span>,
le comunalità possono essere stimate calcolando</p>
<div class="math notranslate nohighlight">
\[
\hat{h}_i^2=s_{ii}-\frac{1}{r^{ii}},
\]</div>
<p>dove <span class="math notranslate nohighlight">\(s_{ii}\)</span> è l’elemento diagonale <span class="math notranslate nohighlight">\(i\)</span>-esimo di <span class="math notranslate nohighlight">\(\textbf{S}\)</span>.</p>
<p>Affinché le stime comunalità possano essere calcolate come descritto
sopra, la matrice <span class="math notranslate nohighlight">\(\textbf{R}\)</span> non deve essere singolare. Se <span class="math notranslate nohighlight">\(\textbf{R}\)</span> è singolare, per la stima della comunalità <span class="math notranslate nohighlight">\(i\)</span>-esima, <span class="math notranslate nohighlight">\(\hat{h}^2_i\)</span>, si utilizza il valore assoluto del più elevato
coefficiente di correlazione lineare tra <span class="math notranslate nohighlight">\(Y_i\)</span> e le altre variabili.</p>
<p>Scelta la stima della comunalità, la matrice ridotta di
varianze-covarianze si ottiene sostituendo le stime delle comunalità alle varianze sulla diagonale
principale della matrice <span class="math notranslate nohighlight">\(\textbf{S}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\textbf{S} - \hat{\boldsymbol{\Psi}} = 
\left[
  \begin{array}{ c c c c }
    \hat{h}^2_1 &amp; s_{12} &amp; \dots &amp; s_{1p} \\
    s_{21} &amp; \hat{h}^2_2 &amp; \dots &amp; s_{2p} \\
    \dots &amp; \dots &amp;           &amp; \dots\\
    s_{p1} &amp;  s_{p2} &amp; \dots &amp; \hat{h}^2_p
  \end{array} 
\right]
\end{split}\]</div>
<p>In maniera equivalente, la matrice ridotta di correlazioni si
ottiene nel modo seguente:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\textbf{R} - \hat{\boldsymbol{\Psi}} = 
\left[
  \begin{array}{ c c c c }
    \hat{h}^2_1 &amp; r_{12} &amp; \dots &amp; r_{1p} \\
    r_{21} &amp; \hat{h}^2_2 &amp; \dots &amp; r_{2p} \\
    \dots &amp; \dots &amp;           &amp; \dots\\
    r_{p1} &amp;  r_{p2} &amp; \dots &amp; \hat{h}^2_p
  \end{array} 
\right]
\end{split}\]</div>
<p>Facciamo ora un esempio concreto usando la matrice
di correlazione dell’esempio precedente. Quale stima della comunalità
<span class="math notranslate nohighlight">\(i\)</span>-esima, useremo il valore assoluto più elevato nella riga
<span class="math notranslate nohighlight">\(i\)</span>-esima della matrice <strong>R</strong>. Per i dati dell’esempio, le stime delle
comunalità sono dunque pari a <span class="math notranslate nohighlight">\(0.995\)</span>, <span class="math notranslate nohighlight">\(0.837\)</span>, <span class="math notranslate nohighlight">\(0.881\)</span>, <span class="math notranslate nohighlight">\(0.995\)</span> e
<span class="math notranslate nohighlight">\(0.837\)</span>.</p>
<p>Inserendo tali valori nella diagonale principale, otteniamo la matrice
ridotta delle correlazioni <span class="math notranslate nohighlight">\(\textbf{R} - \hat{\boldsymbol{\Psi}}\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">R1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">R</span>
<span class="n">h.hat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">.</span><span class="m">995</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">837</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">881</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">995</span><span class="p">,</span><span class="w"> </span><span class="n">.</span><span class="m">837</span><span class="p">)</span>
<span class="n">R1</span><span class="p">[</span><span class="nf">cbind</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">h.hat</span>
<span class="n">R1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A matrix: 5 × 5 of type dbl</caption>
<thead>
	<tr><th></th><th scope=col>K</th><th scope=col>I</th><th scope=col>H</th><th scope=col>L</th><th scope=col>J</th></tr>
</thead>
<tbody>
	<tr><th scope=row>K</th><td>0.995</td><td> 0.296</td><td> 0.881</td><td>0.995</td><td>0.545</td></tr>
	<tr><th scope=row>I</th><td>0.296</td><td> 0.837</td><td>-0.022</td><td>0.326</td><td>0.837</td></tr>
	<tr><th scope=row>H</th><td>0.881</td><td>-0.022</td><td> 0.881</td><td>0.867</td><td>0.130</td></tr>
	<tr><th scope=row>L</th><td>0.995</td><td> 0.326</td><td> 0.867</td><td>0.995</td><td>0.544</td></tr>
	<tr><th scope=row>J</th><td>0.545</td><td> 0.837</td><td> 0.130</td><td>0.544</td><td>0.837</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Gli autovalori della matrice ridotta di correlazioni
<span class="math notranslate nohighlight">\(\textbf{R} - \hat{\boldsymbol{\Psi}}\)</span> sono:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">ee</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">eigen</span><span class="p">(</span><span class="n">R1</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">ee</span><span class="o">$</span><span class="n">values</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1]  3.202  1.394  0.029  0.000 -0.080
</pre></div>
</div>
</div>
</div>
<p>La somma degli autovalori è uguale a</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">ee</span><span class="o">$</span><span class="n">values</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 4.545
</pre></div>
</div>
</div>
</div>
<p>I primi due autovalori di <span class="math notranslate nohighlight">\(\textbf{R} - \hat{\boldsymbol{\Psi}}\)</span> sono:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">ee</span><span class="o">$</span><span class="n">vectors</span><span class="p">[,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">2</span><span class="p">],</span><span class="w"> </span><span class="m">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>       [,1]   [,2]
[1,] -0.548 -0.177
[2,] -0.272  0.656
[3,] -0.431 -0.461
[4,] -0.549 -0.159
[5,] -0.373  0.549
</pre></div>
</div>
</div>
</div>
<p>Moltiplicando tali valori per la radice quadrata dei rispettivi
autovalori si ottengono le stime delle saturazioni fattoriali:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">round</span><span class="p">(</span><span class="n">ee</span><span class="o">$</span><span class="n">vectors</span><span class="p">[,</span><span class="m">1</span><span class="o">:</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">diag</span><span class="p">(</span><span class="n">ee</span><span class="o">$</span><span class="n">values</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">2</span><span class="p">])),</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A matrix: 5 × 2 of type dbl</caption>
<tbody>
	<tr><td>-0.981</td><td>-0.209</td></tr>
	<tr><td>-0.487</td><td> 0.774</td></tr>
	<tr><td>-0.772</td><td>-0.544</td></tr>
	<tr><td>-0.982</td><td>-0.187</td></tr>
	<tr><td>-0.667</td><td> 0.648</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Tale risultato replica quello riportato da Rencher (2002).</p>
</section>
<section id="metodo-dei-fattori-principali-iterato">
<h2><span class="section-number">17.3. </span>Metodo dei fattori principali iterato<a class="headerlink" href="#metodo-dei-fattori-principali-iterato" title="Permalink to this headline">#</a></h2>
<p>Solitamente, per migliorare la stima della comunalità, la diagonale
della matrice <span class="math notranslate nohighlight">\(\textbf{S} - \hat{\boldsymbol{\Psi}}\)</span> o
<span class="math notranslate nohighlight">\(\textbf{R} - \hat{\boldsymbol{\Psi}}\)</span> viene ottenuta per iterazione.
Dopo avere trovato <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Lambda}}\)</span> a partire da
<span class="math notranslate nohighlight">\(\textbf{S} - \hat{\boldsymbol{\Psi}}\)</span> o
<span class="math notranslate nohighlight">\(\textbf{R} - \hat{\boldsymbol{\Psi}}\)</span> come indicato in precedenza,
utilizzando le stime delle saturazioni fattoriali così ottenute possiamo
stimare le comunalità nel modo seguente:</p>
<div class="math notranslate nohighlight">
\[\hat{h}^2_i = \sum_{i=1}^m \hat{\lambda}_{ij}^2.\]</div>
<p>I valori di <span class="math notranslate nohighlight">\(\hat{h}^2_i\)</span> così trovati vengono quindi sostituiti nella diagonale della matrice
ridotta <span class="math notranslate nohighlight">\(\textbf{S} - \hat{\boldsymbol{\Psi}}\)</span> o
<span class="math notranslate nohighlight">\(\textbf{R} - \hat{\boldsymbol{\Psi}}\)</span>. A partire da questa nuova
matrice, usando il metodo descritto in precedenza, possiamo
ottenere una nuova stima delle saturazioni fattoriali
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Lambda}}\)</span>. Mediante questa nuova stima di
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Lambda}}\)</span>, possiamo procedere ad una nuova stima
delle comunalità. Tale processo continua iterativamente sino alla
convergenza. Gli autovalori e gli autovettori della versione finale di
<span class="math notranslate nohighlight">\(\textbf{S} - \hat{\boldsymbol{\Psi}}\)</span> o
<span class="math notranslate nohighlight">\(\textbf{R} - \hat{\boldsymbol{\Psi}}\)</span> vengono infine usati per stimare
i pesi fattoriali. Il metodo dei fattori principali iterato e il metodo
delle componenti principali producono risultati molto simili quando <span class="math notranslate nohighlight">\(m\)</span>
assume un piccolo valore (questo si verifica quando le correlazioni sono
alte) e quando <span class="math notranslate nohighlight">\(p\)</span> (il numero delle variabili) è grande.</p>
<section id="casi-di-heywood">
<h3><span class="section-number">17.3.1. </span>Casi di Heywood<a class="headerlink" href="#casi-di-heywood" title="Permalink to this headline">#</a></h3>
<p>Tra gli inconvenienti del metodo dei fattori principali iterato vi è il
fatto che può talvolta portare a soluzioni inammissibili (quando viene
fattorizzata la matrice <strong>R</strong>) caratterizzate da valori di comunalità
maggiori di uno (<em>caso di Heywood</em>). Se <span class="math notranslate nohighlight">\(\hat{h}^2_i &gt; 1\)</span> allora
<span class="math notranslate nohighlight">\(\hat{\psi}_i &lt; 0\)</span> il che è chiaramente assurdo in quanto una varianza
non può assumere un valore negativo. Solitamente, quando la stima di una
comunalità è maggiore di uno, il processo iterativo viene interrotto e
il programma riporta che non può essere trovata una soluzione.</p>
<p>Per fare un esempio, usiamo la funzione <code class="docutils literal notranslate"><span class="pre">fa()</span></code> contenuta nel pacchetto <code class="docutils literal notranslate"><span class="pre">psych</span></code>. Tale funzione per trovare la soluzione dei fattori principali mediante il metodo iterativo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">pa</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">fa</span><span class="p">(</span><span class="n">R</span><span class="p">,</span><span class="w"> </span><span class="n">nfactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">rotate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;none&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">fm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;pa&quot;</span><span class="p">)</span>
<span class="n">pa</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Warning message in fa.stats(r = r, f = f, phi = phi, n.obs = n.obs, np.obs = np.obs, :
“The estimated weights for the factor scores are probably incorrect.  Try a different factor score estimation method.”
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Warning message in fac(r = r, nfactors = nfactors, n.obs = n.obs, rotate = rotate, :
“An ultra-Heywood case was detected.  Examine the results carefully”
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Factor Analysis using method =  pa
Call: fa(r = R, nfactors = 2, rotate = &quot;none&quot;, fm = &quot;pa&quot;)
Standardized loadings (pattern matrix) based upon correlation matrix
   PA1   PA2   h2     u2 com
K 0.98 -0.21 1.01 -0.008 1.1
I 0.48  0.74 0.77  0.230 1.7
H 0.78 -0.56 0.92  0.085 1.8
L 0.98 -0.19 0.99  0.010 1.1
J 0.69  0.69 0.95  0.049 2.0

                       PA1  PA2
SS loadings           3.22 1.41
Proportion Var        0.64 0.28
Cumulative Var        0.64 0.93
Proportion Explained  0.70 0.30
Cumulative Proportion 0.70 1.00

Mean item complexity =  1.5
Test of the hypothesis that 2 factors are sufficient.

df null model =  10  with the objective function =  12
df of  the model are 1  and the objective function was  5.6 

The root mean square of the residuals (RMSR) is  0.01 
The df corrected root mean square of the residuals is  0.04 

Fit based upon off diagonal values = 1
</pre></div>
</div>
</div>
</div>
<p>Si noti che, in questo caso, le unicità assumono valori negativi, il che
suggerisce che la soluzione è impropria.</p>
</section>
</section>
<section id="metodo-di-massima-verosimiglianza">
<h2><span class="section-number">17.4. </span>Metodo di massima verosimiglianza<a class="headerlink" href="#metodo-di-massima-verosimiglianza" title="Permalink to this headline">#</a></h2>
<p>Il metodo di massima verosimiglianza è indicato quando si può assumere che le variabili manifeste seguano una distribuzione normale multivariata. In queste condizioni, il metodo produce stime dei pesi fattoriali che più verosimilmente hanno prodotto le correlazioni osservate. Gli stimatori di massima verosimiglianza sono preferibili a quelli ottenuti con altri metodi, a condizione che le premesse siano pienamente realizzate.</p>
<p>La funzione <span class="math notranslate nohighlight">\(F\)</span> che viene minimizzata dal metodo di massima verosimiglianza rappresenta una misura di “distanza” tra la matrice di covarianza osservata e quella predetta dal modello. Uguagliando a zero le derivate di <span class="math notranslate nohighlight">\(F\)</span> rispetto ai parametri del modello <span class="math notranslate nohighlight">\(\boldsymbol{\Lambda}\)</span> e <span class="math notranslate nohighlight">\(\boldsymbol{\Psi}\)</span> si
ottengono le equazioni per le stime di massima verosimiglianza di
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Lambda}}\)</span> e <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Psi}}\)</span>. Risolvendo
tali equazioni rispetto alle incognite <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Lambda}}\)</span> e
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Psi}}\)</span> si ricavano le stime di massima
verosimiglianza.</p>
<p>Poiché non esiste una soluzione analitica per le equazioni che stimano i parametri <span class="math notranslate nohighlight">\(\boldsymbol{\Lambda}\)</span> e <span class="math notranslate nohighlight">\(\boldsymbol{\Psi}\)</span>, si utilizzano metodi numerici iterativi per minimizzare la differenza tra la matrice di covarianze (o correlazioni) osservata e quella predetta dal modello. Tuttavia, le stime di massima verosimiglianza possono presentare problemi di convergenza e casi di Heywood, in cui le stime di comunalità sono superiori a 1. Nonostante ciò, la soluzione è indipendente dall’unità di misura delle variabili manifeste e si ottiene la stessa soluzione sia analizzando la matrice delle varianze e covarianze sia quella delle correlazioni.</p>
<p>La stima di massima verosimiglianza si ottiene usando <code class="docutils literal notranslate"><span class="pre">factanal</span></code>. È inoltre il metodo di stima di default di <code class="docutils literal notranslate"><span class="pre">lavaan</span></code>.</p>
<p>Consideriamo nuovamente i dati dell’esempio precedente. La stima di massima verosimiglianza dei parametri <span class="math notranslate nohighlight">\(\boldsymbol{\Lambda}\)</span> e <span class="math notranslate nohighlight">\(\boldsymbol{\Psi}\)</span> si ottiene nel modo seguente. i</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">factanal</span><span class="p">(</span><span class="n">covmat</span><span class="o">=</span><span class="n">R</span><span class="p">,</span><span class="w"> </span><span class="n">factors</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">rotation</span><span class="o">=</span><span class="s">&quot;none&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n.obs</span><span class="o">=</span><span class="m">225</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
factanal(factors = 2, covmat = R, n.obs = 225, rotation = &quot;none&quot;)

Uniquenesses:
    K     I     H     L     J 
0.005 0.268 0.055 0.008 0.005 

Loadings:
  Factor1 Factor2
K  0.955  -0.289 
I  0.528   0.673 
H  0.720  -0.653 
L  0.954  -0.287 
J  0.764   0.642 

               Factor1 Factor2
SS loadings      3.203   1.457
Proportion Var   0.641   0.291
Cumulative Var   0.641   0.932

Test of the hypothesis that 2 factors are sufficient.
The chi square statistic is 648.09 on 1 degree of freedom.
The p-value is 5.81e-143 
</pre></div>
</div>
</div>
</div>
<p>Si noti che il risultato è molto simile a quello ottenuto in precedenza. Si noti inoltre che le stime di massima verosimiglianza consentono un test di bontà di adattamento del modello ai dati (test chi quadrato).</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="201_valutare_le_matrici.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">16. </span>Valutazione della matrice di correlazione</p>
      </div>
    </a>
    <a class="right-next"
       href="203_numero_fattori.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">18. </span>Il numero dei fattori</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-delle-componenti-principali">17.1. Metodo delle componenti principali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-dei-fattori-principali">17.2. Metodo dei fattori principali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-dei-fattori-principali-iterato">17.3. Metodo dei fattori principali iterato</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#casi-di-heywood">17.3.1. Casi di Heywood</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-di-massima-verosimiglianza">17.4. Metodo di massima verosimiglianza</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>